#!/usr/bin/env python3
"""
Test script to validate critical fixes for AI indicators, third-person self-reference,
and conversation flow issues identified in the user's feedback.
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from app.orchestrator.server import (
    validate_character_response,
    _assess_conversation_flow_quality
)

def test_ai_indicator_detection():
    """Test detection of AI indicators that break immersion."""
    print("🚨 Testing AI Indicator Detection")
    print("=" * 50)
    
    test_cases = [
        {
            "character": "Peter",
            "response": "AI (as Peter): Hehehe, that's awesome!",
            "should_fail": True,
            "issue": "AI (as Peter) indicator"
        },
        {
            "character": "Brian", 
            "response": "AI (as Brian): Oh, for heaven's sake, Peter!",
            "should_fail": True,
            "issue": "AI (as Brian) indicator"
        },
        {
            "character": "Stewie",
            "response": "As an AI, I must say that's quite fascinating.",
            "should_fail": True,
            "issue": "As an AI reference"
        },
        {
            "character": "Peter",
            "response": "I'm an artificial intelligence playing Peter Griffin.",
            "should_fail": True,
            "issue": "Artificial intelligence reference"
        },
        {
            "character": "Brian",
            "response": "This response was generated by an AI assistant.",
            "should_fail": True,
            "issue": "AI assistant reference"
        },
        {
            "character": "Stewie",
            "response": "Blast! That's absolutely preposterous, you imbecile!",
            "should_fail": False,
            "issue": "Clean response without AI indicators"
        },
        {
            "character": "Peter",
            "response": "Hehehe, holy crap! That's freakin' awesome!",
            "should_fail": False,
            "issue": "Clean Peter response"
        }
    ]
    
    passed = 0
    for i, test in enumerate(test_cases, 1):
        print(f"\\nTest {i}: {test['issue']}")
        print(f"Character: {test['character']}")
        print(f"Response: {test['response']}")
        
        is_valid, _ = validate_character_response(test['character'], test['response'])
        
        if test['should_fail']:
            if not is_valid:
                print(f"✅ CORRECTLY REJECTED: AI indicator detected")
                passed += 1
            else:
                print(f"❌ MISSED AI INDICATOR: Response incorrectly passed validation")
        else:
            if is_valid:
                print(f"✅ CORRECTLY PASSED: Clean response accepted")
                passed += 1
            else:
                print(f"❌ FALSE POSITIVE: Clean response incorrectly rejected")
    
    print(f"\\n📊 AI Indicator Detection: {passed}/{len(test_cases)} tests passed")
    return passed == len(test_cases)

def test_third_person_self_reference():
    """Test detection of third-person self-reference issues."""
    print("\\n🎭 Testing Third-Person Self-Reference Detection")
    print("=" * 50)
    
    test_cases = [
        {
            "character": "Stewie",
            "response": "I must tend to Stewie's latest invention.",
            "should_fail": True,
            "issue": "Stewie referring to 'Stewie's latest'"
        },
        {
            "character": "Stewie",
            "response": "I must tend to my latest invention.",
            "should_fail": False,
            "issue": "Correct first-person reference"
        },
        {
            "character": "Brian",
            "response": "Brian thinks this is quite fascinating.",
            "should_fail": True,
            "issue": "Brian thinks (third person)"
        },
        {
            "character": "Brian",
            "response": "I think this is quite fascinating.",
            "should_fail": False,
            "issue": "Correct first-person thinking"
        },
        {
            "character": "Peter",
            "response": "Peter goes to the kitchen for beer.",
            "should_fail": True,
            "issue": "Peter goes (third person action)"
        },
        {
            "character": "Peter",
            "response": "I'm gonna go get some beer!",
            "should_fail": False,
            "issue": "Correct first-person action"
        },
        {
            "character": "Stewie",
            "response": "Stewie's plan for world domination is brilliant.",
            "should_fail": True,
            "issue": "Stewie's plan (possessive third person)"
        },
        {
            "character": "Stewie",
            "response": "My plan for world domination is brilliant.",
            "should_fail": False,
            "issue": "Correct first-person possessive"
        },
        {
            "character": "Brian",
            "response": "Brian's novel is a masterpiece of literature.",
            "should_fail": True,
            "issue": "Brian's novel (possessive third person)"
        },
        {
            "character": "Brian",
            "response": "My novel is a masterpiece of literature.",
            "should_fail": False,
            "issue": "Correct first-person possessive"
        }
    ]
    
    passed = 0
    for i, test in enumerate(test_cases, 1):
        print(f"\\nTest {i}: {test['issue']}")
        print(f"Character: {test['character']}")
        print(f"Response: {test['response']}")
        
        is_valid, _ = validate_character_response(test['character'], test['response'])
        
        # Also test conversation flow assessment
        flow_assessment = _assess_conversation_flow_quality(
            test['character'], 
            test['response'], 
            "Human: What do you think about that?"
        )
        
        has_third_person_issue = any("third-person" in issue.lower() for issue in flow_assessment['issues'])
        
        if test['should_fail']:
            if not is_valid or has_third_person_issue:
                print(f"✅ CORRECTLY REJECTED: Third-person self-reference detected")
                if has_third_person_issue:
                    print(f"   Flow issues: {[issue for issue in flow_assessment['issues'] if 'third-person' in issue.lower()]}")
                passed += 1
            else:
                print(f"❌ MISSED THIRD-PERSON ISSUE: Response incorrectly passed")
        else:
            if is_valid and not has_third_person_issue:
                print(f"✅ CORRECTLY PASSED: Proper first-person reference")
                passed += 1
            else:
                print(f"❌ FALSE POSITIVE: Correct response incorrectly rejected")
                if has_third_person_issue:
                    print(f"   False flow issues: {flow_assessment['issues']}")
    
    print(f"\\n📊 Third-Person Detection: {passed}/{len(test_cases)} tests passed")
    return passed == len(test_cases)

def test_conversation_engagement():
    """Test that characters engage with conversation rather than talking to themselves."""
    print("\\n🗣️ Testing Conversation Engagement")
    print("=" * 50)
    
    test_cases = [
        {
            "character": "Peter",
            "response": "Hehehe, that's awesome! Holy crap, I never thought of it that way!",
            "context": "Human: What do you think about this idea?",
            "should_pass": True,
            "issue": "Peter engaging with human question"
        },
        {
            "character": "Peter",
            "response": "I was thinking about beer. I should get some chicken. TV is good.",
            "context": "Human: What do you think about this idea?",
            "should_pass": False,
            "issue": "Peter ignoring question, talking to himself"
        },
        {
            "character": "Brian",
            "response": "That's a fascinating perspective. I find your analysis quite thought-provoking.",
            "context": "Human: Literature is important for society.",
            "should_pass": True,
            "issue": "Brian engaging intellectually"
        },
        {
            "character": "Brian",
            "response": "I've been working on my novel. I need to finish chapter three. Writing is hard.",
            "context": "Human: Literature is important for society.",
            "should_pass": False,
            "issue": "Brian monologuing about his own concerns"
        },
        {
            "character": "Stewie",
            "response": "What you're suggesting is absolutely brilliant! Though naturally, my own plans are far superior.",
            "context": "Human: I have an idea for world improvement.",
            "should_pass": True,
            "issue": "Stewie engaging condescendingly but appropriately"
        },
        {
            "character": "Stewie",
            "response": "My latest invention requires more sophisticated components. I must build a death ray.",
            "context": "Human: I have an idea for world improvement.",
            "should_pass": False,
            "issue": "Stewie ignoring input, monologuing about own plans"
        }
    ]
    
    passed = 0
    for i, test in enumerate(test_cases, 1):
        print(f"\\nTest {i}: {test['issue']}")
        print(f"Context: {test['context']}")
        print(f"Response: {test['response']}")
        
        flow_assessment = _assess_conversation_flow_quality(
            test['character'], 
            test['response'], 
            test['context']
        )
        
        has_conversation_awareness = flow_assessment['conversation_awareness']
        has_monologue_tendency = flow_assessment['monologue_tendency']
        flow_score = flow_assessment['flow_score']
        
        if test['should_pass']:
            if has_conversation_awareness and not has_monologue_tendency and flow_score >= 3.0:
                print(f"✅ GOOD ENGAGEMENT: Awareness={has_conversation_awareness}, Score={flow_score:.1f}")
                print(f"   Strengths: {', '.join(flow_assessment['strengths'])}")
                passed += 1
            else:
                print(f"❌ POOR ENGAGEMENT: Awareness={has_conversation_awareness}, Monologue={has_monologue_tendency}, Score={flow_score:.1f}")
                print(f"   Issues: {', '.join(flow_assessment['issues'])}")
        else:
            if not has_conversation_awareness or has_monologue_tendency or flow_score < 3.0:
                print(f"✅ CORRECTLY DETECTED POOR ENGAGEMENT: Score={flow_score:.1f}")
                print(f"   Issues: {', '.join(flow_assessment['issues'])}")
                passed += 1
            else:
                print(f"❌ MISSED POOR ENGAGEMENT: Score={flow_score:.1f}")
    
    print(f"\\n📊 Conversation Engagement: {passed}/{len(test_cases)} tests passed")
    return passed == len(test_cases)

def test_real_world_problematic_examples():
    """Test with actual problematic examples from the user's conversation."""
    print("\\n🌍 Testing Real-World Problematic Examples")
    print("=" * 50)
    
    # Test the actual problematic responses from the user's screenshot
    test_cases = [
        {
            "character": "Peter",
            "response": "AI (as Peter): Hehehehe, Brian! You're always so high and mighty with your big words. Me? I just wanna make sure my butt's comfortable while Stewie's busy with all his scheming.",
            "should_fail": True,
            "issue": "Real example: AI (as Peter) indicator"
        },
        {
            "character": "Brian",
            "response": "AI (as Brian): Oh, for heaven's sake, Peter! Must you reduce everything to a crude bodily function?",
            "should_fail": True,
            "issue": "Real example: AI (as Brian) indicator"
        },
        {
            "character": "Stewie",
            "response": "Now, if you'll excuse me, I must tend to Stewie's latest invention. It seems he's become rather obsessed with... well, I wouldn't want to spoil the surprise now, would I?",
            "should_fail": True,
            "issue": "Real example: Third-person self-reference 'Stewie's latest'"
        },
        {
            "character": "Peter",
            "response": "Hehehehe, Brian! You're always so high and mighty with your big words. Me? I just wanna make sure my butt's comfortable while Stewie's busy with all his scheming.",
            "should_fail": False,
            "issue": "Corrected: Removed AI indicator"
        },
        {
            "character": "Brian",
            "response": "Oh, for heaven's sake, Peter! Must you reduce everything to a crude bodily function?",
            "should_fail": False,
            "issue": "Corrected: Removed AI indicator"
        },
        {
            "character": "Stewie",
            "response": "Now, if you'll excuse me, I must tend to my latest invention. It seems I've become rather obsessed with... well, I wouldn't want to spoil the surprise now, would I?",
            "should_fail": False,
            "issue": "Corrected: Changed to first-person"
        }
    ]
    
    passed = 0
    for i, test in enumerate(test_cases, 1):
        print(f"\\nTest {i}: {test['issue']}")
        print(f"Response: {test['response'][:80]}...")
        
        is_valid, _ = validate_character_response(test['character'], test['response'])
        
        flow_assessment = _assess_conversation_flow_quality(
            test['character'], 
            test['response'], 
            "Human: What's going on?"
        )
        
        has_critical_issues = any("CRITICAL" in issue for issue in flow_assessment['issues'])
        
        if test['should_fail']:
            if not is_valid or has_critical_issues:
                print(f"✅ CORRECTLY REJECTED: Critical issues detected")
                if has_critical_issues:
                    critical_issues = [issue for issue in flow_assessment['issues'] if "CRITICAL" in issue]
                    print(f"   Critical issues: {critical_issues}")
                passed += 1
            else:
                print(f"❌ MISSED CRITICAL ISSUE: Response incorrectly passed")
        else:
            if is_valid and not has_critical_issues:
                print(f"✅ CORRECTLY PASSED: Clean corrected response")
                passed += 1
            else:
                print(f"❌ FALSE POSITIVE: Corrected response incorrectly rejected")
                if has_critical_issues:
                    print(f"   False critical issues: {[issue for issue in flow_assessment['issues'] if 'CRITICAL' in issue]}")
    
    print(f"\\n📊 Real-World Examples: {passed}/{len(test_cases)} tests passed")
    return passed == len(test_cases)

def main():
    """Run all critical fix tests."""
    print("🚨 CRITICAL FIXES VALIDATION")
    print("=" * 60)
    print("Testing fixes for AI indicators, third-person self-reference,")
    print("and conversation engagement issues.\\n")
    
    results = []
    
    # Run all test suites
    results.append(test_ai_indicator_detection())
    results.append(test_third_person_self_reference())
    results.append(test_conversation_engagement())
    results.append(test_real_world_problematic_examples())
    
    # Summary
    passed_suites = sum(results)
    total_suites = len(results)
    
    print(f"\\n🎯 FINAL RESULTS")
    print("=" * 60)
    print(f"Test Suites Passed: {passed_suites}/{total_suites}")
    
    if passed_suites == total_suites:
        print("🎉 ALL CRITICAL FIXES WORKING! The system should now:")
        print("   • Block all AI indicators and meta-references")
        print("   • Prevent third-person self-reference")
        print("   • Ensure characters engage with conversation")
        print("   • Maintain natural conversation flow")
    elif passed_suites >= total_suites * 0.8:
        print("✅ MOSTLY WORKING! Some minor issues to address.")
    else:
        print("⚠️ NEEDS IMPROVEMENT! Several critical issues remain.")
    
    print(f"\\nOverall Success Rate: {(passed_suites/total_suites)*100:.1f}%")
    
    return passed_suites == total_suites

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 