# RAG Crawler Service Dockerfile
# Handles web scraping and vector database population
FROM python:3.9-slim

# Set working directory
WORKDIR /app

# Install system dependencies for web scraping and ML
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    wget \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements file
COPY requirements-rag-crawler.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements-rag-crawler.txt

# Copy the application source code
COPY src/ ./src/

# Create a non-root user for security
RUN useradd -m -u 1004 ragcrawler && chown -R ragcrawler:ragcrawler /app
USER ragcrawler

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONPATH=/app:/app/src

# Expose the service port
EXPOSE 5009

# Health check endpoint
HEALTHCHECK --interval=60s --timeout=30s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:5009/health || exit 1

# Start the RAG crawler service
CMD ["gunicorn", "--preload", "--timeout", "120", "-w", "1", "-b", "0.0.0.0:5009", "src.app.rag_crawler.crawler_service:app"] 