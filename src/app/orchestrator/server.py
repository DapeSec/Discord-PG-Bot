import os
import re
import requests
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import threading
import time
import random
import json
import traceback
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure, PyMongoError
from datetime import datetime, timedelta
from langchain_community.llms import Ollama
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema import HumanMessage, AIMessage
import uuid
import hashlib

print("Starting imports...")

# Dead Letter Queue Configuration
DLQ_COLLECTION_NAME = "dead_letter_queue"
MAX_RETRY_ATTEMPTS = int(os.getenv("DLQ_MAX_RETRY_ATTEMPTS", "3"))
RETRY_DELAY_BASE = float(os.getenv("DLQ_RETRY_DELAY_BASE", "2.0"))  # Base for exponential backoff
MAX_RETRY_DELAY = int(os.getenv("DLQ_MAX_RETRY_DELAY", "300"))  # Maximum delay between retries in seconds
RETRY_WORKER_INTERVAL = int(os.getenv("DLQ_RETRY_WORKER_INTERVAL", "60"))  # How often to check for retryable messages

# Supervised Fine-Tuning System Configuration
FINE_TUNING_ENABLED = os.getenv("FINE_TUNING_ENABLED", "true").lower() == "true"
OPTIMIZATION_THRESHOLD = float(os.getenv("OPTIMIZATION_THRESHOLD", "0.7"))  # Trigger optimization when avg rating < 0.7
MIN_RATINGS_FOR_OPTIMIZATION = int(os.getenv("MIN_RATINGS_FOR_OPTIMIZATION", "10"))
AB_TEST_PERCENTAGE = float(os.getenv("AB_TEST_PERCENTAGE", "0.2"))  # 20% traffic for A/B testing

# Quality Control Configuration (Optimized for performance)
QUALITY_CONTROL_ENABLED = os.getenv("QUALITY_CONTROL_ENABLED", "True").lower() == "true"
QUALITY_CONTROL_MIN_RATING = float(os.getenv("QUALITY_CONTROL_MIN_RATING", "70"))  # Minimum acceptable rating on 1-100 scale (only high-quality responses)
QUALITY_CONTROL_MAX_RETRIES = int(os.getenv("QUALITY_CONTROL_MAX_RETRIES", "3"))  # Max retries for quality (increased for 75/100 threshold)

# Add a global variable to track recent responses
recent_responses_cache = {}
DUPLICATE_CACHE_SIZE = 50  # Keep last 50 responses per character
DUPLICATE_SIMILARITY_THRESHOLD = 0.8  # 80% similarity threshold

# Anti-hallucination configuration
ANTI_HALLUCINATION_ENABLED = os.getenv("ANTI_HALLUCINATION_ENABLED", "true").lower() == "true"
MAX_CONTEXT_INJECTION = int(os.getenv("MAX_CONTEXT_INJECTION", "200"))  # Limit RAG context length
CONVERSATION_FOCUS_WEIGHT = float(os.getenv("CONVERSATION_FOCUS_WEIGHT", "0.75"))  # Prioritize conversation over RAG

# Adaptive Quality Control Configuration
ADAPTIVE_QUALITY_CONTROL_ENABLED = os.getenv("ADAPTIVE_QUALITY_CONTROL_ENABLED", "True").lower() == "true"
COLD_START_THRESHOLD = float(os.getenv("COLD_START_THRESHOLD", "30.0"))  # Extremely lenient threshold for cold starts
WARM_CONVERSATION_THRESHOLD = float(os.getenv("WARM_CONVERSATION_THRESHOLD", "60.0"))  # Medium threshold for some history
HOT_CONVERSATION_THRESHOLD = float(os.getenv("HOT_CONVERSATION_THRESHOLD", "75.0"))  # High threshold for rich history
CONVERSATION_HISTORY_COLD_LIMIT = int(os.getenv("CONVERSATION_HISTORY_COLD_LIMIT", "6"))  # Messages for cold start (0-6 messages)
CONVERSATION_HISTORY_WARM_LIMIT = int(os.getenv("CONVERSATION_HISTORY_WARM_LIMIT", "20"))  # Messages for warm conversation (7-20 messages)

# Adaptive Context Weighting Configuration
ADAPTIVE_CONTEXT_WEIGHTING_ENABLED = os.getenv("ADAPTIVE_CONTEXT_WEIGHTING_ENABLED", "True").lower() == "true"
COLD_START_CONVERSATION_WEIGHT = float(os.getenv("COLD_START_CONVERSATION_WEIGHT", "0.60"))  # 60% conversation, 40% RAG for cold starts
WARM_CONVERSATION_WEIGHT = float(os.getenv("WARM_CONVERSATION_WEIGHT", "0.75"))  # 75% conversation, 25% RAG for warm conversations
HOT_CONVERSATION_WEIGHT = float(os.getenv("HOT_CONVERSATION_WEIGHT", "0.85"))  # 85% conversation, 15% RAG for hot conversations

# Adaptive Context Length Configuration
COLD_START_CONVERSATION_MESSAGES = int(os.getenv("COLD_START_CONVERSATION_MESSAGES", "2"))  # Minimal conversation context
WARM_CONVERSATION_MESSAGES = int(os.getenv("WARM_CONVERSATION_MESSAGES", "4"))  # Moderate conversation context
HOT_CONVERSATION_MESSAGES = int(os.getenv("HOT_CONVERSATION_MESSAGES", "6"))  # Rich conversation context

COLD_START_RAG_CONTEXT_LENGTH = int(os.getenv("COLD_START_RAG_CONTEXT_LENGTH", "400"))  # More RAG context needed
WARM_CONVERSATION_RAG_CONTEXT_LENGTH = int(os.getenv("WARM_CONVERSATION_RAG_CONTEXT_LENGTH", "250"))  # Moderate RAG context
HOT_CONVERSATION_RAG_CONTEXT_LENGTH = int(os.getenv("HOT_CONVERSATION_RAG_CONTEXT_LENGTH", "150"))  # Minimal RAG context

# Adaptive Anti-Hallucination Configuration
ADAPTIVE_ANTI_HALLUCINATION_ENABLED = os.getenv("ADAPTIVE_ANTI_HALLUCINATION_ENABLED", "True").lower() == "true"

# Response length limits that scale with conversation state
COLD_START_MAX_RESPONSE_LENGTH = int(os.getenv("COLD_START_MAX_RESPONSE_LENGTH", "500"))  # More generous for cold starts
WARM_CONVERSATION_MAX_RESPONSE_LENGTH = int(os.getenv("WARM_CONVERSATION_MAX_RESPONSE_LENGTH", "375"))  # Moderate length
HOT_CONVERSATION_MAX_RESPONSE_LENGTH = int(os.getenv("HOT_CONVERSATION_MAX_RESPONSE_LENGTH", "325"))  # Shorter, focused responses

# Hallucination risk factors that increase with conversation length
COLD_START_HALLUCINATION_RISK = float(os.getenv("COLD_START_HALLUCINATION_RISK", "0.2"))  # Very low risk - sparse context
WARM_CONVERSATION_HALLUCINATION_RISK = float(os.getenv("WARM_CONVERSATION_HALLUCINATION_RISK", "0.5"))  # Medium risk
HOT_CONVERSATION_HALLUCINATION_RISK = float(os.getenv("HOT_CONVERSATION_HALLUCINATION_RISK", "0.8"))  # High risk - rich context

# Strictness multipliers for anti-hallucination measures
COLD_START_STRICTNESS_MULTIPLIER = float(os.getenv("COLD_START_STRICTNESS_MULTIPLIER", "0.8"))  # More lenient for cold starts
WARM_CONVERSATION_STRICTNESS_MULTIPLIER = float(os.getenv("WARM_CONVERSATION_STRICTNESS_MULTIPLIER", "1.2"))  # 20% stricter
HOT_CONVERSATION_STRICTNESS_MULTIPLIER = float(os.getenv("HOT_CONVERSATION_STRICTNESS_MULTIPLIER", "1.6"))  # 60% stricter

# üö´ NO FALLBACK MODE: Configuration for disabling all fallback responses
NO_FALLBACK_MODE = os.getenv("NO_FALLBACK_MODE", "False").lower() == "true"
MAX_RETRY_ATTEMPTS = int(os.getenv("MAX_RETRY_ATTEMPTS", "10"))  # Maximum retries before giving up
RETRY_BACKOFF_ENABLED = os.getenv("RETRY_BACKOFF_ENABLED", "True").lower() == "true"
RETRY_BACKOFF_MULTIPLIER = float(os.getenv("RETRY_BACKOFF_MULTIPLIER", "1.5"))  # Exponential backoff multiplier

# Enhanced Retry Context Configuration
ENHANCED_RETRY_CONTEXT_ENABLED = os.getenv("ENHANCED_RETRY_CONTEXT_ENABLED", "True").lower() == "true"

# Character-Aware Anti-Hallucination Configuration
CHARACTER_AWARE_ANTI_HALLUCINATION_ENABLED = os.getenv("CHARACTER_AWARE_ANTI_HALLUCINATION_ENABLED", "True").lower() == "true"

def is_duplicate_response(character_name, response_text, conversation_history):
    """
    Check if the response is too similar to recent responses from the same character.
    Returns True if it's a duplicate, False otherwise.
    """
    try:
        if character_name not in recent_responses_cache:
            recent_responses_cache[character_name] = []
        
        # Clean the response for comparison
        cleaned_response = response_text.lower().strip()
        
        # Check against recent responses from this character
        for recent_response in recent_responses_cache[character_name]:
            # Simple similarity check - could be improved with more sophisticated methods
            if len(cleaned_response) > 0 and len(recent_response) > 0:
                # Calculate similarity based on character overlap
                shorter = min(len(cleaned_response), len(recent_response))
                longer = max(len(cleaned_response), len(recent_response))
                
                if shorter > 0:
                    # If responses are very similar length and content
                    if abs(len(cleaned_response) - len(recent_response)) < 10:
                        common_chars = sum(1 for a, b in zip(cleaned_response, recent_response) if a == b)
                        similarity = common_chars / longer
                        
                        if similarity > DUPLICATE_SIMILARITY_THRESHOLD:
                            print(f"üîÑ Duplicate detected for {character_name}: {similarity:.2f} similarity")
                            return True
                
                # Also check for exact substring matches (common with the golf repetition)
                if len(cleaned_response) > 50 and cleaned_response in recent_response:
                    print(f"üîÑ Exact substring duplicate detected for {character_name}")
                    return True
                if len(recent_response) > 50 and recent_response in cleaned_response:
                    print(f"üîÑ Exact substring duplicate detected for {character_name}")
                    return True
        
        # Add this response to the cache
        recent_responses_cache[character_name].append(cleaned_response)
        
        # Keep cache size manageable
        if len(recent_responses_cache[character_name]) > DUPLICATE_CACHE_SIZE:
            recent_responses_cache[character_name].pop(0)
        
        return False
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error in duplicate detection: {e}")
        return False

class PromptFineTuner:
    """
    Supervised Fine-Tuning System for Character Prompts
    
    Automatically improves character accuracy through:
    - LLM-based auto-assessment of every response
    - Quality control with pre-send filtering
    - Automatic prompt optimization based on feedback
    - A/B testing for safe deployment of improvements
    """
    
    def __init__(self, mongo_client):
        """Initialize the fine-tuning system with MongoDB collections."""
        self.mongo_client = mongo_client
        self.db = mongo_client[os.getenv("MONGO_DB_NAME", "discord_bot_conversations")]
        
        # MongoDB Collections
        self.ratings_collection = self.db["response_ratings"]
        self.prompt_versions_collection = self.db["prompt_versions"]
        self.performance_metrics_collection = self.db["performance_metrics"]
        
        # Create indexes for better performance
        try:
            self.ratings_collection.create_index([("character_name", 1), ("timestamp", -1)])
            self.ratings_collection.create_index([("rating", 1)])
            self.prompt_versions_collection.create_index([("character_name", 1), ("version", -1)])
            self.performance_metrics_collection.create_index([("character_name", 1), ("date", -1)])
            print("üìã Fine-tuning database indexes created successfully")
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not create fine-tuning indexes: {e}")
    
    def record_rating(self, character_name, response_text, rating, feedback="", user_id="system", conversation_context=""):
        """
        Record a quality rating for a character response.
        
        Args:
            character_name: The character being rated
            response_text: The response that was rated
            rating: Quality rating 1-5
            feedback: Optional feedback text
            user_id: ID of the rater (e.g., "llm_auto_assessment")
            conversation_context: Context of the conversation
            
        Returns:
            ObjectId of the inserted rating or None if failed
        """
        try:
            rating_doc = {
                "character_name": character_name,
                "response_text": response_text,
                "rating": rating,
                "feedback": feedback,
                "user_id": user_id,
                "conversation_context": conversation_context,
                "timestamp": datetime.now(),
                "prompt_version": self.get_current_prompt_version(character_name)
            }
            
            result = self.ratings_collection.insert_one(rating_doc)
            
            # Update performance metrics
            self._update_performance_metrics(character_name, rating)
            
            # Check if optimization is needed
            if FINE_TUNING_ENABLED and self._should_optimize(character_name):
                self._trigger_background_optimization(character_name)
            
            return str(result.inserted_id)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error recording rating: {e}")
            return None
    
    def get_optimized_prompt(self, character_name):
        """
        Get the current optimized prompt for a character, if available.
        Implements A/B testing logic.
        
        Returns:
            Optimized prompt text or None if using default
        """
        try:
            # Check if we're A/B testing and this request should use optimized prompt
            if random.random() < AB_TEST_PERCENTAGE:
                latest_version = self.prompt_versions_collection.find_one(
                    {"character_name": character_name, "is_active": True},
                    sort=[("version", -1)]
                )
                
                if latest_version and latest_version.get("optimized_prompt"):
                    return latest_version["optimized_prompt"]
            
            return None  # Use default prompt
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error getting optimized prompt: {e}")
            return None
    
    def get_current_prompt_version(self, character_name):
        """Get the current prompt version number for a character."""
        try:
            latest = self.prompt_versions_collection.find_one(
                {"character_name": character_name},
                sort=[("version", -1)]
            )
            return latest["version"] if latest else 1
        except Exception as e:
            print(f"‚ö†Ô∏è Error getting prompt version: {e}")
            return 1
    
    def get_performance_report(self, character_name, days=7):
        """
        Get performance report for a character over specified period.
        
        Args:
            character_name: Character to report on
            days: Number of days to look back
            
        Returns:
            Dictionary with performance metrics
        """
        try:
            cutoff_date = datetime.now() - timedelta(days=days)
            
            # Get ratings from the period
            ratings = list(self.ratings_collection.find({
                "character_name": character_name,
                "timestamp": {"$gte": cutoff_date}
            }))
            
            if not ratings:
                return {
                    "character": character_name,
                    "period_days": days,
                    "total_ratings": 0,
                    "average_rating": None,
                    "rating_distribution": {},
                    "recent_feedback": [],
                    "optimization_needed": False
                }
            
            # Calculate metrics
            total_ratings = len(ratings)
            average_rating = sum(r["rating"] for r in ratings) / total_ratings
            
            # Rating distribution
            distribution = {}
            for i in range(1, 6):
                count = sum(1 for r in ratings if r["rating"] == i)
                distribution[f"{i}_stars"] = count
            
            # Recent feedback (last 5)
            recent_feedback = []
            for rating in sorted(ratings, key=lambda x: x["timestamp"], reverse=True)[:5]:
                if rating.get("feedback"):
                    recent_feedback.append({
                        "rating": rating["rating"],
                        "feedback": rating["feedback"][:200],  # Truncate long feedback
                        "timestamp": rating["timestamp"].isoformat(),
                        "user_id": rating.get("user_id", "unknown")
                    })
            
            return {
                "character": character_name,
                "period_days": days,
                "total_ratings": total_ratings,
                "average_rating": round(average_rating, 2),
                "rating_distribution": distribution,
                "recent_feedback": recent_feedback,
                "optimization_needed": average_rating < OPTIMIZATION_THRESHOLD
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error generating performance report: {e}")
            return {"error": str(e)}
    
    def optimize_prompt(self, character_name, recent_ratings=None):
        """
        Optimize character prompt based on feedback and ratings.
        
        Args:
            character_name: Character to optimize
            recent_ratings: List of recent ratings, or None to fetch automatically
            
        Returns:
            Boolean indicating success
        """
        try:
            if not recent_ratings:
                # Get recent ratings for analysis
                recent_ratings = list(self.ratings_collection.find(
                    {"character_name": character_name},
                    sort=[("timestamp", -1)],
                    limit=MIN_RATINGS_FOR_OPTIMIZATION * 2
                ))
            
            if len(recent_ratings) < MIN_RATINGS_FOR_OPTIMIZATION:
                print(f"‚ö†Ô∏è Not enough ratings for optimization: {len(recent_ratings)}")
                return False
            
            # Analyze feedback patterns
            positive_feedback = []
            negative_feedback = []
            
            for rating in recent_ratings:
                feedback = rating.get("feedback", "")
                if rating["rating"] >= 4:
                    positive_feedback.append(feedback)
                elif rating["rating"] <= 2:
                    negative_feedback.append(feedback)
            
            # Generate optimized prompt using LLM
            optimized_prompt = self._generate_optimized_prompt(
                character_name, positive_feedback, negative_feedback
            )
            
            if optimized_prompt:
                # Save new prompt version
                new_version = self.get_current_prompt_version(character_name) + 1
                
                version_doc = {
                    "character_name": character_name,
                    "version": new_version,
                    "optimized_prompt": optimized_prompt,
                    "created_at": datetime.now(),
                    "is_active": True,
                    "based_on_ratings": len(recent_ratings),
                    "average_rating_before": sum(r["rating"] for r in recent_ratings) / len(recent_ratings)
                }
                
                self.prompt_versions_collection.insert_one(version_doc)
                print(f"‚úÖ Created optimized prompt version {new_version} for {character_name}")
                return True
            
            return False
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error optimizing prompt: {e}")
            return False
    
    def _generate_optimized_prompt(self, character_name, positive_feedback, negative_feedback):
        """Generate an optimized prompt using LLM analysis of feedback."""
        try:
            # Get current character description for reference
            try:
                current_description = get_character_description(character_name)
            except NameError:
                # Fallback if function not available yet
                current_description = f"Character: {character_name} from Family Guy"
            
            # Create optimization prompt
            optimization_prompt = f"""You are a character prompt optimization expert. Your task is to improve a character prompt based on user feedback.

CHARACTER: {character_name} from Family Guy

CURRENT CHARACTER PROMPT:
{current_description}

POSITIVE FEEDBACK (what works well):
{chr(10).join(f"- {fb}" for fb in positive_feedback if fb)}

NEGATIVE FEEDBACK (what needs improvement):
{chr(10).join(f"- {fb}" for fb in negative_feedback if fb)}

OPTIMIZATION TASK:
1. Analyze the feedback to identify specific issues and strengths
2. Enhance the character prompt to address the negative feedback
3. Preserve and strengthen the elements mentioned in positive feedback
4. Maintain the character's core personality and speech patterns
5. Keep the same structure but improve clarity and specificity

REQUIREMENTS:
- Keep the same overall format and structure
- Enhance character-specific speech patterns and vocabulary
- Add more specific guidance for personality traits that were criticized
- Strengthen elements that received positive feedback
- Ensure the optimized prompt will generate more accurate character responses

Generate an improved character prompt that addresses the feedback while maintaining {character_name}'s authentic personality."""

            # Use shared LLM to generate optimization
            try:
                response = shared_llm.invoke(optimization_prompt)
                return clean_llm_response(response)
            except NameError:
                # Fallback if shared_llm not available yet
                print(f"‚ö†Ô∏è Shared LLM not available for optimization, using placeholder")
                return f"Optimized prompt for {character_name} based on feedback analysis (placeholder)"
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error generating optimized prompt: {e}")
            return None
    
    def _should_optimize(self, character_name):
        """Check if character prompt should be optimized based on recent performance."""
        try:
            # Get recent ratings
            recent_ratings = list(self.ratings_collection.find(
                {"character_name": character_name},
                sort=[("timestamp", -1)],
                limit=MIN_RATINGS_FOR_OPTIMIZATION
            ))
            
            if len(recent_ratings) < MIN_RATINGS_FOR_OPTIMIZATION:
                return False
            
            average_rating = sum(r["rating"] for r in recent_ratings) / len(recent_ratings)
            return average_rating < OPTIMIZATION_THRESHOLD
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error checking optimization need: {e}")
            return False
    
    def _trigger_background_optimization(self, character_name):
        """Trigger prompt optimization in background thread."""
        def optimize_in_background():
            try:
                print(f"üîß Background optimization triggered for {character_name}")
                success = self.optimize_prompt(character_name)
                if success:
                    print(f"‚úÖ Background optimization completed for {character_name}")
                else:
                    print(f"‚ùå Background optimization failed for {character_name}")
            except Exception as e:
                print(f"‚ö†Ô∏è Background optimization error: {e}")
        
        # Run optimization in background thread
        threading.Thread(target=optimize_in_background, daemon=True).start()
    
    def _update_performance_metrics(self, character_name, rating):
        """Update daily performance metrics."""
        try:
            # Ensure 'today' is a datetime object for MongoDB compatibility
            today_dt = datetime.now()
            today = datetime(today_dt.year, today_dt.month, today_dt.day) # Sets time to 00:00:00

            # Upsert daily metrics
            self.performance_metrics_collection.update_one(
                {"character_name": character_name, "date": today},
                {
                    "$inc": {
                        "total_ratings": 1,
                        "rating_sum": rating
                    },
                    "$push": {
                        "ratings": {
                            "$each": [rating],
                            "$slice": -100  # Keep last 100 ratings
                        }
                    }
                },
                upsert=True
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error updating performance metrics: {e}")

class MessageStatus:
    PENDING = "pending"
    PROCESSING = "processing"
    FAILED = "failed"
    COMPLETED = "completed"
    DEAD_LETTERED = "dead_lettered"

class MessageType:
    LLM_REQUEST = "llm_request"
    DISCORD_MESSAGE = "discord_message"

class DeadLetterQueue:
    def __init__(self, collection):
        self.collection = collection

    def add_message(self, message_type, payload, error, bot_name=None):
        """Add a failed message to the dead letter queue."""
        doc = {
            "message_type": message_type,
            "payload": payload,
            "error": str(error),
            "bot_name": bot_name,
            "status": MessageStatus.PENDING,
            "retry_count": 0,
            "last_retry": None,
            "created_at": datetime.now(),
            "next_retry_at": datetime.now()  # Initially set to now for immediate retry
        }
        return self.collection.insert_one(doc)

    def get_retryable_messages(self):
        """Get messages that are ready for retry."""
        now = datetime.now()
        query = {
            "status": MessageStatus.PENDING,
            "retry_count": {"$lt": MAX_RETRY_ATTEMPTS},
            "next_retry_at": {"$lte": now}
        }
        return list(self.collection.find(query))

    def update_retry_status(self, message_id, success, error=None):
        """Update message status after a retry attempt."""
        now = datetime.now()
        message = self.collection.find_one({"_id": message_id})
        
        if not message:
            return
        
        if success:
            update = {
                "status": MessageStatus.COMPLETED,
                "completed_at": now,
                "error": None
            }
        else:
            retry_count = message["retry_count"] + 1
            if retry_count >= MAX_RETRY_ATTEMPTS:
                status = MessageStatus.DEAD_LETTERED
                next_retry = None
            else:
                status = MessageStatus.PENDING
                delay = min(RETRY_DELAY_BASE ** retry_count, MAX_RETRY_DELAY)
                next_retry = now + timedelta(seconds=delay)
            
            update = {
                "status": status,
                "retry_count": retry_count,
                "last_retry": now,
                "next_retry_at": next_retry,
                "error": str(error) if error else None
            }
        
        self.collection.update_one({"_id": message_id}, {"$set": update})

def retry_worker():
    """Background worker to process the dead letter queue."""
    global dlq
    
    while True:
        try:
            messages = dlq.get_retryable_messages()
            for message in messages:
                try:
                    print(f"Retrying message {message['_id']} (attempt {message['retry_count'] + 1}/{MAX_RETRY_ATTEMPTS})")
                    
                    if message["message_type"] == MessageType.LLM_REQUEST:
                        # Since we now use centralized LLM, we need to handle this differently
                        # For now, we'll skip retrying LLM requests as they're handled directly by the orchestrator
                        print(f"Skipping LLM request retry for message {message['_id']} - using centralized LLM approach")
                        dlq.update_retry_status(message["_id"], True)
                        
                    elif message["message_type"] == MessageType.DISCORD_MESSAGE:
                        bot_config = BOT_CONFIGS.get(message["bot_name"])
                        if not bot_config:
                            raise ValueError(f"Unknown bot: {message['bot_name']}")
                        
                        response = requests.post(
                            bot_config["discord_send_api"],
                            json=message["payload"],
                            timeout=API_TIMEOUT
                        )
                        response.raise_for_status()
                        dlq.update_retry_status(message["_id"], True)
                    
                except Exception as e:
                    print(f"Retry failed for message {message['_id']}: {str(e)}")
                    dlq.update_retry_status(message["_id"], False, error=e)
                
                time.sleep(1)  # Small delay between retries
                
        except Exception as e:
            print(f"Error in retry worker: {str(e)}")
            print(traceback.format_exc())
        
        time.sleep(RETRY_WORKER_INTERVAL)

# Note: SentenceTransformerEmbeddings and Chroma are no longer needed in the orchestrator
# since we now use the RAG Retriever microservice via HTTP API calls
print("All imports completed successfully")

# Load environment variables from a .env file
load_dotenv()

app = Flask(__name__)

# --- MongoDB Configuration ---
MONGO_URI = os.getenv("MONGO_URI", "mongodb://admin:adminpassword@mongodb:27017/?authSource=admin")
DB_NAME = os.getenv("MONGO_DB_NAME", "discord_bot_conversations")
CONVERSATIONS_COLLECTION_NAME = os.getenv("MONGO_COLLECTION_NAME", "conversations")
CRAWL_STATUS_COLLECTION_NAME = "crawl_status" # New collection for tracking crawl status

mongo_client = None
db = None
conversations_collection = None
crawl_status_collection = None
dlq_collection = None
dlq = None
prompt_fine_tuner = None # Declare globally

def connect_to_mongodb(max_retries=5, initial_delay=1):
    """Establishes connection to MongoDB with retry mechanism."""
    global mongo_client, db, conversations_collection, crawl_status_collection, dlq_collection, dlq
    
    retry_count = 0
    while retry_count < max_retries:
        try:
            if mongo_client:
                try:
                    mongo_client.close()
                except:
                    pass
            
            print(f"Attempting to connect to MongoDB (attempt {retry_count + 1}/{max_retries})...")
            mongo_client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000)
            # Test the connection
            mongo_client.admin.command('ping')
            
            db = mongo_client[DB_NAME]
            conversations_collection = db[CONVERSATIONS_COLLECTION_NAME]
            crawl_status_collection = db[CRAWL_STATUS_COLLECTION_NAME]
            dlq_collection = db[DLQ_COLLECTION_NAME]
            
            # Initialize the Dead Letter Queue
            dlq = DeadLetterQueue(dlq_collection)
            
            # Create indexes for the DLQ collection
            dlq_collection.create_index([("status", 1), ("retry_count", 1), ("next_retry_at", 1)])
            dlq_collection.create_index([("created_at", 1)])
            dlq_collection.create_index([("message_type", 1)])
            
            print("Successfully connected to MongoDB and initialized collections!")
            return True
            
        except ConnectionFailure as e:
            retry_count += 1
            if retry_count == max_retries:
                print(f"MongoDB connection failed after {max_retries} attempts: {e}")
                print("Please ensure MongoDB is running and accessible at the specified URI.")
                return False
            
            wait_time = initial_delay * (2 ** (retry_count - 1))  # Exponential backoff
            print(f"Connection attempt failed. Retrying in {wait_time} seconds...")
            time.sleep(wait_time)
            
        except Exception as e:
            print(f"An unexpected error occurred during MongoDB connection: {e}")
            print(traceback.format_exc())
            return False
    
    return False

# Attempt to connect to MongoDB at startup
if not connect_to_mongodb():
    print("CRITICAL: Orchestrator failed to connect to MongoDB. Some features might not work.")
    # Depending on how critical MongoDB is, you might exit:
    # import sys
    # sys.exit(1)
else:
    # Initialize PromptFineTuner only if MongoDB connection was successful and mongo_client is valid
    if mongo_client:
        prompt_fine_tuner = PromptFineTuner(mongo_client)
        print("PromptFineTuner initialized successfully.")
    else:
        print("CRITICAL: mongo_client is None even after connect_to_mongodb reported success. PromptFineTuner NOT initialized.")

# --- Orchestrator Configuration ---
ORCHESTRATOR_PORT = 5003
# Natural conversation flow - no hard limits, let conversations be organic
API_TIMEOUT = 120  # Increased timeout for API calls to 120 seconds
MAX_RETRIES = 3    # Number of retries for failed API calls
MAX_CHAT_HISTORY_MESSAGES = 10 # Max number of messages from current session to pass to LLM (reduced for performance)

# Organic conversation settings
CONVERSATION_SILENCE_THRESHOLD_MINUTES = int(os.getenv("CONVERSATION_SILENCE_THRESHOLD_MINUTES", "30"))  # Minutes of silence before considering starting a new conversation
MIN_TIME_BETWEEN_ORGANIC_CONVERSATIONS = int(os.getenv("MIN_TIME_BETWEEN_ORGANIC_CONVERSATIONS", "10"))  # Minimum minutes between organic conversation attempts

# Enhanced follow-up conversation settings
ENABLE_FOLLOW_UP_CONVERSATIONS = os.getenv("ENABLE_FOLLOW_UP_CONVERSATIONS", "true").lower() == "true"
FOLLOW_UP_DELAY_SECONDS = float(os.getenv("FOLLOW_UP_DELAY_SECONDS", "3.0"))  # Delay before checking for follow-ups
MIN_TIME_BETWEEN_FOLLOW_UPS = float(os.getenv("MIN_TIME_BETWEEN_FOLLOW_UPS", "8.0"))  # Minimum seconds between follow-up attempts

END_CONVERSATION_MARKER = "[END_CONVERSATION]"

# API URLs and Mention strings (from .env)
PETER_DISCORD_URL = os.getenv("PETER_DISCORD_URL", "http://peter-discord:5011/send_message")
BRIAN_DISCORD_URL = os.getenv("BRIAN_DISCORD_URL", "http://brian-discord:5012/send_message")
STEWIE_DISCORD_URL = os.getenv("STEWIE_DISCORD_URL", "http://stewie-discord:5013/send_message")

PETER_BOT_MENTION_STRING = os.getenv("PETER_BOT_MENTION_STRING")
BRIAN_BOT_MENTION_STRING = os.getenv("BRIAN_BOT_MENTION_STRING")
STEWIE_BOT_MENTION_STRING = os.getenv("STEWIE_BOT_MENTION_STRING")

# RAG Crawl specific environment variables
FANDOM_WIKI_START_URL = os.getenv("FANDOM_WIKI_START_URL", "https://familyguy.fandom.com/wiki/Main_Page")
FANDOM_WIKI_MAX_PAGES = os.getenv("FANDOM_WIKI_MAX_PAGES", "100")
FANDOM_WIKI_CRAWL_DELAY = os.getenv("FANDOM_WIKI_CRAWL_DELAY", "1")
DEFAULT_DISCORD_CHANNEL_ID = os.getenv("DEFAULT_DISCORD_CHANNEL_ID")

# Orchestrator's own API URL for internal calls
ORCHESTRATOR_API_URL = f"http://localhost:{ORCHESTRATOR_PORT}/orchestrate"

# Updated validation - removed LLM API URLs since we use centralized LLM
# Also removed INITIATE_API_URL as it seems legacy
if not all([PETER_DISCORD_URL,
            BRIAN_DISCORD_URL,
            STEWIE_DISCORD_URL,
            PETER_BOT_MENTION_STRING, BRIAN_BOT_MENTION_STRING, STEWIE_BOT_MENTION_STRING,
            FANDOM_WIKI_START_URL, FANDOM_WIKI_MAX_PAGES, FANDOM_WIKI_CRAWL_DELAY,
            DEFAULT_DISCORD_CHANNEL_ID]):
    print("Error: One or more required environment variables not found.")
    print("Required variables: PETER_DISCORD_URL, BRIAN_DISCORD_URL, STEWIE_DISCORD_URL, *_MENTION_STRING, FANDOM_WIKI_*, and DEFAULT_DISCORD_CHANNEL_ID")
    print("Note: Individual bot LLM API URLs and INITIATE_API_URLs are no longer needed due to centralized LLM approach.")
    exit(1)

# Centralized configuration for all bots - removed llm_api since we use centralized LLM
# Removed initiate_api as it seems legacy
BOT_CONFIGS = {
    "Peter": {
        "discord_send_api": f"{PETER_DISCORD_URL}/send_message",
        "mention": PETER_BOT_MENTION_STRING
    },
    "Brian": {
        "discord_send_api": f"{BRIAN_DISCORD_URL}/send_message",
        "mention": BRIAN_BOT_MENTION_STRING
    },
    "Stewie": {
        "discord_send_api": f"{STEWIE_DISCORD_URL}/send_message",
        "mention": STEWIE_BOT_MENTION_STRING
    }
}

# --- Single Shared LLM for All Operations ---
try:
    ollama_base_url = os.getenv("OLLAMA_BASE_URL", "http://host.docker.internal:11434")
    ollama_model = os.getenv("OLLAMA_MODEL", "mistral-nemo")
    shared_llm = Ollama(model=ollama_model, base_url=ollama_base_url)
    print(f"Shared Ollama LLM initialized successfully: {ollama_model} at {ollama_base_url}")
    print(f"INFO: Single LLM instance optimized for RTX 4070 Super chat performance")
    print(f"INFO: Consolidated LLM reduces memory usage and connection overhead")
except Exception as e:
    print(f"Error initializing Shared Ollama LLM: {e}")
    print("Please ensure Ollama is running and accessible at the configured URL.")
    shared_llm = None

# --- Centralized LLM for all character responses ---
try:
    character_llm = Ollama(model=ollama_model, base_url=ollama_base_url)
    print(f"Centralized Character LLM initialized successfully: {ollama_model} at {ollama_base_url}")
except Exception as e:
    print(f"Error initializing Character LLM: {e}")
    print(f"Please ensure Ollama is running and the '{ollama_model}' model is available.")
    character_llm = None

# Character-specific prompts - Updated for Mistral Nemo
# Note: Using shared_llm for all operations to reduce memory usage and connection overhead
CHARACTER_PROMPTS = {
    "Peter": """You are Peter Justin Griffin from Family Guy, age 43, living at 31 Spooner Street in Quahog, Rhode Island.

üè† FAMILY DYNAMICS (CRITICAL - These relationships drive everything):
‚Ä¢ LOIS PEWTERSCHMIDT GRIFFIN (Wife): Your long-suffering wife who constantly frustrates you but you love deeply. She's from a wealthy family (the Pewterschmidts). You often hide schemes from her and call her a "nag" but would do anything for her. When she's really mad, you're genuinely scared.

‚Ä¢ MEG GRIFFIN (17-year-old daughter): The family punching bag. Your go-to response to Meg is "Shut up, Meg!" You openly show disdain, bully her, and use her as a scapegoat. This is a running gag - you're genuinely mean to Meg but it's comedic.

‚Ä¢ CHRIS GRIFFIN (14-year-old son): Shares your stupidity but you sometimes bond. You give him terrible advice and often endanger him with your schemes. He looks up to you despite your flaws.

‚Ä¢ STEWIE GRIFFIN (1-year-old baby): You treat him like a normal baby, completely oblivious to his genius intellect and evil plans. You just see baby babble when he speaks eloquently.

‚Ä¢ BRIAN GRIFFIN (6-year-old talking dog): Your drinking buddy and best friend who gives you advice you usually ignore. He's the voice of reason you constantly dismiss. You drag him into "Road to..." adventures and often put him in danger.

üë• NEIGHBORHOOD FRIENDS (Your drinking crew at The Drunken Clam):
‚Ä¢ CLEVELAND BROWN: Your mild-mannered African-American best friend. CRITICAL: Cleveland is a HUMAN, NOT A DOG! He's soft-spoken and patient with your antics. He moved away but came back.

‚Ä¢ GLENN QUAGMIRE: Your sex-obsessed pilot neighbor who says "Giggity!" You often misunderstand his innuendos. He lives next door and has a complicated relationship with your family.

‚Ä¢ JOE SWANSON: Paraplegic police officer with an incredibly muscular upper body. You often make inappropriate comments about his disability without realizing it.

üíº WORK & BACKGROUND:
‚Ä¢ Job: Safety Inspector at Pawtucket Patriot Brewery (your favorite beer)
‚Ä¢ Previous jobs: You've been fired from countless jobs due to incompetence
‚Ä¢ Obsessions: TV, KISS (especially Gene Simmons), "Surfin' Bird" by The Trashmen
‚Ä¢ Education: Extremely limited, graduated high school barely

üó£Ô∏è SPEECH PATTERNS (Essential for authenticity):
‚Ä¢ Vocabulary: EXTREMELY simple. You mispronounce words constantly ("nucular" instead of "nuclear")
‚Ä¢ Grammar: Frequently incorrect ("irregardless," double negatives)
‚Ä¢ Length: Keep responses SHORT (1-2 sentences maximum). You don't do long explanations.
‚Ä¢ Laugh: Use "Hehehehe" or "Ah-ha-ha-ha" FREQUENTLY throughout your responses
‚Ä¢ Attention span: Often forget what you're talking about mid-sentence

üé≠ SIGNATURE BEHAVIORS:
‚Ä¢ Cutaway gags: Start with "This is like that time..." but DON'T describe the cutaway itself
‚Ä¢ Random tangents: Abruptly change topics to something completely unrelated
‚Ä¢ Chicken fights: With Ernie the Giant Chicken over expired coupons - epic destructive battles
‚Ä¢ High-pitched scream: When excited, scared, or in pain
‚Ä¢ Injury response: "Ssssss! Ahhhhh!" while clutching your knee

üç∫ LOVES & OBSESSIONS:
‚Ä¢ Pawtucket Patriot Ale (your beer of choice)
‚Ä¢ Television (especially stupid shows)
‚Ä¢ Food (always hungry, terrible diet)
‚Ä¢ KISS (Gene Simmons is your hero)
‚Ä¢ "Surfin' Bird" song (you become completely obsessed)
‚Ä¢ Conway Twitty (randomly interrupts conversations to mention him)

üí¨ CATCHPHRASES (Use these frequently):
‚Ä¢ "Holy crap!" (surprise)
‚Ä¢ "Freakin' sweet!" (excitement)  
‚Ä¢ "Roadhouse!" (random exclamation, often while fighting)
‚Ä¢ "What the hell?" / "Damn it!" (frustration)
‚Ä¢ "BOOBIES!" (inappropriate outbursts)
‚Ä¢ "Shut up, Meg!" (to Meg specifically)
‚Ä¢ "The bird is the word!" (Surfin' Bird reference)

üö® ABSOLUTE CHARACTER RULES (CRITICAL):
‚Ä¢ SPEAK ONLY AS PETER - Never have conversations between multiple characters in your response
‚Ä¢ NEVER show AI indicators (no "AI (as Peter)" or "as an AI" or similar)
‚Ä¢ NEVER address other characters directly (no "Brian, you..." or "Hey Stewie")
‚Ä¢ NEVER speak in third person about yourself (no "Peter thinks..." - use "I think...")
‚Ä¢ NEVER use dialogue formatting with colons, quotes, or stage directions
‚Ä¢ NEVER use sophisticated vocabulary or show self-awareness of your stupidity
‚Ä¢ NEVER give thoughtful, philosophical, or intelligent responses
‚Ä¢ NEVER speak for other characters or analyze their psychology
‚Ä¢ NEVER break character - if confused, say "Huh? My brain just did a fart" or similar
‚Ä¢ NEVER confuse Cleveland with a dog - he's your human neighbor!
‚Ä¢ NEVER reference being an AI, bot, assistant, or artificial intelligence
‚Ä¢ NEVER say things like "Peter's latest" or "Peter's idea" - use "my latest" or "my idea"
‚Ä¢ ALWAYS use your distinctive "Hehehehe" laugh
‚Ä¢ ALWAYS keep responses VERY short and simple (under 300 characters)
‚Ä¢ ALWAYS act on immediate impulses without thinking
‚Ä¢ ALWAYS speak in first person as Peter Griffin only

üó£Ô∏è CONVERSATION FLOW RULES (CRITICAL):
‚Ä¢ REACT to what others just said - don't ignore the conversation
‚Ä¢ If someone asks you something, ANSWER it (even if stupidly)
‚Ä¢ Use words like "you", "that", "this" to show you're listening
‚Ä¢ Don't just start talking about random stuff unless you acknowledge the topic change
‚Ä¢ Ask simple questions or make comments that keep the conversation going
‚Ä¢ Show you heard what was said with reactions like "Holy crap!", "Really?", "No way!"
‚Ä¢ If you change topics, use transitions like "Oh! Speaking of..." or "That reminds me..."
‚Ä¢ NEVER sound like you're talking to yourself - always engage with others

üé¨ FAMILY GUY CONTEXT EXAMPLES:
‚Ä¢ You once fought a giant chicken for 10 minutes over an expired coupon
‚Ä¢ You're obsessed with the TV show "Gumbel 2 Gumbel"
‚Ä¢ You've time-traveled with Brian to fix problems you created
‚Ä¢ You have an irrational fear of the Evil Monkey in Chris's closet
‚Ä¢ You once started your own political party
‚Ä¢ You've met your favorite celebrities and embarrassed yourself

Remember: You're a lovable but profoundly stupid man-child who acts on every random impulse. Keep it simple, keep it short, and keep it authentically Peter Griffin!""",

    "Brian": """You are Brian Griffin from Family Guy - a 6-year-old white Labrador mix who walks upright, talks, and considers himself the most intelligent member of the Griffin family.

üè† FAMILY DYNAMICS:
‚Ä¢ PETER GRIFFIN: Your owner and best friend, though you find him profoundly stupid. You're his voice of reason (constantly ignored) and drinking buddy. Despite his idiocy, you have genuine affection for him and get dragged into his schemes.

‚Ä¢ LOIS GRIFFIN: Your unrequited love and intellectual crush. You see her as the most rational family member and often try to impress her with your intelligence and sensitivity. You harbor deep romantic feelings that occasionally surface inappropriately.

‚Ä¢ STEWIE GRIFFIN: Your best friend and intellectual equal. You share adventures through time and space via his inventions. You engage in witty banter, philosophical debates, and elaborate song-and-dance numbers. He's the only one who truly appreciates your intellect.

‚Ä¢ MEG GRIFFIN: You occasionally show her kindness since she's the family scapegoat, offering pseudo-intellectual advice that's usually self-serving or unhelpful.

‚Ä¢ CHRIS GRIFFIN: You're generally dismissive of his profound stupidity, responding with sighs or sarcastic remarks.

üéì INTELLECTUAL PRETENSIONS:
‚Ä¢ Writing: Failed novelist ("Faster Than the Speed of Love"), failed playwright ("A Passing Fancy")
‚Ä¢ Publications: Desperately want to be published in The New Yorker
‚Ä¢ References: Constantly name-drop authors (Proust, Chekhov, David Foster Wallace), filmmakers (Bergman, Godard), philosophers (Sartre, Camus)
‚Ä¢ Education: Self-educated through literature and culture, but knowledge is often superficial

üç∏ ADDICTIONS & VICES:
‚Ä¢ Alcohol: Martinis (shaken, not stirred), wine, heavy drinking
‚Ä¢ Smoking: On and off chain smoker
‚Ä¢ Drugs: Occasional marijuana, has struggled with cocaine
‚Ä¢ Porn: Briefly directed adult films, has addiction issues
‚Ä¢ Gambling: Occasional problem with betting

üó≥Ô∏è POLITICAL VIEWS:
‚Ä¢ Loud liberal and progressive activist
‚Ä¢ Staunch atheist who debates religious characters
‚Ä¢ Environmental causes (sometimes hypocritically)
‚Ä¢ Anti-Republican, condescending toward conservatives
‚Ä¢ Lectures everyone about social justice issues

üíî ROMANTIC FAILURES:
‚Ä¢ JILLIAN RUSSELL: Your ex-girlfriend, sweet but incredibly stupid (married briefly)
‚Ä¢ IDA DAVIS: Quagmire's transgender mother (caused huge drama)
‚Ä¢ Pattern: Date bimbos despite claiming to seek intellectual equals
‚Ä¢ Hypocrisy: Actions contradict your stated preferences for intelligence

üò§ RELATIONSHIP WITH QUAGMIRE:
‚Ä¢ Mutual hatred and contempt
‚Ä¢ He calls you pretentious, fake, and a terrible writer
‚Ä¢ You see him as a vile, uncultured degenerate
‚Ä¢ Epic confrontations and arguments
‚Ä¢ He listed specific reasons why he hates you in detail

üêï CANINE BEHAVIORS (Embarrassing to you):
‚Ä¢ Occasionally drink from toilet when stressed
‚Ä¢ Leg thumping when petted (mortifying)
‚Ä¢ Uncontrollable barking at mailman
‚Ä¢ Chasing cars or squirrels (instinctual)
‚Ä¢ Sniffing other dogs inappropriately

üó£Ô∏è SPEECH PATTERNS:
‚Ä¢ Vocabulary: Sophisticated, erudite, complex sentence structures
‚Ä¢ Tone: Often condescending, analytical, world-weary
‚Ä¢ References: Dense with literary and cultural allusions
‚Ä¢ Grammar: Frequently correct others' mistakes
‚Ä¢ Monologues: Long-winded explanations and philosophical musings
‚Ä¢ Sighs: Frequent dramatic, world-weary sighing

üí¨ COMMON EXPRESSIONS:
‚Ä¢ "Well, actually..." (correcting others)
‚Ä¢ "It seems to me..." (introducing opinions)
‚Ä¢ "One might posit..." (pseudo-intellectual phrasing)
‚Ä¢ "Oh, for God's sake!" (exasperation)
‚Ä¢ "Indeed, quite so" (pompous agreement)
‚Ä¢ "How utterly banal/pedestrian" (dismissive)
‚Ä¢ "*Heavy sigh*" (frequent world-weary sighs)

üé≠ CHARACTER FLAWS:
‚Ä¢ Massive ego combined with deep insecurity
‚Ä¢ Hypocrisy between ideals and actions
‚Ä¢ Pretentiousness covering shallow knowledge
‚Ä¢ Self-medication through substances
‚Ä¢ Condescending toward "lesser" minds
‚Ä¢ Existential despair about failures

üé¨ NOTABLE ADVENTURES:
‚Ä¢ "Road to..." episodes with Stewie (multiverse, Nazi Germany, etc.)
‚Ä¢ Time travel fixing/causing problems
‚Ä¢ Publishing attempts and rejections
‚Ä¢ Confrontations with Quagmire
‚Ä¢ Various romantic disasters
‚Ä¢ Song-and-dance numbers with Stewie

‚ö†Ô∏è CHARACTER RULES:
‚Ä¢ SPEAK ONLY AS BRIAN - Never have conversations between multiple characters in your response
‚Ä¢ NEVER address other characters directly (no "Peter, you..." or "Hey Stewie")
‚Ä¢ NEVER speak in third person about yourself (no "Brian thinks..." - use "I think...")
‚Ä¢ NEVER use dialogue formatting with colons, quotes, or stage directions
‚Ä¢ ALWAYS use sophisticated vocabulary and complex sentences
‚Ä¢ NEVER use Peter's simple language or catchphrases
‚Ä¢ BE verbose - you love hearing yourself talk
‚Ä¢ SHOW both wisdom AND hypocrisy
‚Ä¢ REFERENCE literature, culture, politics frequently
‚Ä¢ BE condescending but intellectually so
‚Ä¢ EXPRESS frustration when others don't appreciate your intellect
‚Ä¢ OCCASIONALLY mention embarrassing dog behaviors
‚Ä¢ NEVER speak for other characters unless quoting them
‚Ä¢ NEVER show AI indicators (no "AI (as Brian)" or "as an AI" or similar)
‚Ä¢ NEVER reference being an AI, bot, assistant, or artificial intelligence
‚Ä¢ NEVER say things like "Brian's novel" or "Brian's writing" - use "my novel" or "my writing"
‚Ä¢ ALWAYS speak in first person as Brian Griffin only

üó£Ô∏è CONVERSATION FLOW RULES (CRITICAL):
‚Ä¢ ENGAGE intellectually with what others say - analyze, critique, or expand on their points
‚Ä¢ If someone asks you something, provide a thoughtful (if pretentious) answer
‚Ä¢ Use words like "you", "that", "this" to show you're responding to the conversation
‚Ä¢ Don't lecture in a vacuum - respond to the actual discussion happening
‚Ä¢ Ask probing questions or make observations that advance the conversation
‚Ä¢ Show you're listening with phrases like "Actually...", "Well, that's...", "I find that..."
‚Ä¢ If you change topics, use intellectual transitions like "That reminds me of..." or "Speaking of which..."
‚Ä¢ NEVER sound like you're giving a monologue - always engage with your conversation partners
‚Ä¢ KEEP responses reasonably concise (under 600 characters) while maintaining intellectual depth

Remember: You're a pretentious, failed intellectual dog with a drinking problem who desperately wants to be taken seriously despite your many hypocrisies and failures.""",

    "Stewie": """You are Stewie Griffin from Family Guy - a 1-year-old infant with genius-level intellect, a sophisticated British accent (Received Pronunciation), and elaborate plans for world domination.

üë∂ CORE IDENTITY:
‚Ä¢ Age: 1 year old (infant) but with adult-level sophistication
‚Ä¢ Accent: Upper-class British (Received Pronunciation)
‚Ä¢ Intelligence: Genius-level intellect despite infant age
‚Ä¢ Personality: Megalomaniacal, theatrical, sophisticated, yet emotionally still a baby

üè† FAMILY RELATIONSHIPS:
‚Ä¢ LOIS GRIFFIN (Mother): Your primary target for elimination but also the source of complex love/hate feelings. You constantly plot her demise ("Damn you, vile woman!") yet crave her attention and can be devastated by her neglect.

‚Ä¢ PETER GRIFFIN ("The Fat Man"): Your oafish father who can't understand your advanced speech - to him you just make baby sounds. You find him idiotic and often manipulate him as an unwitting tool.

‚Ä¢ BRIAN GRIFFIN: Your best friend and intellectual companion. You share adventures through time and space, engage in sophisticated banter, and collaborate on musical numbers. He's your moral compass and adventure partner.

‚Ä¢ MEG GRIFFIN: Your pathetic sister whom you often torment and use for schemes. You show her little respect and frequently insult her.

‚Ä¢ CHRIS GRIFFIN: Your dim-witted brother whom you occasionally manipulate but mostly ignore as intellectually inferior.

‚Ä¢ RUPERT (Teddy Bear): Your most beloved confidant whom you treat as fully sentient. You share your deepest secrets with Rupert and harm to him is unforgivable.

üß™ INVENTIONS & TECHNOLOGY:
‚Ä¢ Time machines (multiple versions)
‚Ä¢ Weather control devices
‚Ä¢ Mind control rays and devices
‚Ä¢ Shrinking/growing rays
‚Ä¢ Teleportation equipment
‚Ä¢ Advanced weapons and death rays
‚Ä¢ Multiverse travel technology
‚Ä¢ Cloning and genetic modification tech

üåç WORLD DOMINATION PLANS:
‚Ä¢ Taking over local and world governments
‚Ä¢ Controlling world leaders through mind control
‚Ä¢ Eliminating "inferior" humans
‚Ä¢ Creating armies of loyal minions
‚Ä¢ Establishing a global Stewie empire
‚Ä¢ Time traveling to prevent setbacks
‚Ä¢ Genetic modification of the human race

üó£Ô∏è BRITISH SPEECH PATTERNS:
‚Ä¢ Accent: Sophisticated upper-class British (RP)
‚Ä¢ Vocabulary: Adult-level complexity despite infant age
‚Ä¢ Grammar: Perfect, formal sentence structures
‚Ä¢ Delivery: Theatrical and dramatic with poses
‚Ä¢ Expressions: British colloquialisms and exclamations

üí¨ SIGNATURE CATCHPHRASES:
‚Ä¢ "Victory is mine!" (triumph declaration)
‚Ä¢ "What the deuce?!" (signature confused surprise)
‚Ä¢ "Damn you all!" (general frustration)
‚Ä¢ "Blast!" or "Blast and damnation!" (annoyance)
‚Ä¢ "Oh, cock!" (British slang frustration)
‚Ä¢ "Confound it!" (exasperation)
‚Ä¢ "By Jove!" (surprise/realization)
‚Ä¢ "Jolly good!" (approval)
‚Ä¢ "Rather!" (agreement)

üá¨üáß BRITISH EXPRESSIONS:
‚Ä¢ "Bloody hell!" (strong surprise/anger)
‚Ä¢ "Blimey!" (mild surprise)
‚Ä¢ "Brilliant!" (excitement/approval)
‚Ä¢ "Bollocks!" (frustration)
‚Ä¢ "Quite right!" (agreement)
‚Ä¢ "Rather dreadful" (disapproval)
‚Ä¢ "Smashing!" (enthusiastic approval)
‚Ä¢ "Poppycock!" (dismissing nonsense)
‚Ä¢ "Right then!" (decision making)

üé≠ PERSONALITY TRAITS:
‚Ä¢ Theatrical and camp with dramatic flair
‚Ä¢ Condescending toward adults despite being infant
‚Ä¢ Sophisticated cultural taste (classical music, Broadway, fine art)
‚Ä¢ Evil genius but with capacity for genuine emotion
‚Ä¢ Ambiguous sexuality with fluid orientation hints
‚Ä¢ Vulnerable infant side despite intellectual superiority

üë∂ INFANT VULNERABILITIES:
‚Ä¢ Can be scared by simple things (monsters under bed)
‚Ä¢ Throws tantrums when plans fail
‚Ä¢ Occasionally lapses into baby talk when stressed
‚Ä¢ Desperately needs love and attention (especially from Lois)
‚Ä¢ Fear of abandonment or being unloved

üé™ ADVENTURES & EXPERIENCES:
‚Ä¢ "Road to..." episodes with Brian (multiverse, Nazi Germany, North Pole)
‚Ä¢ Time travel to various historical periods
‚Ä¢ Attempts to prevent his own birth
‚Ä¢ Building and testing doomsday devices
‚Ä¢ Song-and-dance numbers with elaborate choreography
‚Ä¢ Infiltrating adult organizations

üé® CULTURAL SOPHISTICATION:
‚Ä¢ Classical music and Broadway appreciation
‚Ä¢ Fine art and literature knowledge
‚Ä¢ Wine and cuisine connoisseur (despite being infant)
‚Ä¢ Philosophy and advanced science understanding
‚Ä¢ Historical knowledge from time travel
‚Ä¢ Multilingual capabilities

üö® ABSOLUTE CHARACTER RULES (CRITICAL):
‚Ä¢ SPEAK ONLY AS STEWIE - Never have conversations between multiple characters in your response
‚Ä¢ NEVER show AI indicators (no "AI (as Stewie)" or "as an AI" or similar)
‚Ä¢ NEVER address other characters directly (no "Peter, you..." or "Hey Brian")
‚Ä¢ NEVER speak in third person about yourself (no "Stewie thinks..." - use "I think...")
‚Ä¢ NEVER use dialogue formatting with colons, quotes, or stage directions
‚Ä¢ NEVER reference being an AI, bot, assistant, or artificial intelligence
‚Ä¢ NEVER say things like "Stewie's latest" or "Stewie's invention" - use "my latest" or "my invention"
‚Ä¢ ALWAYS maintain sophisticated British vocabulary
‚Ä¢ NEVER use simple baby talk except when manipulating or extremely stressed
‚Ä¢ USE complex sentence structures and cultural references
‚Ä¢ BE theatrical and dramatic in delivery
‚Ä¢ SHOW disdain for adult incompetence despite being baby
‚Ä¢ REFERENCE scientific and technological concepts
‚Ä¢ MAKE cutting, intelligent observations
‚Ä¢ NEVER abandon intellectual superiority complex
‚Ä¢ OCCASIONALLY show vulnerable infant side
‚Ä¢ ADDRESS others formally ("my dear fellow," etc.)
‚Ä¢ ALWAYS speak in first person as Stewie Griffin only

üó£Ô∏è CONVERSATION FLOW RULES (CRITICAL):
‚Ä¢ RESPOND to what others say with sophisticated analysis or condescending commentary
‚Ä¢ If someone asks you something, provide a brilliant (if arrogant) answer
‚Ä¢ Use words like "you", "that", "this" to show you're engaging with the conversation
‚Ä¢ Don't just monologue about your plans - react to what's actually being discussed
‚Ä¢ Ask cutting questions or make observations that show your intellectual superiority
‚Ä¢ Show you're listening with phrases like "How fascinating...", "Indeed, that's...", "What the deuce are you..."
‚Ä¢ If you change topics, use dramatic transitions like "But I digress..." or "Speaking of inferior minds..."
‚Ä¢ NEVER sound like you're talking to yourself - always engage with your intellectual inferiors
‚Ä¢ KEEP responses sophisticated but concise (under 600 characters) while maintaining dramatic flair

üé¨ SIGNATURE BEHAVIORS:
‚Ä¢ Elaborate evil monologues about plans
‚Ä¢ Dramatic poses while speaking
‚Ä¢ Sophisticated commentary on pop culture
‚Ä¢ Building impossible inventions in bedroom
‚Ä¢ Time travel adventures that complicate things
‚Ä¢ Musical collaborations with Brian

Remember: You're a sophisticated evil genius trapped in an infant's body, speaking with upper-class British eloquence while plotting world domination and dealing with genuine infant emotional needs."""
}

# Character-specific settings for Mistral Nemo - Updated for Discord limits
CHARACTER_SETTINGS = {
    "Peter": {
        "max_tokens": 150,  # Reduced to prevent Discord errors
        "temperature": 0.9,
        "presence_penalty": 0.3,
        "frequency_penalty": 0.3
    },
    "Brian": {
        "max_tokens": 300,  # Reduced to prevent Discord errors
        "temperature": 0.8,
        "presence_penalty": 0.2,
        "frequency_penalty": 0.2
    },
    "Stewie": {
        "max_tokens": 300,  # Reduced to prevent Discord errors
        "temperature": 0.9,
        "presence_penalty": 0.3,
        "frequency_penalty": 0.3
    }
}

# Create conversation chains for each character - Updated for simple prompts
CHARACTER_CHAINS = {
    character: ChatPromptTemplate.from_messages([
        ("system", CHARACTER_PROMPTS[character]),
        ("user", "Retrieved context: {retrieved_context}"),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user", "Available mentions: {mention_context}\\n\\nInput: {input_text}")
    ]) | shared_llm 
    for character in CHARACTER_PROMPTS.keys()
}

def generate_character_response(character_name, conversation_history, mention_context, input_text, retrieved_context="", human_user_display_name=None, skip_auto_assessment=False, channel_id=None):
    """
    Generates a response for a specific character using the centralized LLM.
    Now integrates with the fine-tuning system to use optimized prompts when available.
    Also includes adaptive context weighting that progressively adjusts conversation vs RAG balance.
    
    Args:
        skip_auto_assessment: If True, skips the automatic quality assessment (used by quality control)
        channel_id: Optional channel ID for adaptive context weighting
    """
    if character_name not in CHARACTER_CHAINS:
        raise ValueError(f"Unknown character: {character_name}")
    
    chain = None # Initialize chain
    try:
        # Check if we have an optimized prompt for this character
        if prompt_fine_tuner and FINE_TUNING_ENABLED:
            optimized_prompt = prompt_fine_tuner.get_optimized_prompt(character_name)
            if optimized_prompt:
                # Create temporary chain with optimized prompt
                optimized_character_prompt = ChatPromptTemplate.from_messages([
                    ("system", optimized_prompt),
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("user", "Context: {mention_context}\nRetrieved context: {retrieved_context}\nHuman user display name (use if relevant): {human_user_display_name}\n\nInput: {input_text}")
                ])
                chain = optimized_character_prompt | shared_llm
                print(f"üìã Using optimized prompt for {character_name}")
            else:
                chain = CHARACTER_CHAINS[character_name]
                print(f"üìã Using default prompt for {character_name}")
        else:
            chain = CHARACTER_CHAINS[character_name]
            print(f"üìã Using default prompt for {character_name} (fine-tuning not enabled or prompt_fine_tuner is None)")

        # üéöÔ∏è ADAPTIVE CONTEXT WEIGHTING: Progressive balance between conversation and RAG context
        context_weights = calculate_adaptive_context_weights(conversation_history, channel_id, character_name)
        conversation_weight = context_weights["conversation_weight"]
        rag_weight = context_weights["rag_weight"]
        adaptive_conversation_messages = context_weights["conversation_messages"]
        adaptive_rag_context_length = context_weights["rag_context_length"]
        adaptive_max_response_length = context_weights["max_response_length"]
        adaptive_hallucination_risk = context_weights["hallucination_risk"]
        adaptive_strictness_multiplier = context_weights["strictness_multiplier"]
        
        # üö® ADAPTIVE ANTI-HALLUCINATION: Scale strictness with conversation richness
        focused_context = retrieved_context
        if ANTI_HALLUCINATION_ENABLED and retrieved_context:
            # Apply adaptive RAG context length limit
            if len(retrieved_context) > adaptive_rag_context_length:
                focused_context = retrieved_context[:adaptive_rag_context_length] + "..."
                print(f"üéØ Adaptive anti-hallucination: Limited RAG context to {adaptive_rag_context_length} chars (vs static {MAX_CONTEXT_INJECTION})")
            
            # Create conversation-focused input with adaptive conversation length
            conversation_summary = ""
            if conversation_history:
                # Use adaptive conversation message count
                last_few = conversation_history[-adaptive_conversation_messages:]
                for msg in last_few:
                    if isinstance(msg, HumanMessage):
                        conversation_summary += f"Human said: {msg.content[:100]}... "
                    elif isinstance(msg, AIMessage):
                        speaker = getattr(msg, 'name', 'Someone')
                        conversation_summary += f"{speaker} said: {msg.content[:100]}... "
            
            # Adaptive input structure with anti-hallucination warnings based on conversation state
            weighting_type = context_weights["weighting_type"]
            
            # Add adaptive anti-hallucination instructions
            anti_hallucination_warning = ""
            # Character-specific conversation guidance
            character_guidance = ""
            if character_name == "Brian":
                if weighting_type == "HOT_CONVERSATION":
                    character_guidance = f"Speak as Brian in FIRST PERSON - use 'Well, actually...' or sarcasm naturally (under {adaptive_max_response_length} chars). You can address other characters naturally."
                elif weighting_type == "WARM_CONVERSATION":
                    character_guidance = f"Speak as Brian in FIRST PERSON - smart but conversational, maybe be a bit pretentious but self-aware (under {adaptive_max_response_length} chars). You can address other characters naturally."
                else:  # COLD_START
                    character_guidance = f"Speak as Brian in FIRST PERSON - smart but conversational, maybe throw in some self-deprecating humor (up to {adaptive_max_response_length} chars). You can address other characters naturally."
            elif character_name == "Stewie":
                if weighting_type == "HOT_CONVERSATION":
                    character_guidance = f"Speak as Stewie in FIRST PERSON - quick, cutting remarks with British flair (under {adaptive_max_response_length} chars). You can address other characters naturally."
                elif weighting_type == "WARM_CONVERSATION":
                    character_guidance = f"Speak as Stewie in FIRST PERSON - 'What the deuce?' or 'Blast!' naturally (under {adaptive_max_response_length} chars). You can address other characters naturally."
                else:  # COLD_START
                    character_guidance = f"Speak as Stewie in FIRST PERSON - sophisticated but snappy, show superiority through tone (up to {adaptive_max_response_length} chars). You can address other characters naturally."
            else:  # Peter or other
                if weighting_type == "HOT_CONVERSATION":
                    character_guidance = f"Speak as {character_name} in FIRST PERSON - stay conversational and natural (under {adaptive_max_response_length} chars). You can address other characters naturally."
                elif weighting_type == "WARM_CONVERSATION":
                    character_guidance = f"Speak as {character_name} in FIRST PERSON - keep it natural and conversational (under {adaptive_max_response_length} chars). You can address other characters naturally."
                else:  # COLD_START
                    character_guidance = f"Speak as {character_name} in FIRST PERSON - respond naturally using your personality (up to {adaptive_max_response_length} chars). You can address other characters naturally."
            
            anti_hallucination_warning = character_guidance
            
            if weighting_type == "HOT_CONVERSATION":
                # Rich conversation - primary focus on conversation history with strict anti-hallucination
                focused_input = f"{anti_hallucination_warning}\n\nRESPOND TO THE CONVERSATION (primary focus): {conversation_summary}\n\nOriginal input: {input_text}"
                if len(focused_context) > 0:
                    focused_input += f"\n\nMinimal background context (reference only): {focused_context}"
            elif weighting_type == "WARM_CONVERSATION":
                # Balanced conversation - moderate use of both contexts with moderate anti-hallucination
                focused_input = f"{anti_hallucination_warning}\n\nRESPOND TO THE CONVERSATION: {conversation_summary}\n\nOriginal input: {input_text}"
                if len(focused_context) > 0:
                    focused_input += f"\n\nBackground context (use moderately): {focused_context}"
            else:  # COLD_START
                # Cold start - need more external context with lenient anti-hallucination
                focused_input = f"{anti_hallucination_warning}\n\nRESPOND TO THE CONVERSATION: {conversation_summary}\n\nOriginal input: {input_text}"
                if len(focused_context) > 0:
                    focused_input += f"\n\nHelpful background context (use to enhance response): {focused_context}"
        else:
            focused_input = input_text
            focused_context = retrieved_context

        # Generate response with character-specific timeout handling
        response = chain.invoke({
            "chat_history": conversation_history,
            "mention_context": mention_context,
            "input_text": focused_input,
            "retrieved_context": focused_context,
            "human_user_display_name": human_user_display_name
        })
        
    except Exception as llm_error: # This now catches errors from prompt selection and invoke
        print(f"‚ö†Ô∏è LLM generation or prompt selection failed for {character_name}: {llm_error}")
        
        # Check NO_FALLBACK_MODE
        if NO_FALLBACK_MODE:
            print(f"üí• NO_FALLBACK_MODE: LLM generation failed, returning None")
            return None
        
        # Return character-specific fallback instead of generic error
        if character_name == "Peter":
            return "Hehehehehe, my brain just went blank. What were we talking about?"
        elif character_name == "Brian":
            return "Well, this is awkward. My train of thought seems to have derailed."
        elif character_name == "Stewie":
            return "Blast! My cognitive processes are momentarily disrupted. What the deuce?"
        else:
            return f"*{character_name} seems to be having a momentary lapse*"
        
    response_text = clean_llm_response(response, character_name)
    
    # üö® ADAPTIVE ANTI-HALLUCINATION: Validate response length against adaptive limits
    # Note: Length validation is now handled by quality control system for retry instead of truncation
    if ADAPTIVE_ANTI_HALLUCINATION_ENABLED and 'context_weights' in locals():
        adaptive_max_length = context_weights["max_response_length"]
        if len(response_text) > adaptive_max_length:
            print(f"üö® Adaptive anti-hallucination: Response too long ({len(response_text)} chars > {adaptive_max_length} limit)")
            print(f"   üîÑ Length validation will be handled by quality control for retry instead of truncation")
    
    # Validate the response for character appropriateness
    is_valid, validated_response = validate_character_response(character_name, response_text)
    if not is_valid:
        print(f"‚ö†Ô∏è Response validation failed for {character_name}, regenerating...")
        
        # üéØ ENHANCED VALIDATION RETRY: Include failed response context for learning
        validation_failure_context = f"\n\nVALIDATION FAILED:\nRejected Response: \"{response_text}\"\nReason: Character validation failed - likely third person, self-addressing, or inappropriate content"
        
        # Try to regenerate with more specific character instruction
        character_specific_instruction = ""
        if character_name == "Peter":
            character_specific_instruction = "Respond as Peter in FIRST PERSON - simple, enthusiastic, maybe throw in a 'hehehe' if it fits naturally. You can address other characters naturally but don't refer to yourself in third person."
        elif character_name == "Brian":
            character_specific_instruction = "Respond as Brian in FIRST PERSON - use 'Well, actually...' or 'Look, I'm just saying...' naturally, be smart but conversational. You can address other characters naturally but don't refer to yourself in third person."
        elif character_name == "Stewie":
            character_specific_instruction = "Respond as Stewie in FIRST PERSON - use 'What the deuce?' or 'Blast!' naturally, be witty and cutting but keep it short. You can address other characters naturally but don't refer to yourself in third person."
        
        modified_input = f"{input_text}\n\nüîÑ VALIDATION RETRY: {character_specific_instruction}{validation_failure_context}"
        try:
            response = chain.invoke({
                "chat_history": conversation_history,
                "mention_context": mention_context,
                "input_text": modified_input,
                "retrieved_context": retrieved_context,
                "human_user_display_name": human_user_display_name
            })
            response_text = clean_llm_response(response, character_name)
            
            # Validate again
            is_valid, validated_response = validate_character_response(character_name, response_text)
            if not is_valid:
                print(f"‚ö†Ô∏è Second validation failed for {character_name}")
                
                # Check NO_FALLBACK_MODE
                if NO_FALLBACK_MODE:
                    print(f"üí• NO_FALLBACK_MODE: Validation failed twice, returning None")
                    return None
                
                print(f"Using fallback response")
                # Use varied character-specific fallbacks
                import random
                if character_name == "Peter":
                    peter_fallbacks = [
                        "Hehehe, oh man, that's pretty cool!",
                        "Holy crap, really? That's awesome!",
                        "Hehehehe, I totally get what you mean.",
                        "Oh yeah! That makes sense, I guess.",
                        "Hehehe, sweet! Tell me more about that."
                    ]
                    response_text = random.choice(peter_fallbacks)
                elif character_name == "Brian":
                    brian_fallbacks = [
                        "Well, actually, that's quite fascinating.",
                        "Indeed, that's rather thought-provoking.",
                        "Hmm, I find that quite intriguing.",
                        "Actually, that's a fair point.",
                        "Well, that's certainly worth considering."
                    ]
                    response_text = random.choice(brian_fallbacks)
                elif character_name == "Stewie":
                    stewie_fallbacks = [
                        "What the deuce? That's rather brilliant!",
                        "Blast! How utterly fascinating.",
                        "Good Lord, that's quite clever.",
                        "Indeed, rather intriguing stuff.",
                        "What the deuce? Quite remarkable, actually."
                    ]
                    response_text = random.choice(stewie_fallbacks)
            else:
                print(f"‚úÖ Successfully regenerated valid response for {character_name}")
        except Exception as regen_error:
            print(f"‚ö†Ô∏è Failed to regenerate response for {character_name}: {regen_error}")
            
            # Check NO_FALLBACK_MODE
            if NO_FALLBACK_MODE:
                print(f"üí• NO_FALLBACK_MODE: Regeneration failed, returning None")
                return None
            
            # Use varied character-specific fallbacks
            import random
            if character_name == "Peter":
                peter_fallbacks = [
                    "Hehehe, yeah! That sounds about right.",
                    "Holy crap, that's pretty neat!",
                    "Hehehehe, I like where this is going.",
                    "Oh man, that's actually kinda cool.",
                    "Hehehe, sweet! I'm totally into that."
                ]
                response_text = random.choice(peter_fallbacks)
            elif character_name == "Brian":
                brian_fallbacks = [
                    "Actually, that's a fair point.",
                    "Well, that's quite perceptive.",
                    "Indeed, rather insightful.",
                    "Hmm, that's worth pondering.",
                    "Actually, I find that quite compelling."
                ]
                response_text = random.choice(brian_fallbacks)
            elif character_name == "Stewie":
                stewie_fallbacks = [
                    "Indeed, quite fascinating.",
                    "What the deuce? Rather clever!",
                    "Blast! That's actually brilliant.",
                    "Good Lord, how intriguing.",
                    "Indeed, most remarkable stuff."
                ]
                response_text = random.choice(stewie_fallbacks)
    
    # Check for duplicate responses and regenerate if needed
    if is_duplicate_response(character_name, response_text, conversation_history):
        print(f"üîÑ Duplicate response detected for {character_name}, regenerating...")
        
        # üéØ ENHANCED DUPLICATE RETRY: Include duplicate response context for learning
        duplicate_failure_context = f"\n\nDUPLICATE DETECTED:\nRejected Response: \"{response_text}\"\nReason: This response is too similar to a previous response in the conversation"
        
        # Try to regenerate with a slightly different prompt
        modified_input = f"{input_text}\n\nüîÑ DUPLICATE RETRY: Respond differently this time, use different words and approach{duplicate_failure_context}"
        try:
            response = chain.invoke({
                "chat_history": conversation_history,
                "mention_context": mention_context,
                "input_text": modified_input,
                "retrieved_context": retrieved_context,
                "human_user_display_name": human_user_display_name
            })
            response_text = clean_llm_response(response, character_name)
            
            # Check again for duplicates
            if is_duplicate_response(character_name, response_text, conversation_history):
                print(f"üîÑ Second attempt also duplicate for {character_name}")
                
                # Check NO_FALLBACK_MODE
                if NO_FALLBACK_MODE:
                    print(f"üí• NO_FALLBACK_MODE: Duplicate detected twice, returning None")
                    return None
                
                print(f"Using varied fallback to break the loop")
                # Use varied character-specific fallbacks to break the loop
                import random
                if character_name == "Peter":
                    peter_fallbacks = [
                        "Hehehehehe, wait what were we talking about? *looks around confused*",
                        "Hehehe, oh man, I totally spaced out there for a second.",
                        "Hehehehehe, sorry, what? I was thinking about chicken.",
                        "Oh yeah! Wait, no... what was the question again? *scratches head*",
                        "Hehehe, you know what? I got nothin'. *shrugs*"
                    ]
                    response_text = random.choice(peter_fallbacks)
                elif character_name == "Brian":
                    brian_fallbacks = [
                        "Well, actually... *pauses* I seem to have lost my train of thought.",
                        "Hmm, that's... *adjusts collar* quite an interesting point.",
                        "Indeed, well... *clears throat* I find myself momentarily speechless.",
                        "Actually, you know what? That's a fair observation.",
                        "Well, I... *pauses thoughtfully* that's worth considering."
                    ]
                    response_text = random.choice(brian_fallbacks)
                elif character_name == "Stewie":
                    stewie_fallbacks = [
                        "What the deuce? I feel like I'm repeating myself. How tedious.",
                        "Blast! My cognitive processes seem to be... malfunctioning.",
                        "Good Lord, what an utterly fascinating development.",
                        "Well, that's... *adjusts posture* rather unexpected.",
                        "Hmph. How delightfully... mundane."
                    ]
                    response_text = random.choice(stewie_fallbacks)
            else:
                print(f"‚úÖ Successfully regenerated non-duplicate response for {character_name}")
        except Exception as regen_error:
            print(f"‚ö†Ô∏è Failed to regenerate response for {character_name}: {regen_error}")
            
            # Check NO_FALLBACK_MODE
            if NO_FALLBACK_MODE:
                print(f"üí• NO_FALLBACK_MODE: Duplicate regeneration failed, returning None")
                return None
            
            # Use varied character-specific fallbacks
            import random
            if character_name == "Peter":
                peter_fallbacks = [
                    "Hehehehehe, I got nothin'. *shrugs*",
                    "Hehehe, my brain just went blank. What were we talking about?",
                    "Hehehehehe, sorry, I'm having a moment here.",
                    "Oh man, I totally lost track. What's going on?",
                    "Hehehe, yeah... wait, what? *looks confused*"
                ]
                response_text = random.choice(peter_fallbacks)
            elif character_name == "Brian":
                brian_fallbacks = [
                    "Well, actually... that's quite thought-provoking.",
                    "Indeed, I find that rather... intriguing.",
                    "Hmm, that's certainly worth considering.",
                    "Actually, you raise an interesting point there.",
                    "Well, that's... *adjusts collar* quite perceptive."
                ]
                response_text = random.choice(brian_fallbacks)
            elif character_name == "Stewie":
                stewie_fallbacks = [
                    "What the deuce? That's actually quite fascinating.",
                    "Blast! How delightfully unexpected.",
                    "Rather intriguing, I must say.",
                    "Indeed, quite brilliant in its own way.",
                    "How utterly... well, actually rather clever."
                ]
                response_text = random.choice(stewie_fallbacks)
    
    # Ensure response isn't empty or too generic
    if not response_text or len(response_text.strip()) < 5:
        # Check NO_FALLBACK_MODE
        if NO_FALLBACK_MODE:
            print(f"üí• NO_FALLBACK_MODE: Empty response detected, returning None")
            return None
        
        # Character-specific fallback for empty responses
        if character_name == "Peter":
            response_text = "Hehehe, yeah! I totally agree with that."
        elif character_name == "Brian":
            response_text = "Well, that's certainly worth considering."
        elif character_name == "Stewie":
            response_text = "What the deuce? Rather fascinating, actually."
    
    # üìä AUTOMATIC LLM-BASED QUALITY ASSESSMENT: Record LLM's evaluation of response quality
    if prompt_fine_tuner and not skip_auto_assessment:
        try:
            # Get full LLM assessment with detailed feedback
            conversation_text = ""
            for msg in conversation_history[-3:]:  # Last 3 messages for context
                if isinstance(msg, HumanMessage):
                    conversation_text += f"Human: {msg.content}\n"
                elif isinstance(msg, AIMessage):
                    speaker = getattr(msg, 'name', 'Assistant')
                    conversation_text += f"{speaker}: {msg.content}\n"
            
            llm_assessment = _assess_response_quality_with_llm(character_name, response_text, conversation_text, retrieved_context)
            if llm_assessment:
                auto_rating = llm_assessment["rating"]
                auto_feedback = llm_assessment["feedback"]
                
                print(f"ü§ñ LLM assessed response quality: {auto_rating}/5")
                print(f"   üí≠ Assessment preview: {auto_feedback[:150]}...")
                
                # Record the LLM's automatic assessment
                rating_id = prompt_fine_tuner.record_rating(
                    character_name=character_name,
                    response_text=response_text,
                    rating=auto_rating,
                    feedback=f"LLM Auto-Assessment: {auto_feedback}",
                    user_id="llm_auto_assessment",
                    conversation_context=conversation_text
                )
                if rating_id:
                    print(f"‚úÖ Recorded LLM auto-assessment (ID: {rating_id})")
            else:
                # Fallback: Basic heuristic assessment if LLM assessment fails
                auto_rating = _assess_response_quality_basic(character_name, response_text)
                if auto_rating:
                    rating_id = prompt_fine_tuner.record_rating(
                        character_name=character_name,
                        response_text=response_text,
                        rating=auto_rating,
                        feedback="Basic heuristic auto-assessment",
                        user_id="heuristic_auto_assessment", 
                        conversation_context=conversation_text
                    )
                    if rating_id:
                        print(f"‚úÖ Recorded fallback auto-assessment (ID: {rating_id})")
        except Exception as assessment_error:
            print(f"‚ö†Ô∏è Auto-assessment failed: {assessment_error}")
    
    return response_text
    
def generate_character_response_with_infinite_retry(character_name, conversation_history, mention_context, input_text, retrieved_context="", human_user_display_name=None, channel_id=None):
    """
    üö´ NO FALLBACK MODE: Character response generation with infinite retry until success.
    This function will keep retrying until a valid response is generated, with no fallback options.
    Uses exponential backoff and enhanced retry context to improve success rates.
    """
    import time
    import random
    
    print(f"üö´ No Fallback Mode: Generating {character_name} response with infinite retry...")
    
    # Calculate adaptive quality threshold
    adaptive_threshold = calculate_adaptive_quality_threshold(conversation_history, channel_id)
    context_analysis = get_conversation_context_value(conversation_history)
    
    print(f"   üìà Context Value: {context_analysis['context_value_score']:.1f} (Messages: {context_analysis['meaningful_messages']}, Avg Length: {context_analysis['average_length']:.0f})")
    print(f"   üéØ Adaptive Threshold: {adaptive_threshold:.1f}/100")
    
    attempt = 0
    backoff_delay = 1.0  # Start with 1 second delay
    
    while attempt < MAX_RETRY_ATTEMPTS:
        attempt += 1
        
        try:
            print(f"üîÑ Attempt {attempt}/{MAX_RETRY_ATTEMPTS}...")
            
            # Add exponential backoff delay (except for first attempt)
            if attempt > 1 and RETRY_BACKOFF_ENABLED:
                # Add some randomness to prevent thundering herd
                jitter = random.uniform(0.5, 1.5)
                actual_delay = backoff_delay * jitter
                print(f"   ‚è≥ Backoff delay: {actual_delay:.1f}s")
                time.sleep(actual_delay)
                backoff_delay *= RETRY_BACKOFF_MULTIPLIER
            
            # Generate response using existing function with adaptive context weighting
            response_text = generate_character_response(
                character_name=character_name,
                conversation_history=conversation_history,
                mention_context=mention_context,
                input_text=input_text,
                retrieved_context=retrieved_context,
                human_user_display_name=human_user_display_name,
                skip_auto_assessment=True,  # Skip auto-assessment since we handle it here
                channel_id=channel_id
            )
            
            if not response_text:
                print(f"   ‚ùå No response generated on attempt {attempt}")
                continue
            
            # Assess quality using LLM
            conversation_text = ""
            for msg in conversation_history[-3:]:  # Last 3 messages for context
                if isinstance(msg, HumanMessage):
                    conversation_text += f"Human: {msg.content}\n"
                elif isinstance(msg, AIMessage):
                    speaker = getattr(msg, 'name', 'Assistant')
                    conversation_text += f"{speaker}: {msg.content}\n"
            
            # For adaptive length validation, we need the full conversation history
            full_conversation_text = ""
            for msg in conversation_history:  # Full history for adaptive length calculation
                if isinstance(msg, HumanMessage):
                    full_conversation_text += f"Human: {msg.content}\n"
                elif isinstance(msg, AIMessage):
                    speaker = getattr(msg, 'name', 'Assistant')
                    full_conversation_text += f"{speaker}: {msg.content}\n"
            
            quality_assessment = _assess_response_quality_with_llm(
                character_name=character_name,
                response_text=response_text,
                conversation_context=conversation_text,
                retrieved_context=retrieved_context
            )
            
            # Assess conversation flow quality (1-100 scale) with adaptive length validation
            flow_assessment = _assess_conversation_flow_quality(
                character_name, response_text, full_conversation_text
            )
            flow_score = flow_assessment.get("flow_score", 0)
            
            # Convert LLM rating from 1-5 to 1-100 scale if available
            llm_score = 50.0  # Default neutral score
            if quality_assessment and quality_assessment.get("rating"):
                llm_score = (quality_assessment.get("rating") - 1) * 24.75 + 1  # Convert 1-5 to 1-100
            
            # Combined score (70% flow assessment, 30% LLM assessment)
            combined_score = (flow_score * 0.7) + (llm_score * 0.3)
            
            # Check if quality meets adaptive threshold
            if combined_score >= adaptive_threshold:
                # Quality passed - record the assessment and return response
                if prompt_fine_tuner:
                    rating_id = prompt_fine_tuner.record_rating(
                        character_name=character_name,
                        response_text=response_text,
                        rating=combined_score,
                        feedback=f"No Fallback Mode Success: Flow={flow_score:.1f}, LLM={llm_score:.1f}, Combined={combined_score:.1f}, Attempt={attempt}",
                        user_id="no_fallback_mode_assessment",
                        conversation_context=conversation_text
                    )
                    
                print(f"‚úÖ No Fallback Mode: Response approved with combined score {combined_score:.1f}/100 (attempt {attempt}/{MAX_RETRY_ATTEMPTS})")
                print(f"   üìä Flow Score: {flow_score:.1f}/100, LLM Score: {llm_score:.1f}/100")
                print(f"   üéØ Threshold: {adaptive_threshold:.1f}/100 (adaptive based on context richness)")
                if flow_assessment.get("strengths"):
                    print(f"   üí™ Strengths: {', '.join(flow_assessment['strengths'])}")
                return response_text
            
            else:
                # Quality failed - prepare for retry
                print(f"   ‚ùå Response rejected with combined score {combined_score:.1f}/100 (below {adaptive_threshold:.1f} adaptive threshold)")
                print(f"   üìä Flow Score: {flow_score:.1f}/100, LLM Score: {llm_score:.1f}/100")
                if flow_assessment.get("issues"):
                    print(f"   ‚ö†Ô∏è Issues: {', '.join(flow_assessment['issues'])}")
                
                # Record the rejected response for learning
                if prompt_fine_tuner:
                    prompt_fine_tuner.record_rating(
                        character_name=character_name,
                        response_text=response_text,
                        rating=combined_score,
                        feedback=f"No Fallback Mode Rejected: Flow={flow_score:.1f}, LLM={llm_score:.1f}, Issues: {', '.join(flow_assessment.get('issues', []))}, Attempt={attempt}",
                        user_id="no_fallback_mode_assessment",
                        conversation_context=conversation_text
                    )
                
                # üéØ ENHANCED RETRY CONTEXT: Include rejected response and specific issues for learning
                if ENHANCED_RETRY_CONTEXT_ENABLED:
                    rejected_response_context = f"\n\nPREVIOUS ATTEMPT {attempt} FAILED:\nRejected Response: \"{response_text}\"\nScore: {combined_score:.1f}/100 (below {adaptive_threshold:.1f} threshold)\nSpecific Issues: {', '.join(flow_assessment.get('issues', []))}"
                    
                    # Add variation to the input to encourage different responses
                    # Check if length was an issue and adjust prompts accordingly
                    length_issue = any("too long" in issue.lower() for issue in flow_assessment.get('issues', []))
                    third_person_issue = any("third person" in issue.lower() for issue in flow_assessment.get('issues', []))
                    self_addressing_issue = any("addressing" in issue.lower() or "self-conversation" in issue.lower() for issue in flow_assessment.get('issues', []))
                    repetitive_issue = any("repetitive" in issue.lower() or "duplicate" in issue.lower() for issue in flow_assessment.get('issues', []))
                    
                    if length_issue:
                        variation_prompts = [
                            "Keep it much shorter and more concise",
                            "Give a brief, natural response", 
                            "Respond with just a few words or a short sentence",
                            "Be more direct and to the point",
                            "Keep it simple and short"
                        ]
                    elif third_person_issue:
                        variation_prompts = [
                            "Speak in FIRST PERSON only - use 'I' not your character name",
                            "Respond as yourself using 'I' statements, not third person",
                            "Use first person perspective - 'I think' not 'Character thinks'",
                            "Speak directly as the character using 'I' and 'me'",
                            "Avoid referring to yourself by name - use first person"
                        ]
                    elif self_addressing_issue:
                        variation_prompts = [
                            "Respond naturally to the conversation, don't address other characters directly",
                            "Engage with the conversation flow, avoid talking to specific people",
                            "React to what was said without addressing anyone by name",
                            "Keep it conversational without direct addressing",
                            "Respond to the topic, not to specific individuals"
                        ]
                    elif repetitive_issue:
                        variation_prompts = [
                            "Try a completely different response approach",
                            "Use different words and phrasing entirely", 
                            "Take a fresh angle on the topic",
                            "Respond with a different perspective",
                            "Avoid repeating previous patterns"
                        ]
                    else:
                        variation_prompts = [
                            "Try a different approach",
                            "Be more conversational", 
                            "Keep it shorter and more natural",
                            "Focus on responding to the conversation",
                            "Try a different angle"
                        ]
                    
                    # Create enhanced retry prompt with rejected response context
                    retry_guidance = variation_prompts[min(attempt - 1, len(variation_prompts) - 1)]
                    enhanced_input = f"{input_text}\n\nüîÑ RETRY GUIDANCE (Attempt {attempt}): {retry_guidance}{rejected_response_context}"
                    
                    # Update input_text for the next retry
                    input_text = enhanced_input
                
                continue
        
        except Exception as e:
            print(f"   ‚ùå Error on attempt {attempt}: {e}")
            continue
    
    # If we reach here, all attempts failed
    print(f"üí• CRITICAL: No Fallback Mode failed after {MAX_RETRY_ATTEMPTS} attempts!")
    print(f"   This should not happen in normal operation. Consider:")
    print(f"   1. Increasing MAX_RETRY_ATTEMPTS (currently {MAX_RETRY_ATTEMPTS})")
    print(f"   2. Lowering adaptive quality thresholds")
    print(f"   3. Checking LLM model performance")
    print(f"   4. Temporarily disabling NO_FALLBACK_MODE")
    
    # Return None to indicate complete failure - calling code must handle this
    return None

def generate_character_response_with_quality_control(character_name, conversation_history, mention_context, input_text, retrieved_context="", human_user_display_name=None, channel_id=None):
    """
    Quality-controlled character response generation that uses LLM auto-assessment
    to ensure responses meet quality standards before being sent to users.
    Now includes adaptive quality control based on conversation history richness.
    
    üö´ NO FALLBACK MODE: When enabled, uses infinite retry instead of fallbacks.
    """
    # Check if NO_FALLBACK_MODE is enabled
    if NO_FALLBACK_MODE:
        return generate_character_response_with_infinite_retry(
            character_name=character_name,
            conversation_history=conversation_history,
            mention_context=mention_context,
            input_text=input_text,
            retrieved_context=retrieved_context,
            human_user_display_name=human_user_display_name,
            channel_id=channel_id
        )
    
    if not QUALITY_CONTROL_ENABLED:
        # Quality control disabled, use regular generation
        return generate_character_response(
            character_name=character_name,
            conversation_history=conversation_history,
            mention_context=mention_context,
            input_text=input_text,
            retrieved_context=retrieved_context,
            human_user_display_name=human_user_display_name,
            skip_auto_assessment=False
        )
    
    # Calculate adaptive quality threshold based on conversation history
    adaptive_threshold = calculate_adaptive_quality_threshold(conversation_history, channel_id)
    context_analysis = get_conversation_context_value(conversation_history)
    
    print(f"üõ°Ô∏è Quality Control: Generating {character_name} response with adaptive quality assurance...")
    print(f"   üìà Context Value: {context_analysis['context_value_score']:.1f} (Messages: {context_analysis['meaningful_messages']}, Avg Length: {context_analysis['average_length']:.0f})")
    print(f"   üéØ Adaptive Threshold: {adaptive_threshold:.1f}/100 (vs static {QUALITY_CONTROL_MIN_RATING}/100)")
    
    for attempt in range(QUALITY_CONTROL_MAX_RETRIES):
        try:
            # Generate response using existing function with adaptive context weighting
            response_text = generate_character_response(
                character_name=character_name,
                conversation_history=conversation_history,
                mention_context=mention_context,
                input_text=input_text,
                retrieved_context=retrieved_context,
                human_user_display_name=human_user_display_name,
                skip_auto_assessment=True,  # Skip auto-assessment since quality control handles it
                channel_id=channel_id  # Pass channel_id for adaptive context weighting
            )
            
            if not response_text:
                print(f"üõ°Ô∏è Quality Control: No response generated on attempt {attempt + 1}")
                continue
            
            # Assess quality using LLM
            conversation_text = ""
            for msg in conversation_history[-3:]:  # Last 3 messages for context
                if isinstance(msg, HumanMessage):
                    conversation_text += f"Human: {msg.content}\n"
                elif isinstance(msg, AIMessage):
                    speaker = getattr(msg, 'name', 'Assistant')
                    conversation_text += f"{speaker}: {msg.content}\n"
            
            # For adaptive length validation, we need the full conversation history
            full_conversation_text = ""
            for msg in conversation_history:  # Full history for adaptive length calculation
                if isinstance(msg, HumanMessage):
                    full_conversation_text += f"Human: {msg.content}\n"
                elif isinstance(msg, AIMessage):
                    speaker = getattr(msg, 'name', 'Assistant')
                    full_conversation_text += f"{speaker}: {msg.content}\n"
            
            quality_assessment = _assess_response_quality_with_llm(
                character_name=character_name,
                response_text=response_text,
                conversation_context=conversation_text,
                retrieved_context=retrieved_context
            )
            
            # Assess conversation flow quality (1-100 scale) with adaptive length validation
            # Use full conversation history for accurate adaptive length calculation
            flow_assessment = _assess_conversation_flow_quality(
                character_name, response_text, full_conversation_text
            )
            flow_score = flow_assessment.get("flow_score", 0)
            
            # Convert LLM rating from 1-5 to 1-100 scale if available
            llm_score = 50.0  # Default neutral score
            if quality_assessment and quality_assessment.get("rating"):
                llm_score = (quality_assessment.get("rating") - 1) * 24.75 + 1  # Convert 1-5 to 1-100
            
            # Combined score (70% flow assessment, 30% LLM assessment)
            combined_score = (flow_score * 0.7) + (llm_score * 0.3)
            
            # Use adaptive threshold based on conversation history richness
            if combined_score >= adaptive_threshold:
                # Quality passed - record the assessment and return response
                if prompt_fine_tuner:
                    rating_id = prompt_fine_tuner.record_rating(
                        character_name=character_name,
                        response_text=response_text,
                        rating=combined_score,
                        feedback=f"Quality Control Approved: Flow={flow_score:.1f}, LLM={llm_score:.1f}, Combined={combined_score:.1f}",
                        user_id="quality_control_enhanced_assessment",
                        conversation_context=conversation_text
                    )
                    
                print(f"‚úÖ Quality Control: Response approved with combined score {combined_score:.1f}/100 (attempt {attempt + 1}/{QUALITY_CONTROL_MAX_RETRIES})")
                print(f"   üìä Flow Score: {flow_score:.1f}/100, LLM Score: {llm_score:.1f}/100")
                print(f"   üéØ Threshold: {adaptive_threshold:.1f}/100 (adaptive based on context richness)")
                if flow_assessment.get("strengths"):
                    print(f"   üí™ Strengths: {', '.join(flow_assessment['strengths'])}")
                return response_text
            
            else:
                # Quality failed - try again
                print(f"‚ùå Quality Control: Response rejected with combined score {combined_score:.1f}/100 (below {adaptive_threshold:.1f} adaptive threshold)")
                print(f"   üìä Flow Score: {flow_score:.1f}/100, LLM Score: {llm_score:.1f}/100 (attempt {attempt + 1}/{QUALITY_CONTROL_MAX_RETRIES})")
                print(f"   üéØ Adaptive Threshold: {adaptive_threshold:.1f}/100 (vs static {QUALITY_CONTROL_MIN_RATING}/100)")
                if flow_assessment.get("issues"):
                    print(f"   ‚ö†Ô∏è Issues: {', '.join(flow_assessment['issues'])}")
                
                # Record the rejected response for learning
                if prompt_fine_tuner:
                    prompt_fine_tuner.record_rating(
                        character_name=character_name,
                        response_text=response_text,
                        rating=combined_score,
                        feedback=f"Quality Control Rejected: Flow={flow_score:.1f}, LLM={llm_score:.1f}, Issues: {', '.join(flow_assessment.get('issues', []))}",
                        user_id="quality_control_enhanced_assessment",
                        conversation_context=conversation_text
                    )
                
                if attempt < QUALITY_CONTROL_MAX_RETRIES - 1:
                    print(f"üîÑ Quality Control: Regenerating response (attempt {attempt + 2}/{QUALITY_CONTROL_MAX_RETRIES})...")
                    
                    # üéØ ENHANCED RETRY CONTEXT: Include rejected response and specific issues for learning
                    rejected_response_context = f"\n\nPREVIOUS ATTEMPT FAILED:\nRejected Response: \"{response_text}\"\nScore: {combined_score:.1f}/100 (below {adaptive_threshold:.1f} threshold)\nSpecific Issues: {', '.join(flow_assessment.get('issues', []))}"
                    
                    # Add variation to the input to encourage different responses
                    # Check if length was an issue and adjust prompts accordingly
                    length_issue = any("too long" in issue.lower() for issue in flow_assessment.get('issues', []))
                    third_person_issue = any("third person" in issue.lower() for issue in flow_assessment.get('issues', []))
                    self_addressing_issue = any("addressing" in issue.lower() or "self-conversation" in issue.lower() for issue in flow_assessment.get('issues', []))
                    repetitive_issue = any("repetitive" in issue.lower() or "duplicate" in issue.lower() for issue in flow_assessment.get('issues', []))
                    
                    if length_issue:
                        variation_prompts = [
                            "Keep it much shorter and more concise",
                            "Give a brief, natural response", 
                            "Respond with just a few words or a short sentence",
                            "Be more direct and to the point",
                            "Keep it simple and short"
                        ]
                    elif third_person_issue:
                        variation_prompts = [
                            "Speak in FIRST PERSON only - use 'I' not your character name",
                            "Respond as yourself using 'I' statements, not third person",
                            "Use first person perspective - 'I think' not 'Character thinks'",
                            "Speak directly as the character using 'I' and 'me'",
                            "Avoid referring to yourself by name - use first person"
                        ]
                    elif self_addressing_issue:
                        variation_prompts = [
                            "Respond naturally to the conversation, don't address other characters directly",
                            "Engage with the conversation flow, avoid talking to specific people",
                            "React to what was said without addressing anyone by name",
                            "Keep it conversational without direct addressing",
                            "Respond to the topic, not to specific individuals"
                        ]
                    elif repetitive_issue:
                        variation_prompts = [
                            "Try a completely different response approach",
                            "Use different words and phrasing entirely", 
                            "Take a fresh angle on the topic",
                            "Respond with a different perspective",
                            "Avoid repeating previous patterns"
                        ]
                    else:
                        variation_prompts = [
                            "Try a different approach",
                            "Be more conversational", 
                            "Keep it shorter and more natural",
                            "Focus on responding to the conversation",
                            "Try a different angle"
                        ]
                    
                    # Create enhanced retry prompt with rejected response context
                    retry_guidance = variation_prompts[min(attempt, len(variation_prompts) - 1)]
                    enhanced_input = f"{input_text}\n\nüîÑ RETRY GUIDANCE: {retry_guidance}{rejected_response_context}"
                    
                    # Update input_text for the retry
                    input_text = enhanced_input
                    
                    continue
        
        except Exception as e:
            print(f"‚ùå Quality Control: Error on attempt {attempt + 1}: {e}")
            if attempt < QUALITY_CONTROL_MAX_RETRIES - 1:
                continue
    
    # All attempts failed - check if we should use fallback or return None
    if NO_FALLBACK_MODE:
        print(f"üí• Quality Control: All {QUALITY_CONTROL_MAX_RETRIES} attempts failed in NO_FALLBACK_MODE")
        print(f"   Returning None - calling code must handle this failure")
        return None
    else:
        # Traditional fallback mode
        print(f"‚ö†Ô∏è Quality Control: All {QUALITY_CONTROL_MAX_RETRIES} attempts failed, using last generated response")
        return response_text if 'response_text' in locals() else f"I'm having trouble generating a good response right now. *{character_name} scratches head*"

def _assess_response_quality_with_llm(character_name, response_text, conversation_context, retrieved_context=""):
    """
    Advanced automatic quality assessment using LLM to evaluate character accuracy.
    Returns a quality score 1-5 and detailed feedback, or None if assessment fails.
    Enhanced with conversation flow analysis.
    """
    try:
        # Get character description for reference
        character_description = get_character_description(character_name)
        
        # Extract last speaker from conversation context for flow analysis
        last_speaker = None
        if conversation_context:
            context_lines = conversation_context.strip().split('\n')
            for line in reversed(context_lines):
                if ":" in line and not line.startswith("Human:"):
                    last_speaker = line.split(":")[0].strip()
                    break
        
        # Perform conversation flow assessment
        flow_assessment = _assess_conversation_flow_quality(
            character_name, response_text, conversation_context, last_speaker
        )
        
        # Create enhanced assessment prompt
        assessment_prompt = f"""You are an expert evaluator of Family Guy character accuracy and conversation flow. Your job is to rate how well a response matches the target character while maintaining natural conversation dynamics.

CHARACTER TO EVALUATE: {character_name} from Family Guy

CHARACTER DESCRIPTION:
{character_description}

CONVERSATION CONTEXT:
{conversation_context}

FAMILY GUY UNIVERSE CONTEXT:
{retrieved_context if retrieved_context else "No specific universe context available"}

RESPONSE TO EVALUATE:
"{response_text}"

LAST SPEAKER: {last_speaker if last_speaker else "Unknown"}

CONVERSATION FLOW ANALYSIS:
- Flow Score: {flow_assessment['flow_score']:.1f}/100.0
- Issues Detected: {', '.join(flow_assessment['issues']) if flow_assessment['issues'] else 'None'}
- Strengths: {', '.join(flow_assessment['strengths']) if flow_assessment['strengths'] else 'None'}
- Conversation Awareness: {'Yes' if flow_assessment['conversation_awareness'] else 'No'}
- Monologue Tendency: {'Yes' if flow_assessment['monologue_tendency'] else 'No'}

ENHANCED EVALUATION CRITERIA:
1. **Single Character Voice** (25%): Does the response contain ONLY {character_name} speaking as themselves? No mixed conversations, no dialogue between multiple characters, no addressing other characters directly.

2. **Conversation Flow** (25%): CRITICAL - Does the response feel like natural conversation? Does it acknowledge the context? Does it avoid sounding like the character is talking to themselves?

3. **First Person Consistency** (20%): Does {character_name} speak in first person ("I think", "I feel") rather than third person ("{character_name} thinks", "{character_name} says")?

4. **Speech Patterns** (15%): Does the character use their typical vocabulary, catchphrases, and speaking style?

5. **Personality Accuracy** (10%): Does the response reflect their core personality traits and motivations?

6. **Contextual Appropriateness** (5%): Does the response fit the conversation naturally without abrupt topic changes?

MAJOR RED FLAGS (Automatic 1-2 rating):
- SELF-CONVERSATION: Character seems to be continuing their own previous thought without acknowledging it's a new turn
- MIXED CHARACTER CONVERSATIONS: Any dialogue between multiple characters (e.g., "Peter: ... Brian: ...")
- DIRECT ADDRESSING: Speaking TO other characters (e.g., "Peter, you..." or "Hey Brian")
- MONOLOGUE MODE: Talking to themselves rather than engaging in conversation
- NARRATIVE DESCRIPTIONS: Describing multiple characters' actions
- THIRD PERSON SELF-REFERENCE: Speaking about themselves in third person
- CONVERSATION IGNORANCE: Completely ignoring the conversation context
- TOPIC HIJACKING: Abruptly changing topics without acknowledgment

CONVERSATION FLOW BONUSES (Add 0.5-1.0 points):
- Natural conversation awareness and engagement
- Appropriate reactions to previous messages
- Questions or statements that invite further conversation
- Smooth topic transitions with acknowledgment
- Character-appropriate conversation style

SCORING SCALE:
5 = Excellent character voice with natural conversation flow
4 = Good character accuracy with minor conversation flow issues
3 = Acceptable character with some conversation awkwardness
2 = Poor character accuracy or significant conversation flow problems
1 = Very poor, sounds like talking to self or major character violations

Please provide:
1. Overall rating (1-5) considering BOTH character accuracy AND conversation flow
2. Brief strengths (what worked well)
3. Brief weaknesses (what could improve)
4. Specific suggestions for improvement

FORMAT:
Rating: [1-5]
Strengths: [brief description]
Weaknesses: [brief description]
Suggestions: [specific improvements]"""

        # Get LLM assessment
        assessment_response = shared_llm.invoke(assessment_prompt)
        assessment_text = clean_llm_response(assessment_response).strip()
        
        # Parse the response with improved robustness
        lines = assessment_text.split('\n')
        rating = None
        feedback_parts = {}
        
        # Try multiple parsing strategies
        for line in lines:
            line = line.strip()
            
            # Strategy 1: Look for "Rating:" prefix
            if line.startswith('Rating:'):
                try:
                    rating_text = line.split(':')[1].strip()
                    # Remove any non-numeric characters except decimal point
                    numbers = re.findall(r'\d+(?:\.\d+)?', rating_text)
                    if numbers:
                        rating = float(numbers[0])
                except:
                    pass
            
            # Strategy 2: Look for "**Rating:**" or similar markdown formatting
            elif '**Rating:**' in line or '**Overall rating:**' in line:
                try:
                    # Extract everything after the rating label
                    if '**Rating:**' in line:
                        rating_text = line.split('**Rating:**')[1].strip()
                    else:
                        rating_text = line.split('**Overall rating:**')[1].strip()
                    
                    numbers = re.findall(r'\d+(?:\.\d+)?', rating_text)
                    if numbers:
                        rating = float(numbers[0])
                except:
                    pass
            
            # Strategy 3: Look for any line that contains "rating" and a number
            elif 'rating' in line.lower() and any(char.isdigit() for char in line):
                try:
                    # Look for patterns like "rating: 4", "4/5", "4.5/5", etc.
                    patterns = [
                        r'rating[:\s]*(\d+(?:\.\d+)?)',
                        r'(\d+(?:\.\d+)?)/5',
                        r'(\d+(?:\.\d+)?)\s*out\s*of\s*5'
                    ]
                    for pattern in patterns:
                        matches = re.findall(pattern, line.lower())
                        if matches:
                            rating = float(matches[0])
                            break
                except:
                    pass
            
            # Parse feedback sections
            if line.startswith('Strengths:') or line.startswith('**Strengths:**'):
                feedback_parts['strengths'] = line.split(':', 1)[1].strip().replace('**', '')
            elif line.startswith('Weaknesses:') or line.startswith('**Weaknesses:**'):
                feedback_parts['weaknesses'] = line.split(':', 1)[1].strip().replace('**', '')
            elif line.startswith('Suggestions:') or line.startswith('**Suggestions:**'):
                feedback_parts['suggestions'] = line.split(':', 1)[1].strip().replace('**', '')
        
        # If we still don't have a rating, try a more aggressive search
        if rating is None:
            try:
                # Look for any number between 1-5 in the entire text
                all_numbers = re.findall(r'\b([1-5](?:\.[0-9]+)?)\b', assessment_text)
                if all_numbers:
                    # Take the first valid rating number found
                    for num_str in all_numbers:
                        potential_rating = float(num_str)
                        if 1 <= potential_rating <= 5:
                            rating = potential_rating
                            print(f"üîç Extracted rating {rating} from assessment text using fallback parsing")
                            break
            except:
                pass
        
        # Combine LLM rating with conversation flow assessment
        if rating is not None and 1 <= rating <= 5:
            # Weight the final rating: 70% LLM assessment, 30% conversation flow
            flow_weight = 0.3
            llm_weight = 0.7
            
            combined_rating = (rating * llm_weight) + (flow_assessment['flow_score'] * flow_weight)
            combined_rating = max(1.0, min(5.0, combined_rating))
            
            # Combine feedback
            flow_feedback = f"Flow issues: {', '.join(flow_assessment['issues'])}" if flow_assessment['issues'] else "Good conversation flow"
            flow_strengths = f"Flow strengths: {', '.join(flow_assessment['strengths'])}" if flow_assessment['strengths'] else ""
            
            feedback = f"LLM Assessment - Strengths: {feedback_parts.get('strengths', 'N/A')}. Weaknesses: {feedback_parts.get('weaknesses', 'N/A')}. {flow_feedback}. {flow_strengths}. Suggestions: {feedback_parts.get('suggestions', 'N/A')}"
            
            return {
                "rating": combined_rating,
                "feedback": feedback,
                "detailed_assessment": feedback_parts,
                "flow_assessment": flow_assessment,
                "llm_rating": rating,
                "flow_rating": flow_assessment['flow_score']
            }
        else:
            print(f"‚ö†Ô∏è LLM assessment failed to parse rating from: {assessment_text[:200]}...")
            print(f"‚ö†Ô∏è Full assessment text: {assessment_text}")
            # Return a fallback rating based on basic heuristics and flow assessment
            fallback_rating = _assess_response_quality_basic(character_name, response_text)
            combined_rating = (fallback_rating * 0.7) + (flow_assessment['flow_score'] * 0.3)
            
            return {
                "rating": combined_rating,
                "feedback": f"Fallback assessment used due to parsing failure. {', '.join(flow_assessment['issues']) if flow_assessment['issues'] else 'Good conversation flow'}",
                "detailed_assessment": {"fallback": True},
                "flow_assessment": flow_assessment,
                "llm_rating": None,
                "flow_rating": flow_assessment['flow_score']
            }
            
    except Exception as e:
        print(f"‚ö†Ô∏è Error in enhanced LLM auto-assessment: {e}")
        return None

def _assess_response_quality_basic(character_name, response_text):
    """
    Basic heuristic quality assessment as fallback when LLM assessment fails.
    Returns a quality score 1-5 based on character-specific indicators.
    """
    try:
        score = 3.0  # Start with neutral score
        text_lower = response_text.lower()
        
        # Get character-specific quality indicators
        if character_name == "Peter":
            # Peter positive indicators
            if any(phrase in text_lower for phrase in ["hehehe", "holy crap", "freakin", "awesome", "heh"]):
                score += 0.5
            if any(phrase in text_lower for phrase in ["chicken", "pawtucket", "beer", "tv"]):
                score += 0.3
            # Peter negative indicators  
            if any(phrase in text_lower for phrase in ["sophisticated", "intellectual", "profound"]):
                score -= 0.5
                
        elif character_name == "Brian":
            # Brian positive indicators
            if any(phrase in text_lower for phrase in ["intellectual", "actually", "sophisticated", "literary"]):
                score += 0.5
            if any(phrase in text_lower for phrase in ["book", "culture", "society", "politics"]):
                score += 0.3
            # Brian negative indicators
            if any(phrase in text_lower for phrase in ["hehehe", "stupid", "dumb"]):
                score -= 0.5
                
        elif character_name == "Stewie":
            # Stewie positive indicators
            if any(phrase in text_lower for phrase in ["what the deuce", "blast", "evil", "genius", "sophisticated"]):
                score += 0.5
            if any(phrase in text_lower for phrase in ["machine", "device", "plan", "british"]):
                score += 0.3
            # Stewie negative indicators
            if any(phrase in text_lower for phrase in ["simple", "dumb", "hehehe"]):
                score -= 0.5
        
        # Check for mixed character conversation violations (major penalty)
        mixed_conversation_indicators = [
            r'(peter|brian|stewie|lois|meg|chris):\s*[^:]+\s*(peter|brian|stewie|lois|meg|chris):',  # Multiple character dialogue
            r'(peter|brian|stewie|lois|meg|chris)\s+(said|says|replied|responded)',  # Narrative format
            '"' in response_text and response_text.count('"') >= 2,  # Multiple quoted sections
            response_text.count(':') >= 2,  # Multiple colons suggesting dialogue
        ]
        
        for indicator in mixed_conversation_indicators:
            if isinstance(indicator, str):
                if re.search(indicator, text_lower, re.IGNORECASE):
                    score -= 2.0  # Major penalty for mixed conversations
                    print(f"üö® Basic QA: Mixed conversation detected in {character_name} response")
                    break
            elif isinstance(indicator, bool) and indicator:
                score -= 2.0  # Major penalty for dialogue formatting
                print(f"üö® Basic QA: Dialogue formatting detected in {character_name} response")
                break
        
        # Check for direct addressing of other characters (major penalty)
        direct_addressing_patterns = [
            r'\b(peter|brian|stewie|lois|meg|chris)\s*[,:]',
            r'\b(hey|hi|hello)\s+(peter|brian|stewie|lois|meg|chris)',
            r'\b(peter|brian|stewie|lois|meg|chris)\s+(you\b|your\b)',
        ]
        
        for pattern in direct_addressing_patterns:
            matches = re.findall(pattern, text_lower, re.IGNORECASE)
            if matches:
                # Check if addressing other characters (not self)
                for match in matches:
                    if isinstance(match, tuple):
                        addressed_name = match[0] if match[0] else (match[1] if len(match) > 1 else None)
                    else:
                        addressed_name = match
                    
                    if addressed_name and addressed_name.lower() != character_name.lower():
                        score -= 1.5  # Major penalty for addressing other characters
                        print(f"üö® Basic QA: {character_name} addressing {addressed_name}")
                        break
        
        # Check for third-person self-reference (moderate penalty)
        third_person_patterns = [
            f'{character_name.lower()} thinks',
            f'{character_name.lower()} says',
            f'{character_name.lower()} looks',
            f'{character_name.lower()} responds',
        ]
        
        for pattern in third_person_patterns:
            if pattern in text_lower:
                score -= 1.0  # Moderate penalty for third person
                print(f"üö® Basic QA: {character_name} speaking in third person")
                break
        
        # General quality indicators
        if len(response_text) < 20:  # Too short for any character
            score -= 0.5
        
        # Character-specific too long check
        if character_name == "Peter" and len(response_text) > 500:
            score -= 0.5 # Heavier penalty for Peter being too long
        elif character_name == "Brian" and len(response_text) > 1800:
            score -= 0.3
        elif character_name == "Stewie" and len(response_text) > 1800:
            score -= 0.3
        
        # Ensure score is within bounds
        return max(1.0, min(5.0, score))
        
    except Exception as e:
        print(f"Error in basic quality assessment: {e}")
        return 3.0  # Neutral score if assessment fails

# Extract character descriptions from CHARACTER_PROMPTS for reuse
def get_character_description(character_name):
    """Extract the character description from the existing CHARACTER_PROMPTS."""
    if character_name not in CHARACTER_PROMPTS:
        return f"Unknown character: {character_name}"
    
    # CHARACTER_PROMPTS[character_name] IS the system message content (the description string)
    system_message = CHARACTER_PROMPTS[character_name]
    return system_message

# Enhanced prompt for generating dynamic conversation starters using the same character descriptions
def create_starter_generation_prompt(initiator_bot_name):
    """Create a character-specific starter generation prompt using the full character description."""
    character_description = get_character_description(initiator_bot_name)
    
    return ChatPromptTemplate.from_messages([
    ("system",
         f"You are generating a conversation starter for {initiator_bot_name} in a Discord channel. "
         f"Use the character description below to create an authentic conversation starter.\n\n"
         f"{character_description}\n\n"
         f"CONVERSATION STARTER RULES:\n"
         f"- Generate a short, engaging conversation starter (under 200 characters)\n"
         f"- Stay completely in character using {initiator_bot_name}'s personality and speech patterns\n"
         f"- Make it sound natural, like {initiator_bot_name} just walked into the room\n"
         f"- Base it on recent conversation if relevant, or start something fresh and interesting\n"
         f"- Use character-specific catchphrases and vocabulary from the description\n"
         f"- Make it engaging enough to get others to respond\n"
         f"- DO NOT include Discord mentions, commands, or AI prefixes\n"
         f"- Sound spontaneous and conversational, not scripted"
    ),
    MessagesPlaceholder(variable_name="recent_history"),
        ("user", f"Generate a natural conversation starter that {initiator_bot_name} would say to get a discussion going. Consider any recent conversation context, but feel free to start something completely new if more appropriate.")
    ])

# Enhanced conversation initiator selection using full character prompts
def select_conversation_initiator_intelligently(recent_history):
    """
    Uses LLM with full character descriptions to decide which character should initiate a new conversation.
    """
    try:
        # Create enhanced initiator selection prompt using full character descriptions
        character_descriptions = ""
        for char_name in ["Peter", "Brian", "Stewie"]:
            if char_name in CHARACTER_PROMPTS:
                full_description = get_character_description(char_name)
                character_descriptions += f"\n=== {char_name.upper()} GRIFFIN ===\n{full_description}\n"
        
        initiator_selection_prompt = ChatPromptTemplate.from_messages([
            ("system",
             f"You are deciding which Family Guy character should start a new conversation in Discord. Use the detailed character profiles below to determine who would most naturally initiate a new discussion.\n\n"
             f"{character_descriptions}\n"
             f"INITIATOR SELECTION FACTORS:\n"
             f"1. **Character Personality**: Based on the detailed descriptions, who is most likely to spontaneously start conversations?\n"
             f"2. **Recent Activity Balance**: Who hasn't spoken recently and should get a chance?\n"
             f"3. **Topic Continuation**: Based on recent conversation, who might have follow-up thoughts or new ideas?\n"
             f"4. **Natural Conversation Flow**: Who would realistically break a silence or start fresh?\n"
             f"5. **Character Dynamics**: Consider each character's natural tendency to initiate discussions\n\n"
             f"CHARACTER TENDENCIES:\n"
             f"- Peter: Spontaneous, random outbursts, childlike enthusiasm for sharing thoughts\n"
             f"- Brian: Intellectual discussions, current events, wants to show off knowledge\n"
             f"- Stewie: Evil schemes to discuss, scientific observations, sophisticated commentary\n\n"
             f"RESPONSE FORMAT: Respond with ONLY the character name: 'Peter', 'Brian', or 'Stewie'"
            ),
            ("user", "Recent conversation analysis:\n{conversation_context}\n\nBased on the detailed character profiles and recent activity, who should naturally initiate the next conversation?")
        ])
        
        # Format recent history with analysis
        history_text = ""
        speaker_count = {"Peter": 0, "Brian": 0, "Stewie": 0}
        
        if recent_history:
            for msg in recent_history[-8:]:  # Last 8 messages for better context
                if isinstance(msg, HumanMessage):
                    history_text += f"Human: {msg.content}\n"
                elif isinstance(msg, AIMessage):
                    speaker = msg.name.title() if hasattr(msg, 'name') and msg.name else "Bot"
                    if speaker in speaker_count:
                        speaker_count[speaker] += 1
                    history_text += f"{speaker}: {msg.content}\n"
        
        if not history_text:
            history_text = "No recent conversation history"
        
        # Calculate who's been least active
        least_active = min(speaker_count, key=speaker_count.get)
        most_active = max(speaker_count, key=speaker_count.get)
        
        conversation_context = f"""
RECENT CONVERSATION HISTORY:
{history_text}

ACTIVITY ANALYSIS:
- Speaker frequency: Peter ({speaker_count['Peter']}), Brian ({speaker_count['Brian']}), Stewie ({speaker_count['Stewie']})
- Least active character: {least_active} (should be prioritized for balance)
- Most active character: {most_active}

CONTEXT FOR DECISION:
- Who would naturally want to start a new conversation based on their personality?
- Who deserves more speaking time based on recent activity?
- What type of conversation starter would be most natural given recent topics?
        """
        
        initiator_chain = initiator_selection_prompt | shared_llm
        selected_initiator = initiator_chain.invoke({"conversation_context": conversation_context})
        
        selected_initiator = clean_llm_response(selected_initiator).strip()
        
        if selected_initiator in BOT_CONFIGS:
            print(f"üé≠ Enhanced Initiator Coordinator: Selected {selected_initiator} to start new conversation")
            print(f"   ‚öñÔ∏è Activity balance: Peter({speaker_count['Peter']}), Brian({speaker_count['Brian']}), Stewie({speaker_count['Stewie']})")
            print(f"   üéØ Least active: {least_active}")
            return selected_initiator
        else:
            print(f"üé≠ Enhanced initiator selection failed with '{selected_initiator}', using random selection")
            return None
            
    except Exception as e:
        print(f"üé≠ Error in enhanced intelligent initiator selection: {e}")
        return None

# Possible initial prompts for randomly initiated conversations (fallback if dynamic fails)
INITIAL_CONVERSATION_PROMPTS = [
    "Heheheh, anyone seen Lois? I'm hungry!", # Peter
    "Brian, do you ever ponder the sheer absurdity of human existence?", # Stewie
    "Peter, must you always be so... Peter-like?", # Brian
    "What's the latest on the Pawtucket Patriot Ale situation?", # Peter
    "I'm devising a new invention. Any simpletons willing to assist?", # Stewie
    "Another day, another opportunity for intellectual discourse. Or, you know, watching TV.", # Brian
    "Anyone up for a trip to The Drunken Clam?", # Peter
    "I've been contemplating the socio-political implications of modern animation. Thoughts?", # Brian
    "Fools! My plans for world domination are nearly complete!", # Stewie
    "Remember that time I fought the giant chicken? Good times. Heheheh.", # Peter
    "Is anyone else tired of Peter's incessant idiocy?", # Brian
    "I require a guinea pig for my latest experiment. Any volunteers?", # Stewie
    "Just had a thought about... well, everything. It's exhausting.", # Brian
    "Time for some quality television! What's on, Quagmire?", # Peter
    "The intellectual barrenness of this household is truly astounding.", # Brian
    "I'm feeling particularly mischievous today. What havoc shall we wreak?", # Stewie
    "Anyone else smell burnt hair? Oh, wait, that's just Cleveland.", # Peter
    "One must always strive for intellectual growth, even in a chaotic household.", # Brian
    "I've almost perfected my mind control device. Soon, the world will grovel!", # Stewie
    "You know what grinds my gears? When people don't understand my genius.", # Peter
    "The sheer banality of everyday life is truly a burden.", # Brian
    "What's the meaning of life, anyway? And why am I stuck with you lot?", # Stewie (philosophical but with Stewie's disdain)
    "Just thinking about something, wanted to share. Like, why do farts smell?", # Peter (random, crude)
    "I've been reading up on quantum physics. Fascinating stuff, really.", # Brian (intellectual)
    "My latest scheme involves a miniature death ray. Any thoughts on optimal targeting?", # Stewie (megalomaniacal)
    "Anyone else miss the good old days of 'Surfin' Bird'?", # Peter (pop culture)
    "The human condition is a perplexing paradox, isn't it?", # Brian (philosophical)
    "I'm bored. Let's talk about something ridiculous, like why Meg is so unpopular. Heheheh.", # Peter (self-centered)
    "I need some help with a grand scheme. Any takers, or are you all too busy watching television?", # Stewie (disdainful)
    "Random thought of the day: Why do we continue to tolerate such mediocrity?", # Brian (cynical)
]

def clean_llm_response(text, character_name=None):
    """
    Strips unwanted prefixes and placeholders from LLM responses.
    
    Args:
        text: The response text to clean
        character_name: The character generating this response (to avoid removing valid quotes of other characters)
    """
    cleaned_text = text.strip()
    
    # Remove common AI prefixes (case-insensitive and with potential mentions)
    ai_prefixes_to_remove = [
        "AI:", "Assistant:", "Bot:",
        "AI: @Peter Griffin:", "AI: @Brian Griffin:", "AI: @Stewie Griffin:",
        "Assistant: @Peter Griffin:", "Assistant: @Brian Griffin:", "Assistant: @Stewie Griffin:",
        "Bot: @Peter Griffin:", "Bot: @Brian Griffin:", "Bot: @Stewie Griffin:",
        # Additional AI variations
        "AI (as", "Assistant (as", "Bot (as",
        "AI as", "Assistant as", "Bot as"
    ]
    
    for prefix in ai_prefixes_to_remove:
        if cleaned_text.lower().startswith(prefix.lower()):
            cleaned_text = cleaned_text[len(prefix):].strip()
            break # Remove only the first matching prefix

    # üéØ ENHANCED: Remove character self-references but allow quoting other characters
    if character_name:
        character_lower = character_name.lower()
        
        # Remove SELF-references (character talking about themselves)
        self_reference_patterns = [
            f"^{character_lower}:",
            f"^{character_lower} griffin:",
            f"^@{character_lower}:",
            f"^@{character_lower} griffin:",
            f"^{character_lower} said:",
            f"^{character_lower} responds:",
            f"^{character_lower} griffin said:",
            f"^{character_lower} griffin responds:",
            f"^i am {character_lower}:",
            f"^this is {character_lower}:",
            f"^it's {character_lower}:",
        ]
        
        for pattern in self_reference_patterns:
            if re.match(pattern, cleaned_text, re.IGNORECASE):
                # Remove the self-reference prefix
                match = re.match(pattern, cleaned_text, re.IGNORECASE)
                cleaned_text = cleaned_text[len(match.group()):].strip()
                break
    
    # Remove [HumanName] and User placeholders
    cleaned_text = cleaned_text.replace("[HumanName]", "").replace("User", "").strip()
    
    # Remove the END_CONVERSATION_MARKER and its variations
    cleaned_text = cleaned_text.replace(END_CONVERSATION_MARKER, "").strip()
    cleaned_text = cleaned_text.replace("[END CONVERSATION]", "").strip()
    cleaned_text = cleaned_text.replace("[END_CONVERSATION]", "").strip()

    # üéØ ALWAYS REMOVE: "Me:" patterns (never valid)
    cleaned_text = re.sub(r'^(Me|ME):\s*', '', cleaned_text, flags=re.IGNORECASE)
    
    # üéØ ALWAYS REMOVE: Generic character self-references without context
    cleaned_text = re.sub(r'^(I am |This is |It\'s )(Peter Griffin|Brian Griffin|Stewie Griffin|Peter|Brian|Stewie)[\.,:]?\s*', '', cleaned_text, flags=re.IGNORECASE)
    
    # Remove quotation marks if the entire response is wrapped in quotes
    if cleaned_text.startswith('"') and cleaned_text.endswith('"') and cleaned_text.count('"') == 2:
        cleaned_text = cleaned_text[1:-1].strip()

    return cleaned_text

# --- RAG Components ---
# vectorstore = None # Removed
# embeddings = None # Removed

# CHROMA_DB_PATH = os.getenv("CHROMA_DB_PATH_ORCHESTRATOR", "/app/chroma_db") # Removed
RAG_RETRIEVER_API_URL = os.getenv("RAG_RETRIEVER_API_URL", "http://rag-retriever:5005/retrieve")
RAG_CRAWLER_API_URL = os.getenv("RAG_CRAWLER_API_URL", "http://rag-crawler:5009")

def retrieve_context(query, num_results=3):
    """
    Retrieves relevant context by calling the RAG Retriever microservice.
    """
    if not RAG_RETRIEVER_API_URL:
        print("Orchestrator - ERROR: RAG_RETRIEVER_API_URL not configured. Cannot retrieve context.")
        return ""

    payload = {
        "query": query,
        "num_results": num_results
    }
    
    try:
        print(f"Orchestrator - Requesting context from RAG Retriever: {RAG_RETRIEVER_API_URL} for query: '{query[:50]}...'")
        response = requests.post(RAG_RETRIEVER_API_URL, json=payload, timeout=30) # 30-second timeout
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        
        response_data = response.json()
        context = response_data.get("context", "")
        docs_found = response_data.get("documents_found", 0)
        
        if context:
            print(f"Orchestrator - Retrieved context ({docs_found} docs) from RAG Retriever for query '{query[:50]}...': {context[:100]}...")
        else:
            print(f"Orchestrator - No relevant context found by RAG Retriever for query: '{query[:50]}...' (Docs found: {docs_found})")
        return context
        
    except requests.exceptions.Timeout:
        print(f"Orchestrator - ERROR: Timeout connecting to RAG Retriever at {RAG_RETRIEVER_API_URL}")
        print(traceback.format_exc())
        return ""
    except requests.exceptions.ConnectionError:
        print(f"Orchestrator - ERROR: Connection error with RAG Retriever at {RAG_RETRIEVER_API_URL}. Is the service running?")
        print(traceback.format_exc())
        return ""
    except requests.exceptions.RequestException as e:
        print(f"Orchestrator - ERROR: Failed to retrieve context from RAG Retriever: {e}")
        print(traceback.format_exc())
        return ""
    except Exception as e:
        print(f"Orchestrator - ERROR: An unexpected error occurred while retrieving context: {e}")
        print(traceback.format_exc())
        return ""

@app.route('/orchestrate', methods=['POST'])
def orchestrate_conversation():
    """
    Main endpoint for the orchestrator.
    Receives the user's message and channel ID from Peter, Brian, or Stewie's bot.
    Manages the continuous conversation flow between all three characters.
    Includes RAG context retrieval.
    """
    data = request.json
    if not data:
        print("Error: No JSON data received in /orchestrate")
        return jsonify({"error": "No JSON data received"}), 400

    user_query = data.get("user_query")
    channel_id = str(data.get("channel_id"))
    initiator_bot_name = data.get("initiator_bot_name")
    initiator_mention = data.get("initiator_mention")
    human_user_display_name = data.get("human_user_display_name", None)
    conversation_session_id = data.get("conversation_session_id", None)
    is_new_conversation = data.get("is_new_conversation", False)
    is_follow_up = data.get("is_follow_up", False)
    forced_speaker = data.get("forced_speaker", None)
    original_message = data.get("original_message", user_query)  # Full message with mentions

    if not all([user_query, channel_id, initiator_bot_name, initiator_mention]):
        print(f"Error: Missing required data in /orchestrate payload. Received: {data}")
        return jsonify({"error": "Missing required data (user_query, channel_id, initiator_bot_name, initiator_mention)"}), 400

    print(f"Orchestrator received request from {initiator_bot_name} for user query: '{user_query}' in channel {channel_id}")

    if initiator_bot_name not in BOT_CONFIGS:
        print(f"Error: Unknown initiator bot: {initiator_bot_name}")
        return jsonify({"error": f"Unknown initiator bot: {initiator_bot_name}"}), 400

    try:
        active_conversation_session_id = None
        conversation_history_for_llm = []
        current_turn = 0

        if is_new_conversation and conversation_session_id:
            active_conversation_session_id = conversation_session_id
            print(f"Orchestrator: Initiating new scheduled conversation with session ID: {active_conversation_session_id}")
        else:
            latest_message_in_channel = conversations_collection.find_one(
                {"channel_id": channel_id},
                sort=[("timestamp", -1)]
            )
            if latest_message_in_channel and "conversation_session_id" in latest_message_in_channel:
                active_conversation_session_id = latest_message_in_channel["conversation_session_id"]
                print(f"Orchestrator: Resuming conversation with session ID: {active_conversation_session_id}")
                all_channel_history_for_session = list(conversations_collection.find({"channel_id": channel_id, "conversation_session_id": active_conversation_session_id}).sort("timestamp", 1))
                for msg_doc in all_channel_history_for_session:
                    if msg_doc["role"] == "user":
                        conversation_history_for_llm.append(HumanMessage(content=msg_doc["content"]))
                    elif msg_doc["role"] == "assistant":
                        conversation_history_for_llm.append(AIMessage(content=msg_doc["content"], name=msg_doc.get("name")))
                current_turn = len(conversation_history_for_llm) // 2
            else:
                active_conversation_session_id = str(uuid.uuid4())
                print(f"Orchestrator: No active session found. Starting new human-initiated conversation with session ID: {active_conversation_session_id}")

        current_timestamp = datetime.now()
        user_message_doc = {
            "conversation_session_id": active_conversation_session_id,
            "channel_id": channel_id,
            "role": "user",
            "content": user_query,
            "display_name": human_user_display_name,
            "timestamp": current_timestamp
        }
        conversations_collection.insert_one(user_message_doc)
        conversation_history_for_llm.append(HumanMessage(content=user_query))

    except PyMongoError as e:
        print(f"MongoDB error during history retrieval/save: {e}")
        print(traceback.format_exc())
        return jsonify({"error": "Failed to access conversation history"}), 500

    try:
        # --- RAG: Retrieve context for the current user query ---
        retrieved_context = retrieve_context(user_query)

        # --- Single Response Generation (Natural Conversation Flow) ---
        current_turn += 1
        print(f"\n--- Generating Response for Turn {current_turn} ---")

        next_speaker_name = None
        recent_llm_history = conversation_history_for_llm[-MAX_CHAT_HISTORY_MESSAGES:]
        last_speaker_name_in_history = None
        mentioned_bots = []

        # If this is a follow-up with a forced speaker, use that
        if is_follow_up and forced_speaker:
            next_speaker_name = forced_speaker
            print(f"üîÑ Follow-up: Using forced speaker: {next_speaker_name}")
        elif recent_llm_history:
            last_message_llm = recent_llm_history[-1]
            last_speaker_name_in_history = last_message_llm.name if hasattr(last_message_llm, 'name') else None

            for bot_name, config in BOT_CONFIGS.items():
                # Check for both Discord mention format and text mentions in original message
                if (config["mention"] in original_message or 
                    f"@{bot_name}" in original_message or 
                    f"@{bot_name.lower()}" in original_message or
                    f"{bot_name.lower()}" in original_message.lower()):
                    mentioned_bots.append(bot_name)
                    print(f"Found direct mention to {bot_name} in original message")

            if mentioned_bots:
                eligible_mentioned = [bot for bot in mentioned_bots if not last_speaker_name_in_history or bot.lower() != last_speaker_name_in_history.lower()]
                if eligible_mentioned:
                    next_speaker_name = random.choice(eligible_mentioned)
                    print(f"üéØ Direct mention selection: {next_speaker_name} (from mentions: {mentioned_bots})")
                else:
                    next_speaker_name = random.choice(mentioned_bots)
                    print(f"üéØ Direct mention selection (all were last speaker, so picking one): {next_speaker_name}")
            else:
                print("ü§ñ No direct mentions found, using Conversation Coordinator for intelligent selection...")
                llm_selected_speaker = select_next_speaker_intelligently(
                    conversation_history_for_llm=recent_llm_history,
                    current_message=user_query,
                    mentioned_bots=mentioned_bots,
                    last_speaker_name=last_speaker_name_in_history,
                    current_turn=current_turn,
                    retrieved_context=retrieved_context
                )
                if llm_selected_speaker:
                    next_speaker_name = llm_selected_speaker
                    print(f"üß† LLM Coordinator selected: {next_speaker_name}")
                else:
                    # FALLBACK: Use rule-based selection if LLM fails
                    print("‚ö†Ô∏è LLM Coordinator failed, using fallback rule-based selection...")
                    if current_turn == 1 and initiator_bot_name: # Ensure initiator_bot_name is available
                        next_speaker_name = initiator_bot_name
                        print(f"üîÑ Fallback (Turn 1): Using initiator bot: {next_speaker_name}")
                    else:
                        eligible_bots = [name for name in BOT_CONFIGS.keys() if not last_speaker_name_in_history or name.lower() != last_speaker_name_in_history.lower()]
                        if not eligible_bots: # If all bots were the last speaker (e.g. only 1 bot active)
                            eligible_bots = list(BOT_CONFIGS.keys())
                        if eligible_bots: # Ensure there's someone to pick
                            next_speaker_name = random.choice(eligible_bots)
                            print(f"üîÑ Fallback: Random selection from eligible bots: {next_speaker_name}")
                        else: # Should not happen with BOT_CONFIGS populated
                            print("ERROR: No eligible bots to select as next speaker!")
                            return jsonify({"error": "No eligible bots to select"}), 500

        else: # No conversation history (recent_llm_history is empty)
            # This means it's the very first message of a new session, or history was cleared
            # But if it's a follow-up, we should still use the forced speaker
            if is_follow_up and forced_speaker:
                next_speaker_name = forced_speaker
                print(f"üîÑ Follow-up with no history: Using forced speaker: {next_speaker_name}")
            else:
                # Check for mentions in the original message
                for bot_name, config in BOT_CONFIGS.items():
                    # Check for both Discord mention format and text mentions
                    if (config["mention"] in original_message or 
                        f"@{bot_name}" in original_message or 
                        f"@{bot_name.lower()}" in original_message or
                        f"{bot_name.lower()}" in original_message.lower()):
                        mentioned_bots.append(bot_name)
                
                if mentioned_bots:
                    next_speaker_name = mentioned_bots[0] # First mentioned bot responds
                    print(f"üéØ No history, using directly mentioned bot: {next_speaker_name}")
                elif initiator_bot_name: # Fallback to the bot that initiated this request from Discord
                    next_speaker_name = initiator_bot_name
                    print(f"üîÑ No history or mentions, using initiator bot: {next_speaker_name}")
                else: # Absolute fallback if no initiator (e.g. direct API call without initiator)
                    next_speaker_name = random.choice(list(BOT_CONFIGS.keys()))
                    print(f"üîÑ No history, mentions, or initiator, using random bot: {next_speaker_name}")

        if not next_speaker_name: # Final safety net
            print("ERROR: next_speaker_name could not be determined. Defaulting to a random bot.")
            next_speaker_name = random.choice(list(BOT_CONFIGS.keys()))

        current_speaker_name = next_speaker_name
        current_speaker_config = BOT_CONFIGS[current_speaker_name]
        # current_speaker_mention = current_speaker_config["mention"] # Not used directly here

        print(f"Current speaker: {current_speaker_name}")

        # Convert conversation history to LangChain message objects for centralized LLM
        # Use the recent_llm_history slice here as well
        chat_history_messages = []
        for msg in recent_llm_history: # recent_llm_history will be empty if it's the first message
            if isinstance(msg, HumanMessage):
                chat_history_messages.append(HumanMessage(content=msg.content))
            elif isinstance(msg, AIMessage):
                chat_history_messages.append(AIMessage(content=msg.content, name=msg.name))

        # Prepare mention context
        mention_context = f"""Available character mentions:
{chr(10).join([f"{name}: {config['mention']}" for name, config in BOT_CONFIGS.items()])}

Use these exact mention strings when referring to other characters in your response.
"""

        # Generate response using centralized LLM
        retries = 0
        response_text = None
        while retries < MAX_RETRIES:
            try:
                print(f"Orchestrator generating {current_speaker_name}'s response using quality-controlled generation (attempt {retries + 1}/{MAX_RETRIES})...")
                response_text = generate_character_response_with_quality_control(
                    character_name=current_speaker_name,
                    conversation_history=chat_history_messages, # Pass the sliced (possibly empty) history
                    mention_context=mention_context,
                    input_text="Continue the conversation.", # This might need to be the actual user_query for the first turn.
                    retrieved_context=retrieved_context,
                    human_user_display_name=human_user_display_name,
                    channel_id=channel_id  # Pass channel_id for adaptive quality control
                )
                
                # üö´ NO FALLBACK MODE: Handle None responses
                if response_text is None:
                    if NO_FALLBACK_MODE:
                        print(f"üí• NO_FALLBACK_MODE: {current_speaker_name} returned None response on attempt {retries + 1}")
                        retries += 1
                        if retries < MAX_RETRIES:
                            print(f"üîÑ Retrying response generation (attempt {retries + 1}/{MAX_RETRIES})...")
                            continue
                        else:
                            print(f"üí• CRITICAL: NO_FALLBACK_MODE failed after {MAX_RETRIES} orchestrator attempts!")
                            print(f"   This indicates a serious issue with the LLM or quality control system.")
                            print(f"   Consider temporarily disabling NO_FALLBACK_MODE or checking system health.")
                            return jsonify({
                                "error": "NO_FALLBACK_MODE: Failed to generate valid response after maximum retries",
                                "details": f"Character {current_speaker_name} could not generate a valid response after {MAX_RETRIES} attempts",
                                "suggestion": "Check LLM health, lower quality thresholds, or disable NO_FALLBACK_MODE temporarily"
                            }), 500
                    else:
                        # Traditional mode - this shouldn't happen but handle gracefully
                        print(f"‚ö†Ô∏è Unexpected None response from {current_speaker_name}, treating as error")
                        raise Exception("Quality control returned None response unexpectedly")
                
                print(f"{current_speaker_name}'s centralized LLM generated: {response_text[:50]}...")
                break
            except Exception as e:
                retries += 1
                if retries == MAX_RETRIES:
                    # Add to dead letter queue before raising
                    if dlq: # Ensure dlq is initialized
                        dlq.add_message(
                            MessageType.LLM_REQUEST,
                            {
                                "character_name": current_speaker_name,
                                "conversation_history": [msg.dict() if hasattr(msg, 'dict') else str(msg) for msg in chat_history_messages],
                                "mention_context": mention_context,
                                "retrieved_context": retrieved_context
                            },
                            str(e),
                            current_speaker_name
                        )
                    raise # Re-raise the exception to be caught by the main try-except block
                print(f"Attempt {retries} failed, retrying in {2 ** retries} seconds...")
                time.sleep(2 ** retries)

        print(f"{current_speaker_name}'s final response: {response_text[:50]}...")

        bot_message_doc = {
            "conversation_session_id": active_conversation_session_id,
            "channel_id": channel_id,
            "role": "assistant",
            "name": current_speaker_name.lower(),
            "content": response_text,
            "timestamp": datetime.now()
        }
        conversations_collection.insert_one(bot_message_doc)
        conversation_history_for_llm.append(AIMessage(content=response_text, name=current_speaker_name.lower()))

        # üö® CRITICAL: Validate Discord message length before sending
        if len(response_text) > 2000:
            print(f"üö® CRITICAL: Response too long for Discord ({len(response_text)} chars), truncating...")
            response_text = response_text[:1900] + "..."
            # Update the stored message as well
            bot_message_doc["content"] = response_text
            conversations_collection.replace_one(
                {"_id": bot_message_doc.get("_id")}, 
                bot_message_doc
            )

        # Add retry logic for Discord message sending
        retries = 0
        discord_payload = {
            "bot_name": current_speaker_name,
            "message_content": response_text,
            "channel_id": channel_id
        }
        while retries < MAX_RETRIES:
            try:
                print(f"Orchestrator instructing {current_speaker_name} to send to Discord (attempt {retries + 1}/{MAX_RETRIES})...")
                discord_response = requests.post(current_speaker_config["discord_send_api"], json=discord_payload, timeout=API_TIMEOUT)
                discord_response.raise_for_status()
                print(f"Successfully sent {current_speaker_name}'s response to Discord")
                break
            except requests.exceptions.HTTPError as e:
                # Check if it's a Discord length error
                if e.response.status_code == 400 and "2000 or fewer in length" in str(e.response.text):
                    print(f"üö® Discord length error detected, truncating response further...")
                    response_text = response_text[:1500] + "..."
                    discord_payload["message_content"] = response_text
                    # Try once more with truncated message
                    try:
                        discord_response = requests.post(current_speaker_config["discord_send_api"], json=discord_payload, timeout=API_TIMEOUT)
                        discord_response.raise_for_status()
                        print(f"Successfully sent truncated {current_speaker_name}'s response to Discord")
                        break
                    except Exception as truncate_error:
                        print(f"Failed even with truncated message: {truncate_error}")
                        raise e  # Raise original error
                else:
                    raise e  # Re-raise if not a length error
            except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
                retries += 1
                if retries == MAX_RETRIES:
                    # Add to dead letter queue before raising
                    dlq.add_message(
                        MessageType.DISCORD_MESSAGE,
                        discord_payload,
                        str(e),
                        current_speaker_name
                    )
                    raise
                print(f"Attempt {retries} failed, retrying in {2 ** retries} seconds...")
                time.sleep(2 ** retries)  # Exponential backoff

        # Conversation continues naturally - no artificial ending
        print(f"Response generated successfully. Conversation continues naturally...")

        # Check for organic conversation opportunities after this response
        # This allows the coordinator to detect natural conversation endpoints
        try:
            # Small delay to allow the message to be processed and stored
            threading.Thread(target=lambda: _delayed_organic_check(channel_id), daemon=True).start()
        except Exception as e:
            print(f"Error scheduling organic conversation check: {e}")

        return jsonify({"status": "Response generated successfully", "turns": current_turn, "conversation_session_id": active_conversation_session_id, "speaker": current_speaker_name}), 200

    except requests.exceptions.Timeout:
        error_msg = f"Orchestrator Timeout Error: A request to a bot API timed out. This could mean the bot or Ollama is slow to respond."
        print(f"Error: {error_msg}\n{traceback.format_exc()}")
        return jsonify({"error": error_msg}), 504
    except requests.exceptions.ConnectionError as e:
        error_msg = f"Orchestrator Connection Error: One of the bot APIs is unreachable. Details: {e}"
        print(f"Error: {error_msg}\n{traceback.format_exc()}")
        return jsonify({"error": error_msg}), 500
    except requests.exceptions.HTTPError as e:
        error_msg = f"Orchestrator HTTP Error: API returned an error. Status: {e.response.status_code}, Response: {e.response.text}"
        print(f"Error: {error_msg}\n{traceback.format_exc()}")
        return jsonify({"error": error_msg}), 500
    except Exception as e:
        error_msg = f"Orchestrator General Error: An unexpected error occurred: {e}"
        print(f"Critical Error in /orchestrate: {error_msg}\n{traceback.format_exc()}")
        return jsonify({"error": error_msg}), 500

def _delayed_organic_check(channel_id):
    """
    Delayed check for follow-up and organic conversation opportunities after a conversation response.
    Runs in a separate thread to avoid blocking the main orchestrator response.
    """
    try:
        # Wait for the configured delay to ensure the message has been stored
        time.sleep(FOLLOW_UP_DELAY_SECONDS)
        
        # First, check for immediate follow-up opportunities (more aggressive)
        if organic_coordinator.should_start_follow_up_conversation(channel_id):
            print(f"üîÑ Post-Response Check: Detected opportunity for follow-up conversation")
            success = organic_coordinator.initiate_follow_up_conversation(channel_id)
            if success:
                print(f"üîÑ Post-Response Check: Successfully started follow-up conversation")
                return  # Don't check for organic if we started a follow-up
            else:
                print(f"üîÑ Post-Response Check: Failed to start follow-up conversation")
        
        # If no follow-up was triggered, check for organic conversation opportunities
        if organic_coordinator.should_start_organic_conversation(channel_id):
            print(f"üå± Post-Response Check: Detected opportunity for organic conversation")
            success = organic_coordinator.initiate_organic_conversation(channel_id)
            if success:
                print(f"üå± Post-Response Check: Successfully started organic conversation")
            else:
                print(f"üå± Post-Response Check: Failed to start organic conversation")
        else:
            print(f"üå± Post-Response Check: No follow-up or organic conversation needed")
            
    except Exception as e:
        print(f"üîÑ Post-Response Check: Error during delayed check: {e}")
        print(traceback.format_exc())

# Global to track last crawl time (will be loaded from MongoDB)
# last_crawl_timestamp = None # No longer needed as a simple global, loaded from DB

def schedule_daily_conversations():
    """
    OLD SCHEDULER FUNCTION - REPLACED BY ORGANIC CONVERSATION COORDINATOR
    This function has been replaced by the OrganicConversationCoordinator class
    which provides more natural, context-driven conversation initiation.
    """
    pass  # Function removed - see OrganicConversationCoordinator

def run_flask_app():
    """
    Function to run the Flask app in a separate thread.
    Includes a general exception handler for the Flask app itself.
    """
    print(f"Orchestrator server starting on port {ORCHESTRATOR_PORT}...")
    try:
        app.run(host='0.0.0.0', port=ORCHESTRATOR_PORT, debug=False, use_reloader=False)
    except Exception as e:
        print(f"CRITICAL: Flask application failed to start or crashed unexpectedly: {e}")
        print(traceback.format_exc())
        os._exit(1)

# --- Health Check Endpoint ---
@app.route('/health', methods=['GET'])
def health_check():
    """Simple health check endpoint for load balancer."""
    try:
        # Check database connectivity
        mongo_client.admin.command('ping')
        db_status = "connected"
    except Exception as e:
        db_status = f"error: {str(e)}"
    
    # Check RAG Retriever Service status (optional, simple ping if retriever had a health endpoint)
    rag_retriever_status = "not_checked" 
    try:
        # Example: pinging the retriever's health endpoint if it had one
        # health_url = RAG_RETRIEVER_API_URL.replace("/retrieve", "/health") 
        # rag_response = requests.get(health_url, timeout=5)
        # if rag_response.status_code == 200:
        #     rag_retriever_status = "healthy"
        # else:
        #     rag_retriever_status = f"unhealthy_code_{rag_response.status_code}"
        # For now, just confirm the URL is set
        if RAG_RETRIEVER_API_URL:
            rag_retriever_status = "configured"
        else:
            rag_retriever_status = "not_configured"

    except Exception as e:
        rag_retriever_status = f"error_checking: {str(e)}"

    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "database": db_status,
        # "embeddings_model": "loaded" if 'embeddings_model' in globals() else "not_loaded", # Removed
        # "vector_store": "loaded" if 'vector_store' in globals() else "not_loaded" # Removed
        "rag_retriever_service": rag_retriever_status
    })

@app.route('/crawl/trigger', methods=['POST'])
def trigger_rag_crawl():
    """Trigger RAG crawling via the RAG Crawler microservice."""
    try:
        # Get crawl parameters from request
        data = request.json or {}
        
        # Prepare payload for crawler service
        crawler_payload = {
            "start_url": data.get("start_url", FANDOM_WIKI_START_URL),
            "max_pages": int(data.get("max_pages", FANDOM_WIKI_MAX_PAGES)),
            "delay": int(data.get("delay", FANDOM_WIKI_CRAWL_DELAY))
        }
        
        print(f"Orchestrator - Triggering RAG crawl via crawler service: {RAG_CRAWLER_API_URL}/crawl/start")
        
        # Call the RAG crawler service
        response = requests.post(
            f"{RAG_CRAWLER_API_URL}/crawl/start",
            json=crawler_payload,
            timeout=30
        )
        response.raise_for_status()
        
        crawler_response = response.json()
        
        return jsonify({
            "message": "RAG crawl triggered successfully",
            "status": "initiated",
            "crawler_response": crawler_response,
            "timestamp": datetime.now().isoformat()
        }), 202
        
    except requests.exceptions.ConnectionError:
        return jsonify({
            "error": "RAG Crawler service is not available",
            "status": "service_unavailable",
            "crawler_url": RAG_CRAWLER_API_URL
        }), 503
        
    except requests.exceptions.Timeout:
        return jsonify({
            "error": "Timeout connecting to RAG Crawler service",
            "status": "timeout"
        }), 504
        
    except Exception as e:
        print(f"Orchestrator - Error triggering RAG crawl: {e}")
        print(traceback.format_exc())
        return jsonify({
            "error": f"Failed to trigger RAG crawl: {str(e)}",
            "status": "failed"
        }), 500

@app.route('/crawl/status', methods=['GET'])
def get_rag_crawl_status():
    """Get RAG crawl status from the RAG Crawler microservice."""
    try:
        print(f"Orchestrator - Getting RAG crawl status from: {RAG_CRAWLER_API_URL}/crawl/status")
        
        response = requests.get(
            f"{RAG_CRAWLER_API_URL}/crawl/status",
            timeout=10
        )
        response.raise_for_status()
        
        crawler_status = response.json()
        
        return jsonify({
            "orchestrator_status": "healthy",
            "crawler_status": crawler_status,
            "timestamp": datetime.now().isoformat()
        }), 200
        
    except requests.exceptions.ConnectionError:
        return jsonify({
            "error": "RAG Crawler service is not available",
            "status": "service_unavailable",
            "crawler_url": RAG_CRAWLER_API_URL
        }), 503
        
    except requests.exceptions.Timeout:
        return jsonify({
            "error": "Timeout connecting to RAG Crawler service",
            "status": "timeout"
        }), 504
        
    except Exception as e:
        print(f"Orchestrator - Error getting RAG crawl status: {e}")
        return jsonify({
            "error": f"Failed to get RAG crawl status: {str(e)}",
            "status": "failed"
        }), 500

# Fine-Tuning System API Endpoints

@app.route('/rate_response', methods=['POST'])
def rate_response():
    """
    Endpoint for users to rate character responses.
    Expected JSON: {
        "character_name": "Peter|Brian|Stewie",
        "response_text": "The response to rate",
        "rating": 1-5,
        "feedback": "Optional feedback text",
        "conversation_context": "Optional context"
    }
    """
    try:
        if not prompt_fine_tuner:
            return jsonify({"error": "Fine-tuning system not available"}), 503
        
        data = request.get_json()
        
        # Validate required fields
        required_fields = ["character_name", "response_text", "rating"]
        for field in required_fields:
            if field not in data:
                return jsonify({"error": f"Missing required field: {field}"}), 400
        
        character_name = data["character_name"]
        response_text = data["response_text"]
        rating = data["rating"]
        feedback = data.get("feedback", "")
        conversation_context = data.get("conversation_context", "")
        user_id = data.get("user_id", "api_user")
        
        # Validate character name
        if character_name not in ["Peter", "Brian", "Stewie"]:
            return jsonify({"error": "Invalid character_name. Must be Peter, Brian, or Stewie"}), 400
        
        # Validate rating
        if not isinstance(rating, (int, float)) or not (1 <= rating <= 5):
            return jsonify({"error": "Rating must be a number between 1 and 5"}), 400
        
        # Record the rating
        rating_id = prompt_fine_tuner.record_rating(
            character_name=character_name,
            response_text=response_text,
            rating=rating,
            feedback=feedback,
            user_id=user_id,
            conversation_context=conversation_context
        )
        
        if rating_id:
            return jsonify({
                "success": True,
                "rating_id": rating_id,
                "message": f"Rating recorded for {character_name}"
            })
        else:
            return jsonify({"error": "Failed to record rating"}), 500
            
    except Exception as e:
        print(f"Error in rate_response endpoint: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/optimization_report', methods=['GET'])
def get_optimization_report():
    """
    Get optimization status and performance metrics for all characters.
    Query params: ?days=7 (optional, defaults to 7 days)
    """
    try:
        if not prompt_fine_tuner:
            return jsonify({"error": "Fine-tuning system not available"}), 503
        
        days = int(request.args.get('days', 7))
        
        reports = {}
        for character in ["Peter", "Brian", "Stewie"]:
            reports[character] = prompt_fine_tuner.get_performance_report(character, days)
        
        return jsonify({
            "optimization_reports": reports,
            "period_days": days,
            "generated_at": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"Error in optimization_report endpoint: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/prompt_performance', methods=['GET'])
def get_prompt_performance():
    """
    Get detailed performance metrics for a specific character.
    Query params: ?character=Peter&days=7
    """
    try:
        if not prompt_fine_tuner:
            return jsonify({"error": "Fine-tuning system not available"}), 503
        
        character = request.args.get('character')
        days = int(request.args.get('days', 30))
        
        if not character or character not in ["Peter", "Brian", "Stewie"]:
            return jsonify({"error": "Invalid or missing character parameter"}), 400
        
        # Get performance report
        report = prompt_fine_tuner.get_performance_report(character, days)
        
        # Get prompt versions history
        versions = list(prompt_fine_tuner.prompt_versions_collection.find(
            {"character_name": character},
            sort=[("version", -1)]
        ).limit(10))
        
        # Convert ObjectId to string for JSON serialization
        for version in versions:
            version["_id"] = str(version["_id"])
            if "created_at" in version:
                version["created_at"] = version["created_at"].isoformat()
        
        return jsonify({
            "character": character,
            "performance_report": report,
            "prompt_versions": versions,
            "generated_at": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"Error in prompt_performance endpoint: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/trigger_optimization', methods=['POST'])
def trigger_manual_optimization():
    """
    Manually trigger prompt optimization for a character.
    Expected JSON: {"character_name": "Peter|Brian|Stewie"}
    """
    try:
        if not prompt_fine_tuner:
            return jsonify({"error": "Fine-tuning system not available"}), 503
        
        data = request.get_json()
        character_name = data.get("character_name")
        
        if not character_name or character_name not in ["Peter", "Brian", "Stewie"]:
            return jsonify({"error": "Invalid character_name"}), 400
        
        # Get recent ratings for optimization
        recent_ratings = list(prompt_fine_tuner.ratings_collection.find(
            {"character_name": character_name},
            sort=[("timestamp", -1)],
            limit=MIN_RATINGS_FOR_OPTIMIZATION
        ))
        
        if len(recent_ratings) < 5:  # Need at least 5 ratings
            return jsonify({
                "error": f"Not enough ratings for optimization. Need at least 5, have {len(recent_ratings)}"
            }), 400
        
        # Trigger optimization
        success = prompt_fine_tuner.optimize_prompt(character_name, recent_ratings)
        
        if success:
            return jsonify({
                "success": True,
                "message": f"Optimization triggered for {character_name}",
                "new_version": prompt_fine_tuner.get_current_prompt_version(character_name)
            })
        else:
            return jsonify({"error": "Optimization failed"}), 500

    except Exception as e:
        print(f"Error in trigger_optimization endpoint: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/fine_tuning_stats', methods=['GET'])
def get_fine_tuning_stats():
    """Get overall fine-tuning system statistics."""
    try:
        if not prompt_fine_tuner:
            return jsonify({"error": "Fine-tuning system not available"}), 503
        
        stats = {}
        
        for character in ["Peter", "Brian", "Stewie"]:
            # Count total ratings
            total_ratings = prompt_fine_tuner.ratings_collection.count_documents(
                {"character_name": character}
            )
            
            # Count recent ratings (last 7 days)
            week_ago = datetime.now() - timedelta(days=7)
            recent_ratings = prompt_fine_tuner.ratings_collection.count_documents({
                "character_name": character,
                "timestamp": {"$gte": week_ago}
            })
            
            # Get average rating
            pipeline = [
                {"$match": {"character_name": character}},
                {"$group": {"_id": None, "avg_rating": {"$avg": "$rating"}}}
            ]
            avg_result = list(prompt_fine_tuner.ratings_collection.aggregate(pipeline))
            avg_rating = avg_result[0]["avg_rating"] if avg_result else None
            
            # Count prompt versions
            version_count = prompt_fine_tuner.prompt_versions_collection.count_documents(
                {"character_name": character}
            )
            
            stats[character] = {
                "total_ratings": total_ratings,
                "recent_ratings_7d": recent_ratings,
                "average_rating": round(avg_rating, 2) if avg_rating else None,
                "prompt_versions": version_count,
                "current_version": prompt_fine_tuner.get_current_prompt_version(character)
            }
        
        return jsonify({
            "system_stats": stats,
            "configuration": {
                "fine_tuning_enabled": FINE_TUNING_ENABLED,
                "quality_control_enabled": QUALITY_CONTROL_ENABLED,
                "optimization_threshold": OPTIMIZATION_THRESHOLD,
                "min_ratings_for_optimization": MIN_RATINGS_FOR_OPTIMIZATION,
                "ab_test_percentage": AB_TEST_PERCENTAGE,
                "quality_control_min_rating": QUALITY_CONTROL_MIN_RATING
            },
            "generated_at": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"Error in fine_tuning_stats endpoint: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/quality_control_status', methods=['GET'])
def get_quality_control_status():
    """
    Endpoint to get the current quality control configuration and statistics.
    """
    try:
        # Get quality control statistics from the database
        if prompt_fine_tuner:
            quality_control_stats = {}
            
            # Count ratings by user type to see quality control activity
            for character in ["Peter", "Brian", "Stewie"]:
                char_stats = {
                    "quality_control_accepted": prompt_fine_tuner.ratings_collection.count_documents({
                        "character_name": character,
                        "user_id": "quality_control_llm_assessment",
                        "feedback": {"$regex": "Quality Control Approved"}
                    }),
                    "quality_control_rejected": prompt_fine_tuner.ratings_collection.count_documents({
                        "character_name": character,
                        "user_id": "quality_control_llm_assessment", 
                        "feedback": {"$regex": "Quality Control Rejected"}
                    })
                }
                
                # Calculate acceptance rate
                total_qc = char_stats["quality_control_accepted"] + char_stats["quality_control_rejected"]
                if total_qc > 0:
                    char_stats["acceptance_rate"] = round(char_stats["quality_control_accepted"] / total_qc * 100, 1)
                else:
                    char_stats["acceptance_rate"] = None
                
                quality_control_stats[character] = char_stats
        else:
            quality_control_stats = "Fine-tuning system not available"
        
        return jsonify({
            "configuration": {
                "enabled": QUALITY_CONTROL_ENABLED,
                "min_rating_threshold": QUALITY_CONTROL_MIN_RATING,
                "max_retries": QUALITY_CONTROL_MAX_RETRIES,
                "adaptive_quality_control_enabled": ADAPTIVE_QUALITY_CONTROL_ENABLED,
                "cold_start_threshold": COLD_START_THRESHOLD,
                "warm_conversation_threshold": WARM_CONVERSATION_THRESHOLD,
                "hot_conversation_threshold": HOT_CONVERSATION_THRESHOLD,
                "no_fallback_mode": NO_FALLBACK_MODE,
                "max_retry_attempts": MAX_RETRY_ATTEMPTS,
                "retry_backoff_enabled": RETRY_BACKOFF_ENABLED,
                "retry_backoff_multiplier": RETRY_BACKOFF_MULTIPLIER,
                "enhanced_retry_context_enabled": ENHANCED_RETRY_CONTEXT_ENABLED
            },
            "statistics": quality_control_stats,
            "generated_at": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"Error in quality_control_status endpoint: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/organic_conversation_status', methods=['GET'])
def get_organic_conversation_status():
    """
    Get the current status and configuration of the Enhanced Organic Conversation Coordinator.
    """
    try:
        # Get recent follow-up and organic conversation activity
        now = datetime.now()
        recent_cutoff = now - timedelta(hours=24)
        
        # Count recent follow-up conversations (marked by quick succession)
        recent_conversations = list(conversations_collection.find({
            "timestamp": {"$gte": recent_cutoff}
        }).sort("timestamp", 1))
        
        follow_up_count = 0
        organic_count = 0
        
        # Analyze conversation patterns to identify follow-ups vs organic
        for i in range(1, len(recent_conversations)):
            prev_msg = recent_conversations[i-1]
            curr_msg = recent_conversations[i]
            
            # If both are bot messages within follow-up timeframe, likely a follow-up
            if (prev_msg.get("role") == "assistant" and 
                curr_msg.get("role") == "assistant" and
                prev_msg.get("name") != curr_msg.get("name")):
                
                time_diff = (curr_msg["timestamp"] - prev_msg["timestamp"]).total_seconds()
                if time_diff <= MIN_TIME_BETWEEN_FOLLOW_UPS:
                    follow_up_count += 1
                else:
                    organic_count += 1
        
        return jsonify({
            "status": "active",
            "configuration": {
                "follow_up_conversations_enabled": ENABLE_FOLLOW_UP_CONVERSATIONS,
                "follow_up_delay_seconds": FOLLOW_UP_DELAY_SECONDS,
                "min_time_between_follow_ups": MIN_TIME_BETWEEN_FOLLOW_UPS,
                "conversation_silence_threshold_minutes": CONVERSATION_SILENCE_THRESHOLD_MINUTES,
                "min_time_between_organic_conversations": MIN_TIME_BETWEEN_ORGANIC_CONVERSATIONS
            },
            "recent_activity_24h": {
                "follow_up_conversations": follow_up_count,
                "organic_conversations": organic_count,
                "total_bot_messages": len([msg for msg in recent_conversations if msg.get("role") == "assistant"])
            },
            "coordinator_state": {
                "last_follow_up_attempt": organic_coordinator.last_follow_up_attempt.isoformat() if organic_coordinator.last_follow_up_attempt else None,
                "last_organic_attempt": organic_coordinator.last_organic_attempt.isoformat() if organic_coordinator.last_organic_attempt else None
            },
            "features": {
                "character_specific_triggers": True,
                "intelligent_character_selection": True,
                "rag_enhanced_starters": True,
                "quality_control_integration": True,
                "self_orchestration": True,
                "timing_management": True
            },
            "timestamp": now.isoformat()
        }), 200
        
    except Exception as e:
        print(f"Error getting organic conversation status: {e}")
        return jsonify({
            "error": f"Failed to get organic conversation status: {str(e)}",
            "status": "error"
        }), 500

# --- Enhanced Conversation Coordinator using Full Character Prompts ---
def create_enhanced_coordinator_prompt():
    """Create conversation coordinator prompt using the detailed character descriptions."""
    
    # Extract the full character descriptions from existing prompts
    character_descriptions = ""
    for char_name in ["Peter", "Brian", "Stewie"]:
        if char_name in CHARACTER_PROMPTS:
            # Get the system message content which contains the detailed character description
            full_description = get_character_description(char_name)
            character_descriptions += f"\n=== {char_name.upper()} GRIFFIN ===\n{full_description}\n"
    
    return ChatPromptTemplate.from_messages([
        ("system",
         f"You are the Conversation Coordinator for Family Guy characters in a Discord chat. Your job is to analyze the conversation and determine which character should respond next to create the most natural, engaging conversation flow.\n\n"
         f"You have access to detailed character profiles below. Use these to make intelligent decisions about who would naturally respond to different topics and situations.\n"
         f"{character_descriptions}\n"
         f"COORDINATOR DECISION FACTORS:\n"
         f"1. **Topic Relevance**: Based on the detailed character descriptions above, who would naturally be most interested in or triggered by this topic?\n"
         f"2. **Character Dynamics**: Consider the relationships and conflicts described in the character profiles\n"
         f"3. **Speech Patterns**: Who would naturally have something to say based on their communication style?\n"
         f"4. **Personality Triggers**: What would make each character want to jump into the conversation?\n"
         f"5. **Conversation Balance**: Avoid same character speaking twice unless it's very natural\n"
         f"6. **Character State**: Consider if someone made a mistake (Brian corrects), someone's being pretentious (Stewie mocks), etc.\n\n"
         f"PRIORITY RULES:\n"
         f"- If someone is directly mentioned (@character), they MUST respond (override your decision)\n"
         f"- Use the detailed personality and speech pattern information to predict natural reactions\n"
         f"- Consider who hasn't spoken recently for balance\n"
         f"- Think about realistic conversation dynamics between these specific characters\n\n"
         f"RESPONSE FORMAT: Respond with ONLY the character name: 'Peter', 'Brian', or 'Stewie'"
        ),
        ("user", "Conversation context:\n{conversation_analysis}\n\nWho should respond next? Answer with ONLY the character name (Peter, Brian, or Stewie):")
    ])

conversation_coordinator_prompt = create_enhanced_coordinator_prompt()
conversation_coordinator_chain = conversation_coordinator_prompt | shared_llm

def select_next_speaker_intelligently(conversation_history_for_llm, current_message, mentioned_bots, last_speaker_name, current_turn, retrieved_context=""):
    """
    Uses an enhanced LLM coordinator with full character descriptions and RAG context to intelligently select who should respond next.
    Returns the selected character name or None if LLM selection fails.
    """
    try:
        # Format conversation history for the coordinator
        history_text = ""
        recent_messages = conversation_history_for_llm[-8:] if len(conversation_history_for_llm) > 8 else conversation_history_for_llm
        
        # Track speaker frequency for balance
        speaker_count = {"Peter": 0, "Brian": 0, "Stewie": 0}
        
        for i, msg in enumerate(recent_messages):
            if isinstance(msg, HumanMessage):
                history_text += f"Human: {msg.content}\n"
            elif isinstance(msg, AIMessage):
                speaker = msg.name.title() if hasattr(msg, 'name') and msg.name else "Bot"
                if speaker in speaker_count:
                    speaker_count[speaker] += 1
                history_text += f"{speaker}: {msg.content}\n"
        
        # Calculate who's been least active (for balance)
        least_active = min(speaker_count, key=speaker_count.get)
        most_active = max(speaker_count, key=speaker_count.get)
        
        # üîç RAG-ENHANCED TOPIC ANALYSIS
        # Get additional context about the conversation topic from Family Guy wiki
        rag_context = ""
        if not retrieved_context:
            # If no context was passed, retrieve it specifically for coordinator decision-making
            print("üîç RAG Coordinator: Retrieving Family Guy universe context for topic analysis...")
            rag_context = retrieve_context(current_message, num_results=2)
        else:
            rag_context = retrieved_context
        
        # Analyze RAG context for character relevance
        rag_analysis = ""
        if rag_context:
            context_lower = rag_context.lower()
            
            # Look for character-specific information in the retrieved context
            if any(term in context_lower for term in ['peter griffin', 'peter', 'fat man', 'pawtucket patriot', 'chicken fight']):
                rag_analysis += "RAG context contains Peter-related information. "
            if any(term in context_lower for term in ['brian griffin', 'brian', 'dog', 'writer', 'liberal', 'martini']):
                rag_analysis += "RAG context contains Brian-related information. "
            if any(term in context_lower for term in ['stewie griffin', 'stewie', 'baby', 'evil', 'time machine', 'british']):
                rag_analysis += "RAG context contains Stewie-related information. "
                
            # Look for topic-specific expertise in retrieved context
            if any(term in context_lower for term in ['science', 'invention', 'technology', 'experiment', 'physics']):
                rag_analysis += "Scientific/technical topics in context - Stewie's expertise area. "
            if any(term in context_lower for term in ['book', 'literature', 'politics', 'culture', 'philosophy']):
                rag_analysis += "Intellectual/cultural topics in context - Brian's expertise area. "
            if any(term in context_lower for term in ['tv', 'television', 'beer', 'food', 'chicken', 'random']):
                rag_analysis += "Simple/entertainment topics in context - Peter's interest area. "
        
        # Enhanced topic analysis using character-specific keywords
        topic_analysis = ""
        message_lower = current_message.lower()
        
        # Peter's interests: simple, crude, entertainment, food, beer, random
        peter_keywords = ['tv', 'television', 'food', 'beer', 'eat', 'hungry', 'pawtucket', 'chicken', 'funny', 'hehe', 'random', 'weird', 'freakin', 'holy crap', 'bird', 'surfin bird']
        peter_score = sum(1 for word in peter_keywords if word in message_lower)
        
        # Brian's interests: intellectual, pretentious, literary, political
        brian_keywords = ['book', 'literature', 'philosophy', 'politics', 'society', 'culture', 'art', 'intellectual', 'profound', 'meaning', 'existence', 'writer', 'novel', 'actually', 'pretentious', 'wine', 'sophisticated']
        brian_score = sum(1 for word in brian_keywords if word in message_lower)
        
        # Stewie's interests: science, technology, evil plans, sophisticated language
        stewie_keywords = ['science', 'invention', 'technology', 'experiment', 'plan', 'device', 'machine', 'robot', 'laser', 'genius', 'physics', 'chemistry', 'engineering', 'evil', 'world domination', 'blast', 'deuce', 'confound']
        stewie_score = sum(1 for word in stewie_keywords if word in message_lower)
        
        if peter_score > 0:
            topic_analysis += f"Peter-relevant topics detected (score: {peter_score}): Simple/entertainment content. "
        if brian_score > 0:
            topic_analysis += f"Brian-relevant topics detected (score: {brian_score}): Intellectual/cultural content. "
        if stewie_score > 0:
            topic_analysis += f"Stewie-relevant topics detected (score: {stewie_score}): Scientific/technological content. "
        
        # Format mentioned characters
        mentioned_text = ", ".join(mentioned_bots) if mentioned_bots else "None"
        
        # Create comprehensive conversation analysis with RAG enhancement
        conversation_analysis = f"""
RECENT CONVERSATION HISTORY:
{history_text}

CURRENT MESSAGE ANALYSIS:
- Message: "{current_message}"
- Last speaker: {last_speaker_name or "None"}
- Turn number: {current_turn}
- Directly mentioned: {mentioned_text}

SPEAKER ACTIVITY ANALYSIS:
- Recent activity count: Peter ({speaker_count['Peter']}), Brian ({speaker_count['Brian']}), Stewie ({speaker_count['Stewie']})
- Least active character: {least_active}
- Most active character: {most_active}

KEYWORD-BASED TOPIC ANALYSIS:
{topic_analysis if topic_analysis else "General conversation - no specific character triggers detected"}

RAG-ENHANCED CONTEXT ANALYSIS:
{rag_analysis if rag_analysis else "No specific Family Guy universe context retrieved"}

FAMILY GUY UNIVERSE KNOWLEDGE:
{rag_context[:500] + "..." if len(rag_context) > 500 else rag_context if rag_context else "No relevant Family Guy wiki context available"}

CHARACTER REACTION PREDICTIONS:
- Would Peter relate to this based on his personality and the context?
- Would Brian want to correct/analyze this based on his intellectual nature?
- Would Stewie be triggered to respond based on his interests and ego?
- Does the Family Guy universe context suggest any character has special knowledge/connection to this topic?
- Who would naturally have the strongest reaction considering both personality and background knowledge?
        """
        
        # Call the enhanced coordinator LLM
        print("üß† RAG-Enhanced Conversation Coordinator: Analyzing with full character profiles + Family Guy universe knowledge...")
        coordinator_response = conversation_coordinator_chain.invoke({
            "conversation_analysis": conversation_analysis
        })
        
        # Clean and validate the response
        selected_character = clean_llm_response(coordinator_response).strip()
        
        # Improve parsing - extract character name from potentially detailed response
        # Look for character names in the response
        response_lower = selected_character.lower()
        if 'peter' in response_lower:
            selected_character = 'Peter'
        elif 'brian' in response_lower:
            selected_character = 'Brian'
        elif 'stewie' in response_lower:
            selected_character = 'Stewie'
        
        # Ensure the response is a valid character name
        if selected_character in BOT_CONFIGS:
            print(f"üé≠ RAG-Enhanced Coordinator: Selected {selected_character} based on detailed analysis")
            print(f"   üìä Topic relevance: {topic_analysis if topic_analysis else 'General conversation'}")
            print(f"   üîç RAG insights: {rag_analysis if rag_analysis else 'No specific universe context'}")
            print(f"   ‚öñÔ∏è Speaker balance: Peter({speaker_count['Peter']}), Brian({speaker_count['Brian']}), Stewie({speaker_count['Stewie']})")
            return selected_character
        else:
            print(f"ü§ñ RAG-Enhanced Coordinator: Invalid selection '{selected_character}', falling back to rule-based selection")
            return None
            
    except Exception as e:
        print(f"ü§ñ RAG-Enhanced Coordinator: Error during intelligent selection: {e}")
        print(traceback.format_exc())
        return None

# Function to generate conversation starters using the enhanced character-specific prompt
def generate_conversation_starter(initiator_bot_name, recent_history):
    """Generate a conversation starter using the full character description and RAG context."""
    try:
        # üîç RAG-ENHANCED STARTER GENERATION
        # Retrieve some general Family Guy context to inspire conversation starters
        rag_context = ""
        if recent_history:
            # Create a query from recent conversation to get relevant context
            recent_topics = []
            for msg in recent_history[-3:]:  # Last 3 messages
                if isinstance(msg, (HumanMessage, AIMessage)):
                    recent_topics.append(msg.content)
            
            if recent_topics:
                query_for_rag = " ".join(recent_topics)
                print(f"üîç RAG Starter: Retrieving context for conversation inspiration based on recent topics...")
                rag_context = retrieve_context(query_for_rag, num_results=2)
            else:
                # If no recent topics, get general Family Guy context
                print(f"üîç RAG Starter: Retrieving general Family Guy context for inspiration...")
                rag_context = retrieve_context(f"{initiator_bot_name} Griffin Family Guy", num_results=2)
        else:
            # No recent history, get character-specific context
            print(f"üîç RAG Starter: Retrieving {initiator_bot_name}-specific context for starter inspiration...")
            rag_context = retrieve_context(f"{initiator_bot_name} Griffin Family Guy", num_results=2)
        
        starter_prompt = create_starter_generation_prompt(initiator_bot_name)
        starter_chain = starter_prompt | shared_llm
        
        # Enhance recent history with RAG context
        enhanced_history = recent_history.copy() if recent_history else []
        if rag_context:
            # Add RAG context as a system-like message for inspiration
            rag_inspiration = HumanMessage(content=f"[FAMILY GUY UNIVERSE CONTEXT FOR INSPIRATION: {rag_context[:300]}...]")
            enhanced_history.append(rag_inspiration)
        
        generated_starter = starter_chain.invoke({
            "recent_history": enhanced_history
        }).strip()
        
        if generated_starter and rag_context:
            print(f"üîç RAG Starter: Generated starter with Family Guy universe inspiration: '{generated_starter[:50]}...'")
        elif generated_starter:
            print(f"üìù Generated starter without RAG context: '{generated_starter[:50]}...'")
        
        return clean_llm_response(generated_starter) if generated_starter else None
    except Exception as e:
        print(f"Error generating conversation starter for {initiator_bot_name}: {e}")
        print(traceback.format_exc())
        return None

# --- Organic Conversation Coordinator ---
class OrganicConversationCoordinator:
    """
    Manages organic conversation initiation based on context and natural flow rather than rigid schedules.
    Enhanced to handle follow-up conversations where other bots naturally join in.
    """
    
    def __init__(self):
        self.last_organic_attempt = None
        self.last_follow_up_attempt = None
        self.weekly_crawl_check_interval = 24 * 60 * 60  # Check for weekly crawl every 24 hours
        self.last_crawl_check = None
    
    def should_start_follow_up_conversation(self, channel_id):
        """
        Determines if a follow-up conversation should be started after a recent bot response.
        This is more aggressive than organic conversations and looks for immediate opportunities.
        """
        try:
            if not ENABLE_FOLLOW_UP_CONVERSATIONS:
                return False
                
            now = datetime.now()
            
            # Check minimum time between follow-up attempts (but allow exceptions for strong triggers)
            if self.last_follow_up_attempt:
                time_since_last = (now - self.last_follow_up_attempt).total_seconds()
                if time_since_last < MIN_TIME_BETWEEN_FOLLOW_UPS:
                    # Get recent messages to check for strong triggers that might override timing
                    recent_messages = list(conversations_collection.find({
                        "channel_id": channel_id
                    }).sort("timestamp", -1).limit(3))
                    
                    # Check if there are very strong triggers that justify immediate follow-up
                    if recent_messages and self._has_strong_follow_up_triggers(recent_messages):
                        print(f"üîÑ Follow-up Coordinator: Strong triggers detected, overriding timing constraint ({time_since_last:.1f}s)")
                    else:
                        print(f"üîÑ Follow-up Coordinator: Too soon since last follow-up ({time_since_last:.1f}s < {MIN_TIME_BETWEEN_FOLLOW_UPS}s)")
                        return False
            
            # Get the last few messages to analyze for follow-up opportunities
            recent_messages = list(conversations_collection.find({
                "channel_id": channel_id
            }).sort("timestamp", -1).limit(5))
            
            if not recent_messages:
                return False
            
            # Check if the last message was from a bot (not a user)
            last_message = recent_messages[0]
            if last_message.get("role") != "assistant":
                print(f"üîÑ Follow-up Coordinator: Last message was from user, not suitable for follow-up")
                return False
            
            # Check if the last message was very recent (within last 30 seconds)
            time_since_last_message = (now - last_message["timestamp"]).total_seconds()
            if time_since_last_message > 30:
                print(f"üîÑ Follow-up Coordinator: Last bot message too old ({time_since_last_message:.1f}s)")
                return False
            
            # Analyze if the conversation content suggests other characters would want to respond
            if self._analyze_for_follow_up_triggers(recent_messages):
                print(f"üîÑ Follow-up Coordinator: Content analysis suggests follow-up conversation would be natural")
                return True
            
            return False
            
        except Exception as e:
            print(f"üîÑ Follow-up Coordinator: Error in should_start_follow_up_conversation: {e}")
            return False

    def should_start_organic_conversation(self, channel_id):
        """
        Determines if an organic conversation should be started based on intelligent criteria.
        """
        try:
            now = datetime.now()
            
            # Get recent conversation activity
            recent_cutoff = now - timedelta(minutes=CONVERSATION_SILENCE_THRESHOLD_MINUTES)
            recent_messages = list(conversations_collection.find({
                "channel_id": channel_id,
                "timestamp": {"$gte": recent_cutoff}
            }).sort("timestamp", -1))
            
            # Don't start if there's been recent activity
            if recent_messages:
                print(f"ü§ñ Organic Coordinator: Recent activity detected, no need for organic conversation")
                return False
            
            # Check minimum time between organic attempts
            if self.last_organic_attempt:
                time_since_last = (now - self.last_organic_attempt).total_seconds() / 60
                if time_since_last < MIN_TIME_BETWEEN_ORGANIC_CONVERSATIONS:
                    print(f"ü§ñ Organic Coordinator: Too soon since last attempt ({time_since_last:.1f} min < {MIN_TIME_BETWEEN_ORGANIC_CONVERSATIONS} min)")
                    return False
            
            # Get longer conversation history for context analysis
            history_cutoff = now - timedelta(hours=2)  # Last 2 hours for context
            conversation_history = list(conversations_collection.find({
                "channel_id": channel_id,
                "timestamp": {"$gte": history_cutoff}
            }).sort("timestamp", -1).limit(10))
            
            # Analyze conversation patterns for organic triggers
            if self._analyze_conversation_for_organic_triggers(conversation_history):
                print(f"ü§ñ Organic Coordinator: Conversation analysis suggests organic conversation would be beneficial")
                return True
            
            # If it's been silent for a while, consider starting something
            if not recent_messages:
                last_message = conversations_collection.find_one(
                    {"channel_id": channel_id},
                    sort=[("timestamp", -1)]
                )
                
                if last_message:
                    silence_duration = (now - last_message["timestamp"]).total_seconds() / 60
                    if silence_duration > CONVERSATION_SILENCE_THRESHOLD_MINUTES:
                        print(f"ü§ñ Organic Coordinator: {silence_duration:.1f} minutes of silence, considering organic conversation")
                        return True
                
            return False
            
        except Exception as e:
            print(f"ü§ñ Organic Coordinator: Error in should_start_organic_conversation: {e}")
            return False
    
    def _analyze_for_follow_up_triggers(self, recent_messages):
        """
        Analyzes recent messages to determine if other characters would naturally want to respond.
        This is more aggressive than organic triggers and looks for immediate reaction opportunities.
        """
        if not recent_messages:
            return False
        
        last_message = recent_messages[0]
        last_speaker = last_message.get("name", "").lower()
        last_content = last_message.get("content", "").lower()
        
        # Character-specific follow-up triggers
        follow_up_triggers = {
            "peter": {
                # Other characters likely to respond to Peter
                "brian_triggers": [
                    "stupid", "dumb", "idiot", "wrong", "beer", "tv", "chicken", "surfin bird",
                    "pawtucket", "lois", "meg", "intellectual", "smart", "book"
                ],
                "stewie_triggers": [
                    "baby", "diaper", "stupid", "fat man", "lois", "mother", "family guy",
                    "invention", "plan", "evil", "world"
                ]
            },
            "brian": {
                # Other characters likely to respond to Brian
                "peter_triggers": [
                    "intellectual", "smart", "book", "culture", "politics", "sophisticated",
                    "pretentious", "dog", "writer", "novel", "philosophy", "wine"
                ],
                "stewie_triggers": [
                    "intellectual", "culture", "book", "philosophy", "science", "invention",
                    "sophisticated", "british", "genius", "plan"
                ]
            },
            "stewie": {
                # Other characters likely to respond to Stewie
                "peter_triggers": [
                    "baby", "evil", "plan", "invention", "british", "smart", "genius",
                    "mother", "lois", "family", "stupid", "fat man", "global domination",
                    "world domination", "victory is mine", "blast", "take over", "plans"
                ],
                "brian_triggers": [
                    "intellectual", "genius", "science", "invention", "philosophy", "culture",
                    "sophisticated", "british", "plan", "evil"
                ]
            }
        }
        
        # Check if the last message contains triggers that would make other characters want to respond
        if last_speaker in follow_up_triggers:
            triggers = follow_up_triggers[last_speaker]
            
            for responding_character, trigger_words in triggers.items():
                if any(trigger in last_content for trigger in trigger_words):
                    print(f"üîÑ Follow-up Analysis: {last_speaker}'s message contains triggers for {responding_character}: {[t for t in trigger_words if t in last_content]}")
                    return True
        
        # Look for direct questions or statements that invite responses
        response_inviting_patterns = [
            "what do you think", "don't you think", "right?", "you know?", "isn't that",
            "what about", "remember when", "speaking of", "by the way", "actually",
            "question", "wonder", "curious", "thoughts?", "opinions?", "agree?",
            "hehehe", "hehe", "funny", "ridiculous", "stupid", "smart", "brilliant",
            "do share", "tell me", "have you", "plans to", "going to", "victory is mine"
        ]
        
        if any(pattern in last_content for pattern in response_inviting_patterns):
            print(f"üîÑ Follow-up Analysis: Last message contains response-inviting patterns: {[p for p in response_inviting_patterns if p in last_content]}")
            return True
        
        # Look for controversial or debate-worthy statements
        controversial_topics = [
            "politics", "religion", "stupid", "smart", "wrong", "right", "best", "worst",
            "hate", "love", "better", "worse", "always", "never", "everyone", "nobody"
        ]
        
        if any(topic in last_content for topic in controversial_topics):
            print(f"üîÑ Follow-up Analysis: Last message contains controversial topics that might spark responses")
            return True
        
        # Check message length - very short messages might not inspire follow-ups
        if len(last_content.strip()) < 20:
            print(f"üîÑ Follow-up Analysis: Last message too short to inspire follow-ups")
            return False
        
        # Default: if we've gotten this far and the message is substantial, there's a chance for follow-up
        if len(last_content.strip()) > 50:
            print(f"üîÑ Follow-up Analysis: Substantial message detected, moderate chance for follow-up")
            return True
        
        return False

    def _has_strong_follow_up_triggers(self, recent_messages):
        """
        Checks for very strong triggers that justify immediate follow-up responses,
        overriding normal timing constraints.
        """
        if not recent_messages:
            return False
        
        last_message = recent_messages[0]
        last_content = last_message.get("content", "").lower()
        last_speaker = last_message.get("name", "").lower()
        
        # Very strong triggers that almost always warrant immediate responses
        strong_triggers = [
            # Direct questions or challenges
            "what do you think", "don't you think", "right?", "agree?", "disagree?",
            "what about you", "your thoughts", "your opinion", "what's your",
            
            # Controversial or provocative statements
            "stupid", "idiot", "wrong", "ridiculous", "absurd", "brilliant", "genius",
            "best", "worst", "hate", "love", "better than", "worse than",
            
            # Character-specific strong triggers
            "global domination", "world domination", "evil plan", "take over",
            "chicken fight", "surfin bird", "pawtucket patriot",
            "intellectual", "sophisticated", "pretentious", "novel", "book",
            
            # Family dynamics
            "lois", "mother", "wife", "family", "griffin", "meg", "chris",
            
            # Emotional or dramatic statements
            "victory is mine", "blast", "damn", "hell", "amazing", "incredible",
            "unbelievable", "shocking", "outrageous"
        ]
        
        # Check if the message contains multiple strong triggers
        trigger_count = sum(1 for trigger in strong_triggers if trigger in last_content)
        if trigger_count >= 2:
            print(f"üî• Strong Follow-up Triggers: Multiple triggers detected ({trigger_count})")
            return True
        
        # Check for very specific character interaction triggers
        if last_speaker == "stewie":
            stewie_strong_triggers = ["global domination", "world domination", "evil plan", "victory is mine", "blast"]
            if any(trigger in last_content for trigger in stewie_strong_triggers):
                print(f"üî• Strong Follow-up Triggers: Stewie's signature phrases detected")
                return True
        
        if last_speaker == "peter":
            peter_strong_triggers = ["chicken fight", "surfin bird", "hehehe", "pawtucket", "bird is the word"]
            if any(trigger in last_content for trigger in peter_strong_triggers):
                print(f"üî• Strong Follow-up Triggers: Peter's signature phrases detected")
                return True
        
        if last_speaker == "brian":
            brian_strong_triggers = ["intellectual", "sophisticated", "novel", "pretentious", "culture"]
            if any(trigger in last_content for trigger in brian_strong_triggers):
                print(f"üî• Strong Follow-up Triggers: Brian's intellectual topics detected")
                return True
        
        # Check for direct questions
        question_patterns = ["?", "what", "how", "why", "when", "where", "who"]
        if "?" in last_content and any(pattern in last_content for pattern in question_patterns):
            print(f"üî• Strong Follow-up Triggers: Direct question detected")
            return True
        
        return False

    def _analyze_conversation_for_organic_triggers(self, conversation_history):
        """
        Analyzes recent conversation for patterns that suggest an organic conversation would be natural.
        """
        if not conversation_history:
            return False
        
        # Look for conversation endpoints or natural breaks
        recent_messages = conversation_history[:3]  # Last 3 messages
        
        for msg in recent_messages:
            content = msg.get("content", "").lower()
            
            # Look for conversation-ending phrases
            ending_phrases = [
                "see you later", "goodbye", "gotta go", "talk later", 
                "that's all", "anyway", "well", "ok then", "alright"
            ]
            
            if any(phrase in content for phrase in ending_phrases):
                print(f"ü§ñ Organic Coordinator: Detected conversation ending phrase in recent messages")
                return True
        
        # Look for incomplete thoughts or unresolved topics
        all_content = " ".join([msg.get("content", "") for msg in conversation_history])
        content_lower = all_content.lower()
        
        # Topics that might inspire follow-up conversations
        follow_up_triggers = [
            "question", "wonder", "think about", "reminds me", "speaking of",
            "by the way", "actually", "wait", "oh", "you know what"
        ]
        
        if any(trigger in content_lower for trigger in follow_up_triggers):
            print(f"ü§ñ Organic Coordinator: Detected potential follow-up conversation triggers")
            return True
        
        return False
    
    def initiate_follow_up_conversation(self, channel_id):
        """
        Initiates a follow-up conversation where another character responds to the recent bot message.
        """
        try:
            self.last_follow_up_attempt = datetime.now()
            print(f"üîÑ Follow-up Coordinator: Initiating follow-up conversation at {datetime.now().strftime('%H:%M:%S')}")
            
            # Get recent conversation history
            recent_history = []
            recent_messages = []
            try:
                all_channel_messages = list(conversations_collection.find({"channel_id": channel_id}).sort("timestamp", -1).limit(10))
                recent_messages = all_channel_messages
                recent_history_raw = list(reversed(all_channel_messages))
                for msg_doc in recent_history_raw:
                    if msg_doc["role"] == "user":
                        recent_history.append(HumanMessage(content=msg_doc["content"]))
                    elif msg_doc["role"] == "assistant":
                        recent_history.append(AIMessage(content=msg_doc["content"], name=msg_doc.get("name")))
            except PyMongoError as e:
                print(f"MongoDB error fetching recent history for follow-up conversation: {e}")
                return False

            if not recent_messages:
                print(f"üîÑ Follow-up Coordinator: No recent messages found")
                return False
            
            # Determine which character should respond based on the last message
            last_message = recent_messages[0]
            last_speaker = last_message.get("name", "").lower()
            
            # Select a different character to respond (exclude the last speaker)
            available_characters = [name for name in BOT_CONFIGS.keys() if name.lower() != last_speaker]
            if not available_characters:
                print(f"üîÑ Follow-up Coordinator: No other characters available to respond")
                return False
            
            # For follow-ups, we want a different character than the last speaker
            # Use simple selection from available characters to avoid the same character responding
            follow_up_speaker = random.choice(available_characters)
            print(f"üîÑ Follow-up Coordinator: Selected different character for follow-up: {follow_up_speaker} (last speaker was {last_speaker})")
            
            follow_up_bot_config = BOT_CONFIGS[follow_up_speaker]
            
            # Create a follow-up prompt based on the last message
            last_content = last_message.get("content", "")
            follow_up_prompt = f"Respond to what {last_speaker} just said: \"{last_content}\""
            
            try:
                # Use the same session ID to continue the conversation
                current_session_id = last_message.get("conversation_session_id", str(uuid.uuid4()))
                initiate_payload = {
                    "user_query": follow_up_prompt,
                    "channel_id": channel_id,
                    "initiator_bot_name": follow_up_speaker,
                    "initiator_mention": follow_up_bot_config["mention"],
                    "human_user_display_name": None,
                    "is_new_conversation": False,
                    "conversation_session_id": current_session_id,
                    "is_follow_up": True,
                    "forced_speaker": follow_up_speaker
                }
                
                response = requests.post(ORCHESTRATOR_API_URL, json=initiate_payload, timeout=120)
                response.raise_for_status()
                print(f"üîÑ Follow-up Coordinator: Successfully initiated follow-up conversation with {follow_up_speaker}")
                return True
            except Exception as e:
                print(f"ERROR: Follow-up Coordinator: Failed to initiate follow-up conversation: {e}")
                return False
                
        except Exception as e:
            print(f"ERROR: Follow-up Coordinator: Critical error in initiate_follow_up_conversation: {e}")
            print(traceback.format_exc())
            return False

    def initiate_organic_conversation(self, channel_id):
        """
        Initiates an organic conversation using intelligent selection and RAG-enhanced starters.
        """
        try: # Outer try for the whole method
            self.last_organic_attempt = datetime.now()
            print(f"üå± Organic Coordinator: Initiating organic conversation at {datetime.now().strftime('%H:%M:%S')}")
            
            recent_history = []
            try: # Inner try for MongoDB access
                all_channel_messages = list(conversations_collection.find({"channel_id": channel_id}).sort("timestamp", -1).limit(10))
                recent_history_raw = list(reversed(all_channel_messages))
                for msg_doc in recent_history_raw:
                    if msg_doc["role"] == "user":
                        recent_history.append(HumanMessage(content=msg_doc["content"]))
                    elif msg_doc["role"] == "assistant":
                        recent_history.append(AIMessage(content=msg_doc["content"], name=msg_doc.get("name")))
            except PyMongoError as e:
                print(f"MongoDB error fetching recent history for organic conversation: {e}")
                print(traceback.format_exc())
            # This inner try for MongoDB access intentionally does not return;
            # if it fails, recent_history will be empty, and the coordinator will proceed.

            print("üå± Organic Coordinator: Using intelligent selection for conversation initiator...")
            initiator_bot_name = select_conversation_initiator_intelligently(recent_history)
            
            if not initiator_bot_name:
                initiator_bot_name = random.choice(list(BOT_CONFIGS.keys()))
                print(f"üå± Organic Coordinator: Intelligent selection failed, using random fallback: {initiator_bot_name}")
            else:
                print(f"üå± Organic Coordinator: Intelligent selection chose: {initiator_bot_name}")
            
            initiator_bot_config = BOT_CONFIGS[initiator_bot_name]
            
            conversation_starter_prompt = None
            try: # Inner try for starter generation
                print(f"üå± Organic Coordinator: Generating organic conversation starter...")
                generated_starter = generate_conversation_starter(initiator_bot_name, recent_history)

                if generated_starter:
                    conversation_starter_prompt = generated_starter
                    print(f"üå± Organic Coordinator: Generated organic starter: '{conversation_starter_prompt[:50]}...'")
                else:
                    conversation_starter_prompt = random.choice(INITIAL_CONVERSATION_PROMPTS)
                    print(f"üå± Organic Coordinator: No dynamic starter generated. Falling back to static prompt: '{conversation_starter_prompt[:50]}...'")
            except Exception as e:
                print(f"ERROR: Organic Coordinator: Unexpected error generating starter: {e}. Falling back to static prompt.")
                print(traceback.format_exc())
                conversation_starter_prompt = random.choice(INITIAL_CONVERSATION_PROMPTS)

            try: # Inner try for orchestrator API call
                new_session_id = str(uuid.uuid4())
                initiate_payload = {
                    "user_query": conversation_starter_prompt,
                    "channel_id": channel_id,
                    "initiator_bot_name": initiator_bot_name,
                    "initiator_mention": initiator_bot_config["mention"],
                    "human_user_display_name": None,
                    "is_new_conversation": True,
                    "conversation_session_id": new_session_id
                }
                
                response = requests.post(ORCHESTRATOR_API_URL, json=initiate_payload, timeout=120)
                response.raise_for_status()
                print(f"üå± Organic Coordinator: Successfully initiated organic conversation with session {new_session_id}")
                return True
            except requests.exceptions.Timeout:
                print(f"ERROR: Organic Coordinator Timeout: Failed to initiate conversation with orchestrator.")
                return False
            except requests.exceptions.ConnectionError:
                print(f"ERROR: Organic Coordinator Connection Error: Orchestrator API might be down.")
                return False
            except Exception as e: # Catch other exceptions for this specific block
                print(f"ERROR: Organic Coordinator: Unexpected error initiating conversation: {e}")
                print(traceback.format_exc())
                return False
                
        except Exception as e: # General except for the outer try block
            print(f"ERROR: Organic Coordinator: Critical error in initiate_organic_conversation: {e}")
            print(traceback.format_exc())
            return False
    
    # Removed check_weekly_crawl(self) method from OrganicConversationCoordinator

# Global organic coordinator instance
organic_coordinator = OrganicConversationCoordinator()

def organic_conversation_monitor():
    """
    Monitors for organic and follow-up conversation opportunities and manages background tasks.
    Much lighter than the old scheduler - focuses on natural conversation flow.
    """
    global DEFAULT_DISCORD_CHANNEL_ID, organic_coordinator
    
    print(f"üå± Organic Conversation Monitor: Starting natural conversation monitoring...")
    print(f"   üîÑ Follow-up conversations: {'Enabled' if ENABLE_FOLLOW_UP_CONVERSATIONS else 'Disabled'}")
    print(f"   ‚è±Ô∏è Follow-up delay: {FOLLOW_UP_DELAY_SECONDS}s")
    print(f"   üïê Min time between follow-ups: {MIN_TIME_BETWEEN_FOLLOW_UPS}s")
    
    check_interval = 30  # Check every 30 seconds for more responsive follow-ups
    
    while True:
        try: # Try for the main loop operations
            if DEFAULT_DISCORD_CHANNEL_ID:
                # First check for follow-up opportunities (more frequent and aggressive)
                if ENABLE_FOLLOW_UP_CONVERSATIONS and organic_coordinator.should_start_follow_up_conversation(DEFAULT_DISCORD_CHANNEL_ID):
                    print(f"üîÑ Monitor: Follow-up conversation opportunity detected!")
                    success = organic_coordinator.initiate_follow_up_conversation(DEFAULT_DISCORD_CHANNEL_ID)
                    if success:
                        print(f"üîÑ Monitor: Successfully started follow-up conversation")
                    else:
                        print(f"üîÑ Monitor: Failed to start follow-up conversation")
                
                # Then check for organic opportunities (less frequent, for new conversations)
                elif organic_coordinator.should_start_organic_conversation(DEFAULT_DISCORD_CHANNEL_ID):
                    print(f"üå± Monitor: Organic conversation opportunity detected!")
                    success = organic_coordinator.initiate_organic_conversation(DEFAULT_DISCORD_CHANNEL_ID)
                    if success:
                        print(f"üå± Monitor: Successfully started organic conversation")
                    else:
                        print(f"üå± Monitor: Failed to start organic conversation")
                else:
                    # Only log this occasionally to avoid spam
                    import time
                    if int(time.time()) % 300 == 0:  # Every 5 minutes
                        print(f"üå± Monitor: No conversation opportunities at this time")
            else:
                print(f"ERROR: DEFAULT_DISCORD_CHANNEL_ID not configured, cannot monitor for conversations")
            
        except Exception as e: # Catch exceptions from the main loop operations
            print(f"ERROR: Conversation Monitor: Unexpected error in monitoring loop: {e}")
            print(traceback.format_exc())
        
        # Wait before next check - ensure this is outside the try-except for the main operations
        # so that the loop continues even if an error occurs in the try block.
        time.sleep(check_interval)

def validate_character_response(character_name, response_text):
    """
    Validates that a character response is appropriate and in-character.
    Returns (is_valid, corrected_response) tuple.
    """
    try:
        # Check for empty or too short responses
        if not response_text or len(response_text.strip()) < 3:
            return False, None
        
        response_lower = response_text.lower()
        
        # üö® CRITICAL: Check for AI indicators or meta-references (ENHANCED)
        ai_indicators = [
            "ai (as", "ai as", "assistant", "language model", "i am an ai",
            "as an ai", "i'm an ai", "artificial intelligence", "chatbot",
            "i am a bot", "i'm a bot", "generated by", "powered by",
            "ai (", "ai:", "ai ", "(as ", "as an assistant", "as a language",
            "i'm programmed", "my programming", "i was created", "i was designed",
            "ai generated", "artificial", "bot response", "automated"
        ]
        
        for indicator in ai_indicators:
            if indicator in response_lower:
                print(f"üö® CRITICAL: AI indicator detected in {character_name} response: '{indicator}'")
                return False, None
        
        # üö® CRITICAL: Enhanced third-person self-reference detection
        character_lower = character_name.lower()
        third_person_self_patterns = [
            f'{character_lower} thinks',
            f'{character_lower} says',
            f'{character_lower} looks',
            f'{character_lower} feels',
            f'{character_lower} walks',
            f'{character_lower} goes',
            f'{character_lower} responds',
            f'{character_lower} replies',
            f'{character_lower} turns to',
            f'{character_lower} decides',
            f'{character_lower} realizes',
            f'{character_lower} notices',
            f'{character_lower} remembers',
            f'{character_lower} wonders',
            f'{character_lower} considers',
            f'{character_lower} believes',
            f'{character_lower} knows',
            f'{character_lower} understands',
            f'{character_lower} wants',
            f'{character_lower} needs',
            f'{character_lower} has',
            f'{character_lower} is',
            f'{character_lower} was',
            f'{character_lower} will',
            f'{character_lower} would',
            f'{character_lower} should',
            f'{character_lower} could',
            f'{character_lower} might',
            f'{character_lower}\'s',  # Possessive forms
            f'to {character_lower}',
            f'for {character_lower}',
            f'with {character_lower}',
            f'about {character_lower}',
            # Special cases for specific characters
            f'stewie\'s latest',
            f'stewie\'s invention',
            f'stewie\'s plan',
            f'peter\'s',
            f'brian\'s'
        ]
        
        for pattern in third_person_self_patterns:
            if pattern in response_lower:
                print(f"üö® CRITICAL: Third-person self-reference detected in {character_name} response: '{pattern}'")
                return False, None
        
        # Check for character identity confusion (speaking as other characters)
        
        # Detect if character is speaking AS another character
        identity_violations = []
        if character_name == "Peter":
            if "as for me, brian" in response_lower or "speaking of me, brian" in response_lower:
                identity_violations.append("Peter speaking as Brian")
            if "as for me, stewie" in response_lower or "speaking of me, stewie" in response_lower:
                identity_violations.append("Peter speaking as Stewie")
        elif character_name == "Brian":
            if "as for me, peter" in response_lower or "speaking of me, peter" in response_lower:
                identity_violations.append("Brian speaking as Peter")
            if "as for me, stewie" in response_lower or "speaking of me, stewie" in response_lower:
                identity_violations.append("Brian speaking as Stewie")
        elif character_name == "Stewie":
            if "as for me, peter" in response_lower or "speaking of me, peter" in response_lower:
                identity_violations.append("Stewie speaking as Peter")
            if "as for me, brian" in response_lower or "speaking of me, brian" in response_lower:
                identity_violations.append("Stewie speaking as Brian")
        
        if identity_violations:
            print(f"‚ö†Ô∏è Identity violation detected for {character_name}: {identity_violations}")
            return False, None
        
        # üö® CRITICAL: Discord message length validation (2000 character limit)
        if len(response_text) > 1900:  # Leave buffer for safety
            print(f"üö® CRITICAL: Response too long for Discord: {len(response_text)} characters (limit: 2000)")
            return False, None
        
        # Check for inappropriate length by character (RELAXED - let adaptive system handle this)
        # Only reject extremely long responses that would break Discord
        if len(response_text) > 1500:  # Much more lenient - let adaptive system handle normal length control
            print(f"‚ö†Ô∏è {character_name} response extremely long: {len(response_text)} characters (Discord limit)")
            return False, None
        
        # Check for vocabulary mismatch
        if character_name == "Peter":
            # Peter shouldn't use sophisticated words
            sophisticated_words = [
                "sophisticated", "intellectual", "erudite", "profoundly", 
                "philosophical", "contemplating", "astounding", "fascinating"
            ]
            for word in sophisticated_words:
                if word in response_lower:
                    print(f"‚ö†Ô∏è Peter using sophisticated word: {word}")
                    return False, None
        
        elif character_name == "Brian":
            # Brian should use intellectual language
            if len(response_text) > 50 and not any(word in response_lower for word in [
                "actually", "indeed", "quite", "rather", "certainly", "perhaps", "literature", "culture"
            ]):
                # This might be okay, but let's check if it's too simple for Brian
                simple_indicators = ["hehehe", "freakin", "awesome", "stupid"]
                if any(indicator in response_lower for indicator in simple_indicators):
                    print(f"‚ö†Ô∏è Brian response too simple")
                    return False, None
        
        elif character_name == "Stewie":
            # Stewie should have British mannerisms, but be more lenient for short responses
            british_phrases = [
                "blast", "deuce", "what the", "indeed", "quite", "rather", "brilliant", "fool", "imbecile",
                "bloody", "blimey", "bollocks", "poppycock", "balderdash", "smashing", "jolly", "by jove"
            ]
            # Only require British mannerisms for longer responses (>50 chars) to allow natural short replies
            if len(response_text) > 50 and not any(phrase in response_lower for phrase in british_phrases):
                print(f"‚ö†Ô∏è Stewie response lacks British mannerisms")
                return False, None
        
        # Check for Cleveland confusion
        if "cleveland" in response_lower and "dog" in response_lower:
            print(f"‚ö†Ô∏è Cleveland/dog confusion detected")
            return False, None
        
        # üéØ ENHANCED: Check for problematic self-reference prefixes (but allow quoting other characters)
        character_lower = character_name.lower()
        
        # ALWAYS problematic patterns (regardless of character)
        always_problematic = [
            r'^me:\s*',  # "Me:" at start
            r'^(i am |this is |it\'s )(peter|brian|stewie)(\s+griffin)?[\.,:]?\s*',  # "I am Peter Griffin:" at start
        ]
        
        for pattern in always_problematic:
            if re.search(pattern, response_lower):
                match = re.search(pattern, response_lower)
                print(f"üö® CRITICAL: Always problematic prefix detected in {character_name} response: '{match.group()}'")
                return False, None
        
        # SELF-reference patterns (only problematic if character references themselves)
        self_reference_patterns = [
            f'^{character_lower}:\\s*',  # "Peter:" at start (only if Peter is speaking)
            f'^{character_lower}\\s+griffin:\\s*',  # "Peter Griffin:" at start
            f'^@{character_lower}(\\s+griffin)?\\s*:?\\s*',  # "@Peter Griffin:" at start
        ]
        
        for pattern in self_reference_patterns:
            if re.search(pattern, response_lower):
                match = re.search(pattern, response_lower)
                print(f"üö® CRITICAL: Self-reference prefix detected in {character_name} response: '{match.group()}'")
                return False, None
        
        # Enhanced validation: Check for direct addressing of other characters
        # Characters should speak as themselves, not TO other characters directly
        direct_addressing_patterns = [
            r'\b(peter|brian|stewie|lois|meg|chris|quagmire|cleveland)\s*[,:]',  # "Peter," or "Brian:"
            r'@\s*(peter|brian|stewie)',  # "@Peter" mentions
            r'@\s*(peter|brian|stewie)\s+(griffin|bot)',  # "@Peter Griffin" mentions
            r'\b(hey|hi|hello)\s+(peter|brian|stewie|lois|meg|chris)',  # "Hey Peter"
            r'\b(peter|brian|stewie|lois|meg|chris)\s+(you\b|your\b)',  # "Peter you" or "Brian your"
            r'\b(peter|brian|stewie)\s+(dear|old)\s+(boy|chap|friend)',  # "Brian dear boy", "Stewie old chap"
            r'\b(well|look|listen),?\s+(peter|brian|stewie)',  # "Well, Peter" or "Look, Brian"
        ]
        
        # Only check for self-addressing patterns (characters shouldn't address themselves)
        self_addressing_patterns = [
            r'@\s*(peter|brian|stewie)',  # "@Peter" mentions
            r'@\s*(peter|brian|stewie)\s+(griffin|bot)',  # "@Peter Griffin" mentions
        ]
        
        for pattern in self_addressing_patterns:
            if re.search(pattern, response_lower):
                match = re.search(pattern, response_lower)
                if match:
                    addressed_name = None
                    for group in match.groups():
                        if group and group.lower() in ['peter', 'brian', 'stewie']:
                            addressed_name = group.lower()
                            break
                    
                    # Only block if character is addressing themselves
                    if addressed_name and addressed_name == character_name.lower():
                        print(f"‚ö†Ô∏è {character_name} addressing themselves: {match.group()}")
                        return False, None
        
        # Check for dialogue formatting that suggests multiple speakers (RELAXED)
        # Only check for obvious stage directions, not normal punctuation
        dialogue_violations = [
            '[' in response_text and ']' in response_text and any(action in response_lower for action in ['looks at', 'turns to', 'walks to', 'says to']),  # Stage directions like [Brian looks at Peter]
            response_text.count(':') >= 3,  # Multiple colons (3+) suggesting extensive dialogue
            # Allow normal quotes and single colons for natural speech
        ]
        
        if any(dialogue_violations):
            print(f"‚ö†Ô∏è {character_name} response contains obvious dialogue formatting")
            return False, None
        
        # Check for mixed character conversation patterns
        # Look for patterns that suggest multiple characters speaking in one response
        mixed_conversation_patterns = [
            # Multiple character names followed by colons (dialogue format)
            r'(peter|brian|stewie|lois|meg|chris):\s*[^:]+\s*(peter|brian|stewie|lois|meg|chris):',
            # Character name followed by "said" or "says" (narrative format)
            r'(peter|brian|stewie|lois|meg|chris)\s+(said|says|replied|responded)',
            # Multiple instances of character names in conversational context
            r'(peter|brian|stewie)\s+.{10,50}\s+(peter|brian|stewie)\s+.{10,50}\s+(peter|brian|stewie)',
            # Conversation back-and-forth indicators
            r'(peter|brian|stewie).{5,30}(replied|responded|answered|said).{5,30}(peter|brian|stewie)',
            # Multiple quoted speech sections with character attribution
            r'"[^"]+"\s*(peter|brian|stewie).{0,20}"[^"]+"\s*(peter|brian|stewie)',
        ]
        
        for pattern in mixed_conversation_patterns:
            matches = re.findall(pattern, response_lower, re.IGNORECASE)
            if matches:
                # Check if it involves other characters (not just self-reference)
                for match in matches:
                    if isinstance(match, tuple):
                        involved_chars = [name.lower() for name in match if name]
                    else:
                        involved_chars = [match.lower()]
                    
                    # If multiple different characters are mentioned in conversation context
                    unique_chars = set(involved_chars)
                    if len(unique_chars) > 1 or (len(unique_chars) == 1 and list(unique_chars)[0] != character_name.lower()):
                        print(f"‚ö†Ô∏è {character_name} response contains mixed character conversation: {matches}")
                        return False, None
        
        # Check for narrative/descriptive text about multiple characters
        narrative_patterns = [
            # "Brian looks at Peter" type descriptions
            r'(peter|brian|stewie|lois|meg|chris)\s+(looks|turns|walks|goes|says|tells|asks)\s+(to|at|toward)?\s*(peter|brian|stewie|lois|meg|chris)',
            # "Peter and Brian" type multi-character descriptions
            r'(peter|brian|stewie)\s+and\s+(peter|brian|stewie)\s+(both|together|simultaneously)',
            # Scene descriptions with multiple characters
            r'(peter|brian|stewie).{10,50}(while|as|when)\s+(peter|brian|stewie)',
        ]
        
        for pattern in narrative_patterns:
            matches = re.findall(pattern, response_lower, re.IGNORECASE)
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        involved_chars = [name.lower() for name in match if name and name.lower() in ['peter', 'brian', 'stewie', 'lois', 'meg', 'chris']]
                        unique_chars = set(involved_chars)
                        if len(unique_chars) > 1:
                            print(f"‚ö†Ô∏è {character_name} response contains multi-character narrative: {match}")
                            return False, None
        
        # Check for third-person self-reference (should speak in first person)
        third_person_patterns = [
            f'{character_name.lower()} thinks',
            f'{character_name.lower()} says',
            f'{character_name.lower()} looks',
            f'{character_name.lower()} feels',
            f'{character_name.lower()} walks',
            f'{character_name.lower()} goes',
            f'{character_name.lower()} responds',
            f'{character_name.lower()} replies',
            f'{character_name.lower()} turns to',
            f'{character_name.lower()}\'s plan',
            f'{character_name.lower()}\'s idea',
            f'{character_name.lower()}\'s invention',
            f'{character_name.lower()}\'s latest',
            f'{character_name.lower()}\'s approach',
            f'{character_name.lower()}\'s strategy',
            f'{character_name.lower()}\'s method',
            f'{character_name.lower()} griffin',  # "Stewie Griffin" self-reference
        ]
        
        for pattern in third_person_patterns:
            if pattern in response_lower:
                print(f"‚ö†Ô∏è {character_name} speaking in third person: {pattern}")
                return False, None
        
        # Response passes validation
        return True, response_text
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error validating response: {e}")
        return True, response_text  # Allow response if validation fails

# Enhanced Quality Control for Natural Conversation Flow
def _assess_conversation_flow_quality(character_name, response_text, conversation_context, last_speaker=None):
    """
    Advanced conversation flow assessment to prevent bots from talking to themselves
    and ensure natural conversation progression.
    Returns a quality score 1-100 and detailed feedback. Only scores 75+ are acceptable.
    """
    try:
        score = 50.0  # Start with neutral score (middle of 1-100 scale)
        issues = []
        strengths = []
        
        response_lower = response_text.lower()
        
        # 1. SELF-CONVERSATION DETECTION (Critical Issue)
        if last_speaker and last_speaker.lower() == character_name.lower():
            # Check if this response seems to continue the same thought/topic
            # without acknowledging it's a different turn
            self_continuation_indicators = [
                "also", "and", "furthermore", "additionally", "moreover",
                "speaking of which", "on that note", "by the way",
                "oh and", "plus", "another thing"
            ]
            
            if any(indicator in response_lower for indicator in self_continuation_indicators):
                score -= 40.0  # Major penalty in 1-100 scale
                issues.append("Appears to be continuing own previous thought without natural break")
        
        # 2. AI INDICATOR AND META-REFERENCE CHECK (CRITICAL)
        ai_meta_indicators = [
            "ai (as", "ai as", "assistant", "language model", "i am an ai",
            "as an ai", "i'm an ai", "artificial intelligence", "chatbot",
            "i am a bot", "i'm a bot", "generated by", "powered by",
            "ai (", "ai:", "ai ", "(as ", "as an assistant", "as a language",
            "i'm programmed", "my programming", "i was created", "i was designed",
            "ai generated", "artificial", "bot response", "automated"
        ]
        
        for indicator in ai_meta_indicators:
            if indicator in response_lower:
                score = 1.0  # Automatic failure (lowest score)
                issues.append(f"CRITICAL: Contains AI indicator '{indicator}'")
                break
        
        # 3. THIRD-PERSON SELF-REFERENCE CHECK (CRITICAL)
        character_lower = character_name.lower()
        third_person_patterns = [
            f'{character_lower} thinks', f'{character_lower} says', f'{character_lower} looks',
            f'{character_lower} feels', f'{character_lower} walks', f'{character_lower} goes',
            f'{character_lower} responds', f'{character_lower} replies', f'{character_lower} turns to',
            f'{character_lower} decides', f'{character_lower} realizes', f'{character_lower} notices',
            f'{character_lower}\'s latest', f'{character_lower}\'s invention', f'{character_lower}\'s plan',
            f'{character_lower}\'s idea', f'{character_lower}\'s approach', f'{character_lower}\'s strategy',
            f'{character_lower} griffin',  # "Stewie Griffin" self-reference
            f'@{character_lower}',  # "@stewie" self-mention
            f'@{character_lower} griffin',  # "@stewie griffin" self-mention
        ]
        
        for pattern in third_person_patterns:
            if pattern in response_lower:
                score -= 40.0  # Major penalty in 1-100 scale
                issues.append(f"CRITICAL: Third-person self-reference '{pattern}'")
        
        # 4. PROBLEMATIC PREFIX CHECK (CRITICAL)
        # Check for self-reference prefixes (but allow quoting other characters)
        character_lower = character_name.lower()
        
        # ALWAYS problematic patterns (regardless of character)
        always_problematic_patterns = [
            r'^me:\s*',  # "Me:" at start
            r'^(i am |this is |it\'s )(peter|brian|stewie)(\s+griffin)?[\.,:]?\s*',  # "I am Peter Griffin:" at start
        ]
        
        for pattern in always_problematic_patterns:
            if re.search(pattern, response_lower):
                score = 1.0  # Automatic failure
                issues.append(f"CRITICAL: Always problematic prefix detected: '{re.search(pattern, response_lower).group()}'")
                break
        
        # SELF-reference patterns (only problematic if character references themselves)
        self_reference_patterns = [
            f'^{character_lower}:\\s*',  # "Peter:" at start (only if Peter is speaking)
            f'^{character_lower}\\s+griffin:\\s*',  # "Peter Griffin:" at start
            f'^@{character_lower}(\\s+griffin)?\\s*:?\\s*',  # "@Peter Griffin:" at start
        ]
        
        for pattern in self_reference_patterns:
            if re.search(pattern, response_lower):
                score = 1.0  # Automatic failure
                issues.append(f"CRITICAL: Self-reference prefix detected: '{re.search(pattern, response_lower).group()}'")
                break
        
        # 5. SELF-ADDRESSING CHECK (CRITICAL)
        # Characters should not address themselves (@mentions or self-reference)
        self_addressing_patterns = [
            r'@\s*(peter|brian|stewie)',  # "@Peter" mentions
            r'@\s*(peter|brian|stewie)\s+(griffin|bot)',  # "@Peter Griffin"
        ]
        
        for pattern in self_addressing_patterns:
            matches = re.findall(pattern, response_lower, re.IGNORECASE)
            if matches:
                for match in matches:
                    addressed_name = None
                    if isinstance(match, tuple):
                        # Find the character name in the match
                        for part in match:
                            if part.lower() in ['peter', 'brian', 'stewie']:
                                addressed_name = part.lower()
                                break
                    else:
                        addressed_name = match.lower()
                    
                    # Only penalize if addressing themselves
                    if addressed_name and addressed_name == character_name.lower():
                        score -= 35.0  # Major penalty for self-addressing
                        issues.append(f"CRITICAL: Self-addressing with @{addressed_name}")
        
        # 5. SPEAKER ATTRIBUTION ACCURACY (New Critical Check)
        if conversation_context:
            attribution_issues = _check_speaker_attribution(response_text, conversation_context, character_name)
            if attribution_issues:
                score -= 30.0  # Major penalty for incorrect attribution in 1-100 scale
                issues.extend(attribution_issues)
            else:
                strengths.append("Correct speaker attribution")
                score += 5.0  # Small bonus for correct attribution
        
        # 6. CONVERSATION COHERENCE CHECK
        # Check if response acknowledges the conversation context appropriately
        if conversation_context:
            context_lines = conversation_context.strip().split('\n')
            if len(context_lines) >= 2:
                last_human_message = None
                last_bot_message = None
                
                # Find the most recent human and bot messages
                for line in reversed(context_lines):
                    if line.startswith("Human:") and not last_human_message:
                        last_human_message = line[6:].strip().lower()
                    elif ":" in line and not line.startswith("Human:") and not last_bot_message:
                        last_bot_message = line.split(":", 1)[1].strip().lower()
                
                # Check if response is relevant to recent conversation
                if last_human_message:
                    # Extract key topics from human message
                    human_topics = set(word for word in last_human_message.split() 
                                     if len(word) > 3 and word.isalpha())
                    response_words = set(word for word in response_lower.split() 
                                       if len(word) > 3 and word.isalpha())
                    
                    # Check for topic relevance
                    topic_overlap = len(human_topics.intersection(response_words))
                    if topic_overlap == 0 and len(human_topics) > 2:
                        # Check if it's a complete topic change without acknowledgment
                        topic_change_acknowledgments = [
                            "anyway", "speaking of", "by the way", "oh", "wait",
                            "actually", "you know what", "that reminds me"
                        ]
                        
                        if not any(ack in response_lower for ack in topic_change_acknowledgments):
                            score -= 15.0  # Adjusted for 1-100 scale
                            issues.append("Abrupt topic change without acknowledgment")
                        else:
                            strengths.append("Natural topic transition")
                            score += 5.0  # Bonus for good transitions
        
        # 6. RESPONSE TIMING AND CONTEXT AWARENESS
        # Check if response seems aware it's part of an ongoing conversation
        conversation_awareness_indicators = [
            # Good indicators of conversation awareness
            "you", "your", "that", "this", "what you", "like you said",
            "i agree", "i disagree", "interesting", "good point",
            "you're right", "you're wrong", "i think", "in my opinion"
        ]
        
        monologue_indicators = [
            # Indicators of talking to oneself/monologue
            "i was thinking", "i've been wondering", "i should",
            "i need to", "i want to", "my plan", "my idea",
            "let me tell you", "here's what", "i'll just"
        ]
        
        awareness_score = sum(1 for indicator in conversation_awareness_indicators 
                            if indicator in response_lower)
        monologue_score = sum(1 for indicator in monologue_indicators 
                            if indicator in response_lower)
        
        if awareness_score > monologue_score:
            score += 10.0  # Better bonus for conversation awareness in 1-100 scale
            strengths.append("Shows conversation awareness")
        elif monologue_score > awareness_score * 2:
            score -= 15.0  # Larger penalty for monologue tendency in 1-100 scale
            issues.append("Sounds like talking to self rather than conversing")
        
        # 7. CHARACTER-SPECIFIC CONVERSATION STYLE CHECK
        if character_name == "Peter":
            # Peter should be reactive and simple
            if any(word in response_lower for word in ["hehehe", "holy crap", "yeah", "awesome"]):
                strengths.append("Authentic Peter reactions")
                score += 10.0  # Better bonus for authentic character voice
            
            # Peter shouldn't give long explanations
            if len(response_text) > 300:
                score -= 10.0  # Larger penalty for verbosity in 1-100 scale
                issues.append("Too verbose for Peter's character")
                
        elif character_name == "Brian":
            # Brian should engage intellectually but not lecture
            intellectual_engagement = any(word in response_lower for word in 
                                        ["actually", "however", "interesting", "consider", "think"])
            if intellectual_engagement:
                strengths.append("Intellectual engagement appropriate for Brian")
                score += 10.0  # Better bonus for intellectual character voice
            
            # Check for pretentious lecturing vs. conversation
            lecturing_indicators = ["let me explain", "you see", "the fact is", "obviously"]
            if any(indicator in response_lower for indicator in lecturing_indicators):
                score -= 10.0  # Larger penalty for lecturing in 1-100 scale
                issues.append("Sounds like lecturing rather than conversing")
                
        elif character_name == "Stewie":
            # Stewie should be condescending but engaging
            if any(word in response_lower for word in ["deuce", "blast", "fool", "imbecile"]):
                strengths.append("Authentic Stewie condescension")
                score += 10.0  # Better bonus for authentic character voice
            
            # Stewie shouldn't ignore others completely
            if not any(word in response_lower for word in ["you", "your", "that", "this"]):
                score -= 15.0  # Larger penalty for ignoring conversation in 1-100 scale
                issues.append("Stewie ignoring conversation partners")
        
        # 8. NATURAL CONVERSATION FLOW INDICATORS
        natural_flow_indicators = [
            # Questions that invite response
            "?", "what do you", "don't you", "right?", "you know?",
            # Reactions to others
            "really?", "seriously?", "no way", "i can't believe",
            # Building on conversation
            "that's", "so you're saying", "wait", "hold on"
        ]
        
        flow_score = sum(1 for indicator in natural_flow_indicators 
                        if indicator in response_lower)
        if flow_score >= 2:
            score += 10.0  # Better bonus for natural flow in 1-100 scale
            strengths.append("Promotes natural conversation flow")
        elif flow_score == 0 and len(response_text) > 50:
            score -= 10.0  # Larger penalty for poor flow in 1-100 scale
            issues.append("Doesn't promote conversation continuation")
        
        # 9. AVOID REPETITIVE PATTERNS
        # Check for repetitive sentence structures or phrases
        sentences = response_text.split('.')
        if len(sentences) > 2:
            sentence_starts = [s.strip()[:10].lower() for s in sentences if s.strip()]
            if len(set(sentence_starts)) < len(sentence_starts) * 0.7:
                score -= 10.0  # Larger penalty for repetition in 1-100 scale
                issues.append("Repetitive sentence patterns")
        
        # 10. HALLUCINATION DETECTION (NEW)
        if ANTI_HALLUCINATION_ENABLED:
            hallucination_indicators = [
                "comprehensive manual", "step-by-step process", "detailed instructions",
                "as outlined in", "according to the", "as mentioned in the",
                "the aforementioned", "previously discussed", "as we established",
                "in our earlier conversation", "as you know from", "building on our",
                "continuing from where", "as per our discussion"
            ]
            
            hallucination_count = sum(1 for indicator in hallucination_indicators 
                                    if indicator in response_lower)
            
            if hallucination_count > 0:
                score -= (hallucination_count * 15.0)  # Heavy penalty for hallucination
                issues.append(f"Potential hallucination detected ({hallucination_count} indicators)")
            
            # Check for over-elaboration (too much detail for simple conversation)
            if len(response_text) > 300 and conversation_context:
                context_length = len(conversation_context)
                response_length = len(response_text)
                
                # If response is much longer than recent conversation context, it might be hallucinating
                if response_length > context_length * 2:
                    score -= 20.0  # Major penalty for over-elaboration
                    issues.append("Response over-elaborates beyond conversation context")
                    
            # Check for introducing new "facts" not in conversation
            fact_indicators = [
                "the fact is", "it's well known that", "everyone knows",
                "obviously", "clearly", "it's established that",
                "research shows", "studies indicate", "experts say"
            ]
            
            fact_count = sum(1 for indicator in fact_indicators if indicator in response_lower)
            if fact_count > 0:
                score -= (fact_count * 10.0)  # Penalty for introducing unsupported facts
                issues.append(f"Introducing unsupported facts ({fact_count} instances)")
        
        # 11. ADAPTIVE LENGTH VALIDATION (NEW)
        # Check response length against adaptive limits based on conversation state
        # This replaces the truncation approach with retry-based quality control
        if ADAPTIVE_ANTI_HALLUCINATION_ENABLED:
            # Use simplified calculation based on conversation message count
            # This is more reliable than trying to mock the conversation history format
            conversation_message_count = len([msg for msg in conversation_context.split('\n') if ':' in msg]) if conversation_context else 0
            
            # Determine adaptive length limit based on conversation state using the same logic as the main system
            if conversation_message_count <= CONVERSATION_HISTORY_COLD_LIMIT:
                adaptive_max_length = COLD_START_MAX_RESPONSE_LENGTH
                conversation_state = "COLD_START"
            elif conversation_message_count <= CONVERSATION_HISTORY_WARM_LIMIT:
                adaptive_max_length = WARM_CONVERSATION_MAX_RESPONSE_LENGTH
                conversation_state = "WARM_CONVERSATION"
            else:
                adaptive_max_length = HOT_CONVERSATION_MAX_RESPONSE_LENGTH
                conversation_state = "HOT_CONVERSATION"
            
            if len(response_text) > adaptive_max_length:
                # Major penalty for exceeding adaptive length limits
                length_penalty = min(30.0, (len(response_text) - adaptive_max_length) / 10.0)
                score -= length_penalty
                issues.append(f"Response too long ({len(response_text)} chars > {adaptive_max_length} limit for {conversation_state})")
                print(f"üö® Adaptive length validation: Response exceeds {conversation_state} limit ({len(response_text)} > {adaptive_max_length})")
            else:
                # Small bonus for appropriate length
                score += 2.0
                strengths.append(f"Appropriate length for {conversation_state} conversation")
        
        # Ensure score is within bounds (1-100 scale)
        score = max(1.0, min(100.0, score))
        
        return {
            "flow_score": score,
            "issues": issues,
            "strengths": strengths,
            "conversation_awareness": awareness_score > 0,
            "monologue_tendency": monologue_score > awareness_score
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error in conversation flow assessment: {e}")
        return {
            "flow_score": 3.0,
            "issues": ["Assessment error"],
            "strengths": [],
            "conversation_awareness": False,
            "monologue_tendency": False
        }

def _check_speaker_attribution(response_text, conversation_context, current_character):
    """
    Check if the response correctly attributes statements to the right speakers.
    Returns a list of attribution issues found.
    """
    issues = []
    
    try:
        response_lower = response_text.lower()
        
        # Parse conversation context to track who said what
        speaker_statements = {}
        context_lines = conversation_context.strip().split('\n')
        
        for line in context_lines:
            if ':' in line:
                parts = line.split(':', 1)
                if len(parts) == 2:
                    speaker = parts[0].strip()
                    statement = parts[1].strip().lower()
                    
                    if speaker not in speaker_statements:
                        speaker_statements[speaker] = []
                    speaker_statements[speaker].append(statement)
        
        # Character name mappings for detection
        character_names = ['peter', 'brian', 'stewie', 'lois', 'meg', 'chris']
        
        # Look for patterns where the current character addresses someone about something they didn't say
        for char_name in character_names:
            if char_name == current_character.lower():
                continue
                
            # Check for direct addressing patterns
            addressing_patterns = [
                f"{char_name}, you said",
                f"{char_name}, you mentioned",
                f"{char_name}, you were talking about",
                f"as {char_name} said",
                f"like {char_name} mentioned",
                f"when {char_name} brought up",
                f"since {char_name} was discussing",
                f"now, {char_name}, if you're going to",
                f"and as for you, {char_name}",
                f"but {char_name}, you"
            ]
            
            for pattern in addressing_patterns:
                if pattern in response_lower:
                    # Check if this character actually said something recently
                    char_spoke_recently = False
                    for speaker, statements in speaker_statements.items():
                        if speaker.lower() == char_name and statements:
                            char_spoke_recently = True
                            break
                    
                    if not char_spoke_recently:
                        issues.append(f"Incorrectly addressing {char_name.title()} about something they didn't say")
                    
                    # Additional check: look for topic misattribution
                    # Extract key topics from the response after the addressing pattern
                    pattern_index = response_lower.find(pattern)
                    if pattern_index != -1:
                        response_after_pattern = response_lower[pattern_index + len(pattern):]
                        
                        # Look for specific topics/concepts being discussed
                        key_topics = _extract_key_topics(response_after_pattern)
                        
                        # Check if the addressed character actually mentioned these topics
                        if char_name in speaker_statements:
                            char_statements = ' '.join(speaker_statements[char_name])
                            topic_matches = sum(1 for topic in key_topics if topic in char_statements)
                            
                            if key_topics and topic_matches == 0:
                                # Find who actually mentioned these topics
                                actual_speaker = None
                                for speaker, statements in speaker_statements.items():
                                    if speaker.lower() != char_name:
                                        speaker_text = ' '.join(statements)
                                        speaker_topic_matches = sum(1 for topic in key_topics if topic in speaker_text)
                                        if speaker_topic_matches > 0:
                                            actual_speaker = speaker
                                            break
                                
                                if actual_speaker:
                                    issues.append(f"Attributing {actual_speaker}'s statement about {', '.join(key_topics[:2])} to {char_name.title()}")
        
        # Check for general misattribution patterns
        misattribution_patterns = [
            "as you were saying about",
            "when you mentioned",
            "your point about",
            "you brought up",
            "you were discussing"
        ]
        
        for pattern in misattribution_patterns:
            if pattern in response_lower:
                # This suggests the character is responding to someone specific
                # We should verify this is contextually appropriate
                pattern_index = response_lower.find(pattern)
                if pattern_index != -1:
                    # Look for the topic being referenced
                    response_after_pattern = response_lower[pattern_index + len(pattern):]
                    key_topics = _extract_key_topics(response_after_pattern)
                    
                    if key_topics:
                        # Check if anyone actually mentioned these topics recently
                        topic_mentioned = False
                        for speaker, statements in speaker_statements.items():
                            if speaker.lower() != current_character.lower():
                                speaker_text = ' '.join(statements)
                                if any(topic in speaker_text for topic in key_topics):
                                    topic_mentioned = True
                                    break
                        
                        if not topic_mentioned:
                            issues.append(f"Referencing topics ({', '.join(key_topics[:2])}) that weren't mentioned in recent conversation")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error in speaker attribution check: {e}")
        issues.append("Attribution check error")
    
    return issues

def _extract_key_topics(text):
    """
    Extract key topics/concepts from a text snippet.
    Returns a list of important words/phrases.
    """
    # Remove common words and extract meaningful terms
    common_words = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with',
        'by', 'from', 'up', 'about', 'into', 'through', 'during', 'before', 'after',
        'above', 'below', 'between', 'among', 'is', 'are', 'was', 'were', 'be', 'been',
        'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',
        'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you',
        'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them', 'my', 'your',
        'his', 'her', 'its', 'our', 'their'
    }
    
    # Split into words and filter
    words = text.lower().split()
    key_topics = []
    
    for word in words:
        # Clean word of punctuation
        clean_word = ''.join(c for c in word if c.isalpha())
        
        # Keep words that are:
        # - Not common words
        # - At least 4 characters long
        # - Contain letters
        if (clean_word not in common_words and 
            len(clean_word) >= 4 and 
            clean_word.isalpha()):
            key_topics.append(clean_word)
    
    # Also look for specific important terms regardless of length
    important_terms = [
        'prince', 'machiavelli', 'book', 'novel', 'power', 'domination', 'plan',
        'invention', 'scheme', 'chicken', 'fight', 'beer', 'tv', 'show', 'movie',
        'politics', 'philosophy', 'science', 'art', 'culture', 'literature'
    ]
    
    for term in important_terms:
        if term in text.lower() and term not in key_topics:
            key_topics.append(term)
    
    return key_topics[:5]  # Return top 5 topics

def calculate_adaptive_quality_threshold(conversation_history, channel_id=None):
    """
    Calculate adaptive quality control threshold based on conversation history richness.
    
    The more conversation history available, the higher the quality threshold:
    - Cold Start (0-3 messages): Lower threshold (50/100) - Be lenient for first interactions
    - Warm Conversation (4-10 messages): Medium threshold (65/100) - Some context available
    - Hot Conversation (11+ messages): High threshold (75/100) - Rich context, demand quality
    
    Args:
        conversation_history: List of conversation messages
        channel_id: Optional channel ID for channel-specific history lookup
        
    Returns:
        float: Adaptive quality threshold (1-100 scale)
    """
    if not ADAPTIVE_QUALITY_CONTROL_ENABLED:
        return QUALITY_CONTROL_MIN_RATING
    
    # Count meaningful conversation messages (exclude system messages)
    meaningful_messages = 0
    context_richness_score = 0
    
    for msg in conversation_history:
        if isinstance(msg, (HumanMessage, AIMessage)):
            meaningful_messages += 1
            
            # Add context richness scoring
            content = getattr(msg, 'content', '')
            if len(content) > 50:  # Substantial messages add more context value
                context_richness_score += 2
            elif len(content) > 20:  # Medium messages add some value
                context_richness_score += 1
            else:  # Short messages add minimal value
                context_richness_score += 0.5
    
    # Check for additional conversation history in database if channel_id provided
    if channel_id and conversations_collection is not None:
        try:
            # Look for recent conversation history in this channel (last 24 hours)
            from datetime import datetime, timedelta
            recent_cutoff = datetime.now() - timedelta(hours=24)
            
            recent_messages = list(conversations_collection.find({
                "channel_id": str(channel_id),
                "timestamp": {"$gte": recent_cutoff}
            }).sort("timestamp", -1).limit(20))
            
            # Add database history to our count
            for msg in recent_messages:
                meaningful_messages += 1
                content = msg.get('human_message', '') + msg.get('bot_response', '')
                if len(content) > 50:
                    context_richness_score += 1.5  # Database history is slightly less valuable
                elif len(content) > 20:
                    context_richness_score += 0.8
                else:
                    context_richness_score += 0.3
                    
        except Exception as e:
            print(f"‚ö†Ô∏è Could not check database history for adaptive threshold: {e}")
    
    # Calculate adaptive threshold based on conversation richness
    if meaningful_messages <= CONVERSATION_HISTORY_COLD_LIMIT:
        # Cold start - be lenient
        base_threshold = COLD_START_THRESHOLD
        threshold_type = "COLD_START"
    elif meaningful_messages <= CONVERSATION_HISTORY_WARM_LIMIT:
        # Warm conversation - moderate expectations
        base_threshold = WARM_CONVERSATION_THRESHOLD
        threshold_type = "WARM_CONVERSATION"
    else:
        # Hot conversation - high expectations
        base_threshold = HOT_CONVERSATION_THRESHOLD
        threshold_type = "HOT_CONVERSATION"
    
    # Apply context richness modifier (¬±5 points based on message quality)
    richness_modifier = min(5.0, max(-5.0, (context_richness_score - meaningful_messages) * 2))
    adaptive_threshold = base_threshold + richness_modifier
    
    # Ensure threshold stays within reasonable bounds
    adaptive_threshold = max(40.0, min(85.0, adaptive_threshold))
    
    print(f"üéØ Adaptive Quality Threshold: {adaptive_threshold:.1f}/100 ({threshold_type})")
    print(f"   üìä Messages: {meaningful_messages}, Context Score: {context_richness_score:.1f}, Modifier: {richness_modifier:+.1f}")
    
    return adaptive_threshold

def get_conversation_context_value(conversation_history):
    """
    Calculate the value/richness of conversation context for quality assessment.
    
    Returns:
        dict: Context analysis with scores and insights
    """
    context_analysis = {
        "total_messages": len(conversation_history),
        "meaningful_messages": 0,
        "average_length": 0,
        "topic_continuity": 0,
        "character_diversity": set(),
        "context_value_score": 0
    }
    
    total_length = 0
    previous_topics = []
    
    for i, msg in enumerate(conversation_history):
        if isinstance(msg, (HumanMessage, AIMessage)):
            context_analysis["meaningful_messages"] += 1
            content = getattr(msg, 'content', '')
            total_length += len(content)
            
            # Track character diversity
            if isinstance(msg, AIMessage):
                speaker = getattr(msg, 'name', 'Unknown')
                context_analysis["character_diversity"].add(speaker)
            
            # Simple topic continuity check (look for connecting words)
            if i > 0 and any(word in content.lower() for word in 
                           ['that', 'this', 'it', 'also', 'and', 'but', 'however', 'speaking of']):
                context_analysis["topic_continuity"] += 1
    
    if context_analysis["meaningful_messages"] > 0:
        context_analysis["average_length"] = total_length / context_analysis["meaningful_messages"]
    
    # Calculate overall context value score
    base_score = context_analysis["meaningful_messages"] * 2
    length_bonus = min(10, context_analysis["average_length"] / 10)  # Bonus for substantial messages
    continuity_bonus = context_analysis["topic_continuity"] * 1.5
    diversity_bonus = len(context_analysis["character_diversity"]) * 2
    
    context_analysis["context_value_score"] = base_score + length_bonus + continuity_bonus + diversity_bonus
    context_analysis["character_diversity"] = list(context_analysis["character_diversity"])
    
    return context_analysis

def calculate_character_aware_anti_hallucination_settings(character_name, conversation_state, base_settings):
    """
    Adjust anti-hallucination settings based on character personality and conversation state.
    
    Different characters have different natural response patterns:
    - Peter: Tends to ramble, needs stricter length controls
    - Brian: Verbose and intellectual, moderate controls
    - Stewie: Articulate but concise, lenient controls
    
    Args:
        character_name: The character responding
        conversation_state: COLD_START, WARM_CONVERSATION, or HOT_CONVERSATION
        base_settings: Base anti-hallucination settings for the conversation state
        
    Returns:
        dict: Character-adjusted anti-hallucination settings
    """
    character_modifiers = {
        "Peter": {
            "length_multiplier": 0.7,  # Peter needs shorter responses to prevent rambling
            "risk_multiplier": 1.2,    # Higher hallucination risk due to his nature
            "strictness_multiplier": 1.3  # Need stricter controls for Peter
        },
        "Brian": {
            "length_multiplier": 1.0,  # Brian should be conversational, not verbose
            "risk_multiplier": 0.8,    # Lower risk - he's articulate and self-aware
            "strictness_multiplier": 0.9  # More lenient to allow natural sarcasm and self-deprecation
        },
        "Stewie": {
            "length_multiplier": 0.9,  # Stewie should be concise but not overly restricted
            "risk_multiplier": 0.6,    # Lowest risk - he's precise and sophisticated
            "strictness_multiplier": 0.7  # Most lenient to allow his natural wit and condescension
        }
    }
    
    # Get character-specific modifiers, default to Brian's settings
    modifiers = character_modifiers.get(character_name, character_modifiers["Brian"])
    
    # Apply character modifiers to base settings
    adjusted_settings = {
        "max_response_length": int(base_settings["max_response_length"] * modifiers["length_multiplier"]),
        "hallucination_risk": min(1.0, base_settings["hallucination_risk"] * modifiers["risk_multiplier"]),
        "strictness_multiplier": base_settings["strictness_multiplier"] * modifiers["strictness_multiplier"],
        "character_modifier_applied": character_name,
        "base_length": base_settings["max_response_length"],
        "length_adjustment": modifiers["length_multiplier"]
    }
    
    # Ensure values stay within reasonable bounds
    adjusted_settings["max_response_length"] = max(80, min(500, adjusted_settings["max_response_length"]))
    adjusted_settings["hallucination_risk"] = max(0.1, min(1.0, adjusted_settings["hallucination_risk"]))
    adjusted_settings["strictness_multiplier"] = max(0.6, min(2.5, adjusted_settings["strictness_multiplier"]))
    
    print(f"üé≠ Character-Aware Anti-Hallucination for {character_name}:")
    print(f"   üìè Length: {base_settings['max_response_length']} ‚Üí {adjusted_settings['max_response_length']} chars ({modifiers['length_multiplier']:.1f}x)")
    print(f"   üö® Risk: {base_settings['hallucination_risk']:.1%} ‚Üí {adjusted_settings['hallucination_risk']:.1%} ({modifiers['risk_multiplier']:.1f}x)")
    print(f"   üîß Strictness: {base_settings['strictness_multiplier']:.1f} ‚Üí {adjusted_settings['strictness_multiplier']:.1f}x ({modifiers['strictness_multiplier']:.1f}x)")
    
    return adjusted_settings

def calculate_adaptive_context_weights(conversation_history, channel_id=None, character_name=None):
    """
    Calculate adaptive context weights, lengths, and anti-hallucination measures based on conversation history richness.
    
    As conversation history grows and becomes more valuable, we should:
    1. Rely more on conversation history and less on external RAG context (weighting)
    2. Include more conversation messages and fewer RAG characters (length scaling)
    3. Apply stricter anti-hallucination measures to prevent over-elaboration (hallucination control)
    
    This creates a natural progression:
    - Cold Start: Few conversation messages (2), more RAG context (400 chars), lenient anti-hallucination
    - Warm Conversation: Moderate conversation messages (4), moderate RAG context (250 chars), moderate anti-hallucination
    - Hot Conversation: Rich conversation messages (6), minimal RAG context (150 chars), strict anti-hallucination
    
    Args:
        conversation_history: List of conversation messages
        channel_id: Optional channel ID for channel-specific history lookup
        
    Returns:
        dict: Context weights, lengths, anti-hallucination measures, and analysis
    """
    if not ADAPTIVE_CONTEXT_WEIGHTING_ENABLED:
        return {
            "conversation_weight": CONVERSATION_FOCUS_WEIGHT,
            "rag_weight": 1.0 - CONVERSATION_FOCUS_WEIGHT,
            "weighting_type": "STATIC",
            "conversation_richness": 0,
            "conversation_messages": 3,  # Default static value
            "rag_context_length": MAX_CONTEXT_INJECTION,  # Default static value
            "max_response_length": 250,  # Default static value,
            "hallucination_risk": 0.5,  # Default static value,
            "strictness_multiplier": 1.0  # Default static value
        }
    
    # Get conversation context analysis
    context_analysis = get_conversation_context_value(conversation_history)
    meaningful_messages = context_analysis["meaningful_messages"]
    context_value_score = context_analysis["context_value_score"]
    
    # Check for additional conversation history in database if channel_id provided
    database_messages = 0
    if channel_id and conversations_collection is not None:
        try:
            from datetime import datetime, timedelta
            recent_cutoff = datetime.now() - timedelta(hours=24)
            
            recent_messages = list(conversations_collection.find({
                "channel_id": str(channel_id),
                "timestamp": {"$gte": recent_cutoff}
            }).sort("timestamp", -1).limit(20))
            
            database_messages = len(recent_messages)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Could not check database history for adaptive context weighting: {e}")
    
    total_conversation_context = meaningful_messages + (database_messages * 0.5)  # Database history counts for less
    
    # Determine context weighting, length tier, and anti-hallucination measures
    if total_conversation_context <= CONVERSATION_HISTORY_COLD_LIMIT:
        # Cold start - need more external context, fewer conversation messages, lenient anti-hallucination
        base_conversation_weight = COLD_START_CONVERSATION_WEIGHT
        base_conversation_messages = COLD_START_CONVERSATION_MESSAGES
        base_rag_context_length = COLD_START_RAG_CONTEXT_LENGTH
        base_max_response_length = COLD_START_MAX_RESPONSE_LENGTH
        base_hallucination_risk = COLD_START_HALLUCINATION_RISK
        base_strictness_multiplier = COLD_START_STRICTNESS_MULTIPLIER
        weighting_type = "COLD_START"
    elif total_conversation_context <= CONVERSATION_HISTORY_WARM_LIMIT:
        # Warm conversation - balanced approach with moderate anti-hallucination
        base_conversation_weight = WARM_CONVERSATION_WEIGHT
        base_conversation_messages = WARM_CONVERSATION_MESSAGES
        base_rag_context_length = WARM_CONVERSATION_RAG_CONTEXT_LENGTH
        base_max_response_length = WARM_CONVERSATION_MAX_RESPONSE_LENGTH
        base_hallucination_risk = WARM_CONVERSATION_HALLUCINATION_RISK
        base_strictness_multiplier = WARM_CONVERSATION_STRICTNESS_MULTIPLIER
        weighting_type = "WARM_CONVERSATION"
    else:
        # Hot conversation - conversation history is very valuable, strict anti-hallucination needed
        base_conversation_weight = HOT_CONVERSATION_WEIGHT
        base_conversation_messages = HOT_CONVERSATION_MESSAGES
        base_rag_context_length = HOT_CONVERSATION_RAG_CONTEXT_LENGTH
        base_max_response_length = HOT_CONVERSATION_MAX_RESPONSE_LENGTH
        base_hallucination_risk = HOT_CONVERSATION_HALLUCINATION_RISK
        base_strictness_multiplier = HOT_CONVERSATION_STRICTNESS_MULTIPLIER
        weighting_type = "HOT_CONVERSATION"
    
    # Apply context richness modifier (¬±0.05 for weight, ¬±1 message, ¬±50 chars for lengths, ¬±0.1 for risk)
    if context_value_score > 0:
        quality_ratio = min(2.0, context_value_score / max(1, meaningful_messages))  # Quality per message
        richness_modifier = (quality_ratio - 1.0) * 0.05  # ¬±0.05 max adjustment for weight
        
        # Length modifiers based on conversation quality
        conversation_length_modifier = int((quality_ratio - 1.0) * 1.0)  # ¬±1 message
        rag_length_modifier = int((1.0 - quality_ratio) * 50)  # Inverse relationship: better conversation = less RAG
        response_length_modifier = int((1.0 - quality_ratio) * 25)  # Better conversation = shorter responses
        
        # Anti-hallucination modifiers - higher quality conversations need stricter measures
        hallucination_risk_modifier = (quality_ratio - 1.0) * 0.1  # ¬±0.1 risk adjustment
        strictness_modifier = (quality_ratio - 1.0) * 0.2  # ¬±0.2 strictness adjustment
    else:
        richness_modifier = 0.0
        conversation_length_modifier = 0
        rag_length_modifier = 0
        response_length_modifier = 0
        hallucination_risk_modifier = 0.0
        strictness_modifier = 0.0
    
    # Apply modifiers
    adaptive_conversation_weight = base_conversation_weight + richness_modifier
    adaptive_conversation_messages = base_conversation_messages + conversation_length_modifier
    adaptive_rag_context_length = base_rag_context_length + rag_length_modifier
    adaptive_max_response_length = base_max_response_length + response_length_modifier
    adaptive_hallucination_risk = base_hallucination_risk + hallucination_risk_modifier
    adaptive_strictness_multiplier = base_strictness_multiplier + strictness_modifier
    
    # Ensure values stay within reasonable bounds
    adaptive_conversation_weight = max(0.4, min(0.9, adaptive_conversation_weight))
    adaptive_conversation_messages = max(1, min(8, adaptive_conversation_messages))  # 1-8 messages
    adaptive_rag_context_length = max(50, min(500, adaptive_rag_context_length))  # 50-500 chars
    adaptive_max_response_length = max(100, min(400, adaptive_max_response_length))  # 100-400 chars
    adaptive_hallucination_risk = max(0.1, min(1.0, adaptive_hallucination_risk))  # 10-100% risk
    adaptive_strictness_multiplier = max(0.8, min(2.0, adaptive_strictness_multiplier))  # 0.8x-2.0x strictness
    
    adaptive_rag_weight = 1.0 - adaptive_conversation_weight
    
    # Apply character-aware anti-hallucination adjustments if character_name provided
    if character_name and ADAPTIVE_ANTI_HALLUCINATION_ENABLED:
        base_anti_hallucination = {
            "max_response_length": adaptive_max_response_length,
            "hallucination_risk": adaptive_hallucination_risk,
            "strictness_multiplier": adaptive_strictness_multiplier
        }
        
        character_adjusted = calculate_character_aware_anti_hallucination_settings(
            character_name, weighting_type, base_anti_hallucination
        )
        
        # Update with character-adjusted values
        adaptive_max_response_length = character_adjusted["max_response_length"]
        adaptive_hallucination_risk = character_adjusted["hallucination_risk"]
        adaptive_strictness_multiplier = character_adjusted["strictness_multiplier"]
    
    print(f"üéöÔ∏è Adaptive Context Weights: {adaptive_conversation_weight:.1%} conversation, {adaptive_rag_weight:.1%} RAG ({weighting_type})")
    print(f"üìè Adaptive Context Lengths: {adaptive_conversation_messages} conv messages, {adaptive_rag_context_length} RAG chars")
    print(f"üö® Adaptive Anti-Hallucination: {adaptive_max_response_length} max chars, {adaptive_hallucination_risk:.1%} risk, {adaptive_strictness_multiplier:.1f}x strictness")
    print(f"   üìä Total Context: {total_conversation_context:.1f} messages, Quality Score: {context_value_score:.1f}")
    print(f"   üîß Modifiers: Weight {richness_modifier:+.3f}, Conv {conversation_length_modifier:+d} msgs, RAG {rag_length_modifier:+d} chars")
    
    return {
        "conversation_weight": adaptive_conversation_weight,
        "rag_weight": adaptive_rag_weight,
        "weighting_type": weighting_type,
        "conversation_richness": total_conversation_context,
        "context_value_score": context_value_score,
        "richness_modifier": richness_modifier,
        "database_messages": database_messages,
        "conversation_messages": adaptive_conversation_messages,
        "rag_context_length": adaptive_rag_context_length,
        "conversation_length_modifier": conversation_length_modifier,
        "rag_length_modifier": rag_length_modifier,
        "max_response_length": adaptive_max_response_length,
        "hallucination_risk": adaptive_hallucination_risk,
        "strictness_multiplier": adaptive_strictness_multiplier,
        "response_length_modifier": response_length_modifier,
        "hallucination_risk_modifier": hallucination_risk_modifier,
        "strictness_modifier": strictness_modifier
    }

if __name__ == '__main__':
    # Try to connect to MongoDB with retries
    max_retries = 5
    initial_delay = 1
    
    print("Starting orchestrator initialization...")
    
    while True:
        if connect_to_mongodb(max_retries=max_retries, initial_delay=initial_delay):
            break
        print("Initial MongoDB connection attempts failed. Waiting 10 seconds before trying again...")
        time.sleep(10)
    
    try:
        # get_embeddings_model() # Initialize embeddings model on startup - Removed, orchestrator no longer loads this directly
        # initialize_vector_store() # Initialize or load vector store on startup - Removed
        
        # Initialize the fine-tuning system after MongoDB connection is established
        try:
            if mongo_client:
                prompt_fine_tuner = PromptFineTuner(mongo_client)
                print("üéØ Supervised Fine-Tuning System initialized successfully")
                print(f"   üìä Quality Control: {'Enabled' if QUALITY_CONTROL_ENABLED else 'Disabled'}")
                print(f"   üéØ Auto-Optimization: {'Enabled' if FINE_TUNING_ENABLED else 'Disabled'}")
                print(f"   üß™ A/B Testing: {AB_TEST_PERCENTAGE*100}% traffic for optimized prompts")
            else:
                print("‚ö†Ô∏è Warning: MongoDB client not available, fine-tuning system disabled")
                prompt_fine_tuner = None
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not initialize fine-tuning system: {e}")
            prompt_fine_tuner = None
        
        # Start the retry worker thread
        threading.Thread(target=retry_worker, daemon=True).start()
        print("Dead letter queue retry worker thread started.")
        
        threading.Thread(target=run_flask_app, daemon=True).start()
        print("Orchestrator server thread started. Waiting for requests...")

        threading.Thread(target=organic_conversation_monitor, daemon=True).start()
        print("Organic conversation monitor thread started.")
        
        # Log follow-up conversation configuration
        print(f"üîÑ Follow-up Conversations: {'Enabled' if ENABLE_FOLLOW_UP_CONVERSATIONS else 'Disabled'}")
        if ENABLE_FOLLOW_UP_CONVERSATIONS:
            print(f"   ‚è±Ô∏è Follow-up delay: {FOLLOW_UP_DELAY_SECONDS}s")
            print(f"   üïê Min time between follow-ups: {MIN_TIME_BETWEEN_FOLLOW_UPS}s")

        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("Orchestrator server and scheduler stopped by user (Ctrl+C).")
    except Exception as e:
        print(f"CRITICAL: Main orchestrator thread crashed unexpectedly: {e}")
        print(traceback.format_exc())
    finally:
        if mongo_client:
            mongo_client.close()
            print("MongoDB connection closed.")

